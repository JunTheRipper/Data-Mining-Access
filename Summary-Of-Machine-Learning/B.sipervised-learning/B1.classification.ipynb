{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 监督学习专题 —— 分类\n",
    "\n",
    "## 监督学习简介\n",
    "\n",
    "监督学习的目标与特点：\n",
    "\n",
    "利用一组带有标签的数据，学习从输入到输出的映射，然后将这种映射关系应用到未知数据上，达到分类或回归的目的。\n",
    "\n",
    "**分类：当输出是离散的，学习任务为分类任务。**\n",
    "\n",
    "**回归：当输出是连续的，学习任务为回归任务。**\n",
    "\n",
    "### In/Output\n",
    "\n",
    "输入：一组有标签的训练数据(也称观察和评估)，标签表明了这些数\n",
    "据（观察）的所署类别。\n",
    "\n",
    "输出：分类模型根据这些训练数据，训练自己的模型参数，\n",
    "学习出一个适合这组数据的分类器，\n",
    "当有新数据（非训练数据）需要进行类别判断，\n",
    "就可以将这组新数据作为输入送给学好的分类器进行判断。\n",
    "\n",
    "### 评价\n",
    "\n",
    "训练集和测试集的设定\n",
    "\n",
    "训练集(training set):顾名思义用来训练模型的已标注数据，\n",
    "用来建立模型，发现规律。\n",
    "\n",
    "测试集(testing set):也是已标注数据，通常做法是将标注隐藏，\n",
    "输送给训练好的模型，通过结果与真实标注进行对比，评估模型的学习能力。\n",
    "\n",
    "训练集/测试集的划分方法：根据已有标注数据，随机选出一部分数据（70%）数据作为训练数据，余下的作为测试数据，\n",
    "\n",
    "此外还有交叉验证法，自助法用来评估分类模型。\n",
    "\n",
    "#### 评价标准\n",
    "\n",
    "**精确率：**\n",
    "\n",
    "精确率是针对我们预测结果而言的，\n",
    "（以二分类为例）它表示的是预测为正的样本中有多少是真正的正样本。\n",
    "那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，\n",
    "另一种就是把负类预测为正类(FP)，\n",
    "也就是\n",
    "![](Pic/accurency.JPG)\n",
    "\n",
    "**召回率：**\n",
    "\n",
    "是针对我们原来的样本而言的，\n",
    "它表示的是样本中的正例有多少被预测正确了。\n",
    "那也有两种可能，一种是把原来的正类预测成正类(TP)，\n",
    "另一种就是把原来的正类预测为负类(FN)，也就是\n",
    "![](Pic/back.JPG)\n",
    "\n",
    "假设我们手上有60个正样本，40个负样本，\n",
    "我们要找出所有的正样本，\n",
    "分类算法查找出50个，\n",
    "其中只有40个是真正的正样本，\n",
    "\n",
    "TP: 将正类预测为正类数 40；\n",
    "\n",
    "FN: 将正类预测为负类数 20；\n",
    "\n",
    "FP: 将负类预测为正类数 10；\n",
    "\n",
    "TN: 将负类预测为负类数 30\n",
    "\n",
    "准确率（accuracy）=预测对的/所有 = (TP+TN)/(TP+FN+FP+TN) = 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn 中的分类\n",
    "\n",
    "与聚类算法被统一封装在sklearn.cluster模块不同，\n",
    "\n",
    "sklearn库中的分类算法并未被统一封装在一个子模块中，\n",
    "\n",
    "因此对分类算法的import方式各有不同。\n",
    "\n",
    "Sklearn提供的分类函数包括：\n",
    "\n",
    "    • k近邻（knn）\n",
    "    • 朴素贝叶斯（naivebayes），\n",
    "    • 支持向量机（svm），\n",
    "    • 决策树 （decision tree）\n",
    "    • 神经网络模型（Neural networks）等\n",
    "    • 这其中有线性分类器，也有非线性分类器。\n",
    "\n",
    "大致的图像（线性和非线性）的对比\n",
    "\n",
    "![](Pic/classDif.JPG)\n",
    "\n",
    "#### 分类算法应用\n",
    "\n",
    "金融：贷款是否批准进行评估\n",
    "\n",
    " 医疗诊断：判断一个肿瘤是恶性还是良性\n",
    "\n",
    " 欺诈检测：判断一笔银行的交易是否涉嫌欺诈\n",
    "\n",
    " 网页分类：判断网页的所属类别，财经或者是娱乐\n",
    "\n",
    "## 实验数据\n",
    "\n",
    "### Heart Attack Analysis & Prediction Dataset\n",
    "\n",
    "A dataset for heart attack classification\n",
    "\n",
    "心脏病发作分析和预测数据集\n",
    "\n",
    "#### 数据集介绍\n",
    "\n",
    "数据来源： kaggle\n",
    "\n",
    "url: [https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset](https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)\n",
    "\n",
    "数据条目：302条\n",
    "\n",
    "年龄：病人的年龄    Age : Age of the patient\n",
    "\n",
    "性别：患者的性别    Sex : Sex of the patient\n",
    "\n",
    "exang：运动引起的心绞痛（1=是；0=否）    exang: exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "ca：主要血管数量（0-3） ca: number of major vessels (0-3)\n",
    "\n",
    "cp：胸痛型胸痛型 cp : Chest Pain type chest pain type\n",
    "\n",
    "Value 1：典型的心绞痛   Value 1: typical angina\n",
    "\n",
    "Value 2：非典型心绞痛   Value 2: atypical angina\n",
    "\n",
    "Value 3：非心绞痛      Value 3: non-anginal pain\n",
    "\n",
    "Value 4：无症状    Value 4: asymptomatic\n",
    "\n",
    "trtbps：静息血压（以mm Hg为单位）    trtbps : resting blood pressure (in mm Hg)\n",
    "\n",
    "chol：通过BMI传感器获取的mg/dl胆固醇  chol : cholestoral in mg/dl fetched via BMI sensor\n",
    "\n",
    "fbs：（空腹血糖>120 mg/dl）（1=真；0=假） fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "\n",
    "rest_ecg：静息心电图结果\n",
    "rest_ecg : resting electrocardiographic results\n",
    "\n",
    "值0：正常    Value 0: normal\n",
    "\n",
    "值1:ST-T波异常（T波倒置和/或ST抬高或降低>0.05 mV）    Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "\n",
    "值2：根据Estes的标准显示可能或确定的左心室肥大    Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "\n",
    "thalach：达到最大心率    thalach : maximum heart rate achieved\n",
    "\n",
    "目标：0=心脏病发作的机会减少1=心脏病发作的机会增加\n",
    "\n",
    "Slp:坡度\n",
    "\n",
    "target :(output 维度)\n",
    "\n",
    "0= less chance of heart attack\n",
    "\n",
    "1= more chance of heart attack\n",
    "\n",
    "##### 实验预达到目的\n",
    "\n",
    "需求：假设现在出现了一个新用户，但我们只有传感器采集的数据，如何预测他心脏病发作可能性机会增加还是减少呢？\n",
    "\n",
    "在明确这是一个分类问题的情况下，\n",
    "我们可以选定某种分类模型（或者说是算法），通过使用训练数据进行模型学习，然后对每个测试样本给出对应的分类结果。\n",
    "\n",
    "机器学习的分类算法众多，\n",
    "\n",
    "在接下来的学习中我们将会详细介绍经典的分类算法，\n",
    "\n",
    "如K近邻、决策树和朴素贝叶斯的原理和实现，在此之前，我们先尝试对数据进行预处理\n",
    "\n",
    "### 实验基本流程\n",
    "\n",
    "需要从特征文件和标签文件中将所有数据加载到内存\n",
    "中，如果存在缺失值，此步骤还需要进行简单的数据预处理。\n",
    "\n",
    " 创建对应的分类器，并使用训练数据进行训练。\n",
    "\n",
    " 利用测试集预测，通过使用真实值和预测值的比对，计算模型整体的准确率和召回率，来评测模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "5   57    1   0     140   192    0        1       148     0      0.4    1   \n",
       "6   56    0   1     140   294    0        0       153     0      1.3    1   \n",
       "7   44    1   1     120   263    0        1       173     0      0.0    2   \n",
       "8   52    1   2     172   199    1        1       162     0      0.5    2   \n",
       "9   57    1   2     150   168    0        1       174     0      1.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  \n",
       "5    0      1       1  \n",
       "6    0      2       1  \n",
       "7    0      3       1  \n",
       "8    0      3       1  \n",
       "9    0      2       1  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataSet = pd.read_csv('heart.csv')\n",
    "dataSet.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         False\n",
       "sex         False\n",
       "cp          False\n",
       "trtbps      False\n",
       "chol        False\n",
       "fbs         False\n",
       "restecg     False\n",
       "thalachh    False\n",
       "exng        False\n",
       "oldpeak     False\n",
       "slp         False\n",
       "caa         False\n",
       "thall       False\n",
       "output      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 缺失值判断\n",
    "dataSet.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "              age\n",
      "count  303.000000\n",
      "mean    54.366337\n",
      "std      9.082101\n",
      "min     29.000000\n",
      "25%     47.500000\n",
      "50%     55.000000\n",
      "75%     61.000000\n",
      "max     77.000000\n",
      "sex\n",
      "              sex\n",
      "count  303.000000\n",
      "mean     0.683168\n",
      "std      0.466011\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      1.000000\n",
      "75%      1.000000\n",
      "max      1.000000\n",
      "cp\n",
      "               cp\n",
      "count  303.000000\n",
      "mean     0.966997\n",
      "std      1.032052\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      1.000000\n",
      "75%      2.000000\n",
      "max      3.000000\n",
      "trtbps\n",
      "           trtbps\n",
      "count  303.000000\n",
      "mean   131.623762\n",
      "std     17.538143\n",
      "min     94.000000\n",
      "25%    120.000000\n",
      "50%    130.000000\n",
      "75%    140.000000\n",
      "max    200.000000\n",
      "chol\n",
      "             chol\n",
      "count  303.000000\n",
      "mean   246.264026\n",
      "std     51.830751\n",
      "min    126.000000\n",
      "25%    211.000000\n",
      "50%    240.000000\n",
      "75%    274.500000\n",
      "max    564.000000\n",
      "fbs\n",
      "              fbs\n",
      "count  303.000000\n",
      "mean     0.148515\n",
      "std      0.356198\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%      0.000000\n",
      "max      1.000000\n",
      "restecg\n",
      "          restecg\n",
      "count  303.000000\n",
      "mean     0.528053\n",
      "std      0.525860\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      1.000000\n",
      "75%      1.000000\n",
      "max      2.000000\n",
      "thalachh\n",
      "         thalachh\n",
      "count  303.000000\n",
      "mean   149.646865\n",
      "std     22.905161\n",
      "min     71.000000\n",
      "25%    133.500000\n",
      "50%    153.000000\n",
      "75%    166.000000\n",
      "max    202.000000\n",
      "exng\n",
      "             exng\n",
      "count  303.000000\n",
      "mean     0.326733\n",
      "std      0.469794\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%      1.000000\n",
      "max      1.000000\n",
      "oldpeak\n",
      "          oldpeak\n",
      "count  303.000000\n",
      "mean     1.039604\n",
      "std      1.161075\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.800000\n",
      "75%      1.600000\n",
      "max      6.200000\n",
      "slp\n",
      "              slp\n",
      "count  303.000000\n",
      "mean     1.399340\n",
      "std      0.616226\n",
      "min      0.000000\n",
      "25%      1.000000\n",
      "50%      1.000000\n",
      "75%      2.000000\n",
      "max      2.000000\n",
      "caa\n",
      "              caa\n",
      "count  303.000000\n",
      "mean     0.729373\n",
      "std      1.022606\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%      1.000000\n",
      "max      4.000000\n",
      "thall\n",
      "            thall\n",
      "count  303.000000\n",
      "mean     2.313531\n",
      "std      0.612277\n",
      "min      0.000000\n",
      "25%      2.000000\n",
      "50%      2.000000\n",
      "75%      3.000000\n",
      "max      3.000000\n",
      "output\n",
      "           output\n",
      "count  303.000000\n",
      "mean     0.544554\n",
      "std      0.498835\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      1.000000\n",
      "75%      1.000000\n",
      "max      1.000000\n"
     ]
    }
   ],
   "source": [
    "for i in dataSet.columns:\n",
    "    print(i)\n",
    "    print(dataSet[i].to_frame().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "注意，做测试的情况要处理顺序问题，即，要打乱顺序.原始数据在target的结果集上是有顺序的，先1后0，需要打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "187   54    1   0     124   266    0        0       109     1      2.2    1   \n",
       "89    58    0   0     100   248    0        0       122     0      1.0    1   \n",
       "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "190   51    0   0     130   305    0        1       142     1      1.2    1   \n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
       "267   49    1   2     118   149    0        0       126     0      0.8    2   \n",
       "103   42    1   2     120   240    1        1       194     0      0.8    0   \n",
       "24    40    1   3     140   199    0        1       178     1      1.4    2   \n",
       "164   38    1   2     138   175    0        1       173     0      0.0    2   \n",
       "97    52    1   0     108   233    1        1       147     0      0.1    2   \n",
       "\n",
       "     caa  thall  output  \n",
       "3      0      2       1  \n",
       "187    1      3       0  \n",
       "89     0      2       1  \n",
       "1      0      2       1  \n",
       "190    0      3       0  \n",
       "..   ...    ...     ...  \n",
       "267    3      2       0  \n",
       "103    0      3       1  \n",
       "24     0      3       1  \n",
       "164    4      2       1  \n",
       "97     3      3       1  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "dataSet = shuffle(dataSet)\n",
    "dataSet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据总体完善，无异常值，可以进行直接选择处理,先分割成训练集和测试集,总共300多条数据，我们选择260条作为训练集，最后40条作为测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataSet_train = dataSet[:260]\n",
    "dataSet_test =  dataSet[260:]\n",
    "\n",
    "# 训练集\n",
    "y_data_train = dataSet_train['output']\n",
    "# print(y_data)\n",
    "x_data_train = dataSet_train.iloc[:,:-1]\n",
    "\n",
    "# 测试集\n",
    "y_data_test = dataSet_test['output']\n",
    "\n",
    "x_data_test = dataSet_test.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1 KNN\n",
    "\n",
    "KNN：通过计算待分类数据点，与已有数据集中的所有数据点的距离。\n",
    "\n",
    "取距离最小的前K个点，根据“少数服从多数“的原则，将这个数据点划分为出现次数最多的那个类别。\n",
    "\n",
    "### sklearn 的 KNN\n",
    "\n",
    "**sklearn中的K近邻分类器**\n",
    "\n",
    "在sklearn库中，可以使用sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "创建一个K近邻分类器，主要参数有：\n",
    "\n",
    "    • n_neighbors：用于指定分类器中K的大小(默认值为5，注意与kmeans的区别)\n",
    "\n",
    "    • weights：设置选中的K个点对分类结果影响的权重（默认值为平均权重“uniform”，可以选择“distance”代表越近的点权重越高，或者传入自己编写的以距离为参数的权重计算函数）\n",
    "\n",
    "    • algorithm：设置用于计算临近点的方法，因为当数据量很大的情况下计算当前点和所有点的距离再选出最近的k各点，这个计算量是很费时的，所以（选项中有ball_tree、kd_tree和brute，分别代表不同的寻找邻居的优化算法，默认值为auto，根据训练数据自动选择）\n",
    "\n",
    "#### K近邻分类器的使用\n",
    "\n",
    "例子：\n",
    "I 创建一组数据 X 和它对应的标签 y：\n",
    "\n",
    "x = [[0], [1], [2], [3]]\n",
    "\n",
    "y = [0, 0, 1, 1]\n",
    "\n",
    "II 使用 import 语句导入 K 近邻分类器\n",
    "\n",
    "III 参数 n_neighbors 设置为 3，即使用最近的3个邻居作为分类的依据，其他参\n",
    "数保持默认值，并将创建好的实例赋给变量 neigh。\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "IV 调用 fit() 函数，将训练数据 X 和 标签 y 送入分类器进行学习。\n",
    "\n",
    "neigh.fit(X, y)\n",
    "\n",
    "V 调用 predict() 函数，对未知分类样本 [1.1] 分类，可以直接并将需要分类\n",
    "的数据构造为数组形式作为参数传入，得到分类标签作为返回值。\n",
    "\n",
    "**print(neigh.predict([[1.1]]))**\n",
    "\n",
    "样例输出值是 0，表示K近邻分类器通过计算样本 [1.1] 与训练数据的距离，\n",
    "取 0,1,2 这 3 个邻居作为依据，根据“投票法”最终将样本分为类别 0。\n",
    "\n",
    "#### KNN 选择经验\n",
    "\n",
    "在实际使用时，我们可以使用所有训练数据构成特征 X 和标签 y，\n",
    "使用fit() 函数进行训练。在正式分类时，\n",
    "通过一次性构造测试集或者一个一个输入样本的方式，得到样本对应的分类结果。\n",
    "\n",
    "有关K的取值：\n",
    "\n",
    "    • 如果较大，相当于使用较大邻域中的训练实例进行预测，可以减小估计误差，但是距离较远的样本也会对预测起作用，导致预测错误。\n",
    "    • 相反地，如果 K 较小，相当于使用较小的邻域进行预测，如果邻居恰好是噪声点，会导致过拟合。\n",
    "    • 一般情况下，K 会倾向选取较小的值，并使用交叉验证法选取最优 K 值\n",
    "下面我们进行实战操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction All Done!\n",
      "\n",
      "\n",
      "The classification report for knn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.53      0.51        17\n",
      "           1       0.68      0.65      0.67        26\n",
      "\n",
      "    accuracy                           0.60        43\n",
      "   macro avg       0.59      0.59      0.59        43\n",
      "weighted avg       0.61      0.60      0.61        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report # 结果预测评估模块\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn = knn.fit(x_data_train, y_data_train)\n",
    "\n",
    "answer_knn = knn.predict(x_data_test)\n",
    "print(\"Prediction All Done!\")\n",
    "\n",
    "print('\\n\\nThe classification report for knn:')\n",
    "print(classification_report(y_data_test, answer_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在再来尝试一下标准化参考看一下效果.\n",
    "\n",
    "标准化的目的与归一化一样，都是为了避免某个特征的重要程度过大或过小。\n",
    "\n",
    "标准化的优点：受异常点的影响较小。 适用于繁杂大数据。\n",
    "\n",
    "这里用到了\n",
    "**from sklearn.preprocessing import StandardScaler**方法实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction All Done!\n",
      "\n",
      "\n",
      "The classification report for knn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69        17\n",
      "           1       0.79      0.85      0.81        26\n",
      "\n",
      "    accuracy                           0.77        43\n",
      "   macro avg       0.76      0.75      0.75        43\n",
      "weighted avg       0.77      0.77      0.76        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler#用于对数据进行标准化操作\n",
    "dataSet_xtrain_std = StandardScaler().fit_transform(x_data_train)\n",
    "dataSet_xtest_std = StandardScaler().fit_transform(x_data_test)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report # 结果预测评估模块\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn = knn.fit(dataSet_xtrain_std, y_data_train)\n",
    "\n",
    "answer_knn = knn.predict(dataSet_xtest_std)\n",
    "print(\"Prediction All Done!\")\n",
    "\n",
    "print('\\n\\nThe classification report for knn:')\n",
    "print(classification_report(y_data_test, answer_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很明显，得到的测试集成功率比之前的更高了，当然每次训练得到的数据结果不尽相同，\n",
    "\n",
    "这是因为：\n",
    "\n",
    "初试位置选择不同算法收敛到不同结果。\n",
    "\n",
    "我们尝试使用knn参数 n_neighbors，即用于指定分类器中K的大小调整再查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction All Done!\n",
      "\n",
      "\n",
      "The classification report for knn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72        17\n",
      "           1       0.83      0.77      0.80        26\n",
      "\n",
      "    accuracy                           0.77        43\n",
      "   macro avg       0.76      0.77      0.76        43\n",
      "weighted avg       0.77      0.77      0.77        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(6)\n",
    "\n",
    "knn = knn.fit(dataSet_xtrain_std, y_data_train)\n",
    "\n",
    "answer_knn = knn.predict(dataSet_xtest_std)\n",
    "print(\"Prediction All Done!\")\n",
    "\n",
    "print('\\n\\nThe classification report for knn:')\n",
    "print(classification_report(y_data_test, answer_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN 优缺点：\n",
    "\n",
    "优点：\n",
    "\n",
    "    ① 简单，易于理解，易于实现，无需参数估计，无需训练;\n",
    "    ② 对异常值不敏感（个别噪音数据对结果的影响不是很大）;\n",
    "    ③ 适合对稀有事件进行分类;\n",
    "    ④ 适合于多分类问题(multi-modal,对象具有多个类别标签)，KNN要比SVM表现要好;\n",
    "\n",
    "缺点：\n",
    "\n",
    "    ① 对测试样本分类时的计算量大，内存开销大，因为对每一个待分类的文本都要计算它到全体已知样本的距离，才能求得它的K个最近邻点。目前常用的解决方法是事先对已知样本点进行剪辑，事先去除对分类作用不大的样本; \n",
    "    ② 可解释性差，无法告诉你哪个变量更重要，无法给出决策树那样的规则；\n",
    "    ③ K值的选择：最大的缺点是当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数。该算法只计算“最近的”邻居样本，某一类的样本数量很大，那么或者这类样本并不接近目标样本，或者这类样本很靠近目标样本。无论怎样，数量并不能影响运行结果。可以采用权值的方法（和该样本距离小的邻居权值大）来改进; \n",
    "    ④ KNN是一种消极学习方法、懒惰算法。\n",
    "\n",
    "## 2 决策树\n",
    "\n",
    "决策树是一种树形结构的分类器，\n",
    "通过顺序询问分类点的属性决定分类点最终的类别。\n",
    "\n",
    "通常根据特征的信息增益或其他指标，构建一颗决策树。\n",
    "\n",
    "在分类时，只需要按照决策树中的结点依次进行判断，即可得到样本所属类别。\n",
    "\n",
    "例如，根据下图这个构造好的分类决策树，\n",
    "一个无房产，单身，年收入55K的人的会被归入无法偿还信用卡这个类别。\n",
    "\n",
    "![](Pic/Dis.JPG)\n",
    "\n",
    "### sklearn 中的决策树\n",
    "\n",
    "在sklearn库中，可以使用**sklearn.tree.DecisionTreeClassifier**创建一个决策树用于分类，其主要参数有：\n",
    "\n",
    "    criterion ：用于选择属性的准则，可以传入“gini”代表基尼系数，或者“entropy”代表信息增益。\n",
    "    max_features ：表示在决策树结点进行分裂时，从多少个特征中选择最优特征。可以设定固定数目、百分比或其他标准。它的默认值是使用所有特征个数。\n",
    "\n",
    "下面使用简单示例（鸢尾花数据）展现相关决策树的分类状态，并尝试交叉验证技术"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # 鸢尾花数据集\n",
    "from sklearn.tree import DecisionTreeClassifier # 决策树分类器\n",
    "from sklearn.model_selection import cross_val_score # 交叉验证数据集的技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面进行决策树的使用.\n",
    "\n",
    "这里我们将决策树分类器做为待评估的模型，\n",
    "iris.data鸢尾花数据做为特征，\n",
    "\n",
    "iris.target鸢尾花分类标签做为目标结果，通过设定cv为10，使用10折交叉验证。得到最终的交叉验证得分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "       0.86666667, 0.93333333, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "irs = load_iris()\n",
    "k = cross_val_score(clf, irs.data, irs.target, cv=10)\n",
    "# clf.fit()\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "以仿照之前 K近邻分类器的使用方法，利用 fit() 函数训练模型并使用predict() 函数预测：\n",
    "\n",
    "决策树本质上是寻找一种对特征空间上的划分，旨在构建一个训练数据拟合的好，并且复杂度小的决策树。\n",
    "\n",
    "• 在实际使用中，需要根据数据情况，调整DecisionTreeClassifier类中传入的参数，比如选择合适的criterion，设置随机变量等。\n",
    "\n",
    "下面我们尝试对上述的心脏病数据进行决策树分类挖掘，同上，我们对标准化和非标准化进行分开分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction All Done!\n",
      "\n",
      "\n",
      "The classification report for DecisionTree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.65      0.73        17\n",
      "           1       0.80      0.92      0.86        26\n",
      "\n",
      "    accuracy                           0.81        43\n",
      "   macro avg       0.82      0.79      0.80        43\n",
      "weighted avg       0.82      0.81      0.81        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 非标准化\n",
    "from sklearn.tree import DecisionTreeClassifier # 决策树分类器\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "dtree = dtree.fit(x_data_train, y_data_train)\n",
    "\n",
    "answer_dtree = dtree.predict(x_data_test)\n",
    "print(\"Prediction All Done!\")\n",
    "\n",
    "print('\\n\\nThe classification report for DecisionTree:')\n",
    "print(classification_report(y_data_test, answer_dtree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同上，进行标准化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction All Done!\n",
      "\n",
      "\n",
      "The classification report for DecisionTree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69        17\n",
      "           1       0.79      0.85      0.81        26\n",
      "\n",
      "    accuracy                           0.77        43\n",
      "   macro avg       0.76      0.75      0.75        43\n",
      "weighted avg       0.77      0.77      0.76        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 标准化后的结果\n",
    "dtree = dtree.fit(dataSet_xtrain_std, y_data_train)\n",
    "\n",
    "answer_dtree = dtree.predict(dataSet_xtest_std)\n",
    "print(\"Prediction All Done!\")\n",
    "\n",
    "print('\\n\\nThe classification report for DecisionTree:')\n",
    "print(classification_report(y_data_test, answer_dtree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树是一种典型的分类方法\n",
    "\n",
    "    1.首先对数据进行处理，利用归纳算法生成可读的规则和决策树\n",
    "    2.然后使用决策对新数据进行分析\n",
    "本质上决策树是通过一系列规则对数据进行分类的过程\n",
    "\n",
    "### 决策树算法的优点\n",
    "1、推理过程容易理解，决策推理过程可以表示为If — Then 形式；\n",
    "2、推理过程完全依赖于属性变量的取值特点；\n",
    "3、可自动忽略目标变量没有贡献的属性变量，也为判断属性变量的重要性，减少变量的数据提供参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 朴素贝叶斯\n",
    "\n",
    "朴素贝叶斯分类器是一个以贝叶斯定理为基础的多分类的分类器。\n",
    "\n",
    "对于给定数据，首先基于特征的条件独立性假设，学习输入输出的联合概率分布，\n",
    "\n",
    "然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。\n",
    "\n",
    "![](Pic/bays.JPG)\n",
    "\n",
    "### sklearn 中的朴素贝叶斯\n",
    "\n",
    "在sklearn库中，实现了三个朴素贝叶斯分类器，如下表所示\n",
    "\n",
    "![](Pic/baysTB.JPG)\n",
    "\n",
    "在sklearn库中，可以使用sklearn.naive_bayes.GaussianNB创建一个高斯朴素贝叶斯分类器，\n",
    "\n",
    "其参数有：\n",
    "\n",
    "• priors ：给定各个类别的先验概率。如果为空，则按训练数据的实际情况进行统计；如果给定先验概率，则在训练过程中不能更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  # 高斯朴素贝叶斯分类器\n",
    "import numpy as np\n",
    "X =  np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y =  np.array([1, 1, 1, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用默认参数，创建一个高斯朴素贝叶斯分类器，并将该分类器赋给变量clf。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf = GaussianNB(priors=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似的，使用 fit() 函数进行训练，并使用 predict() 函数进行预测，得到\n",
    "预测结果为 1。（测试时可以构造二维数组达到同时预测多个样本的目的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X,Y)\n",
    "print(clf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 总结：\n",
    "朴素贝叶斯是典型的生成学习方法，由训练数据学习联合概率分布，并求得后验概率分布。\n",
    "\n",
    "朴素贝叶斯一般在小规模数据上的表现很好，适合进行多分类任务\n",
    "\n",
    "下面我们尝试对上述的心脏病数据进行朴素贝叶斯分类挖掘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction All Done!\n",
      "\n",
      "\n",
      "The classification report for GaussianNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.65      0.42        17\n",
      "           1       0.14      0.04      0.06        26\n",
      "\n",
      "    accuracy                           0.28        43\n",
      "   macro avg       0.22      0.34      0.24        43\n",
      "weighted avg       0.21      0.28      0.20        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  # 高斯朴素贝叶斯分类器\n",
    "gNB = GaussianNB()\n",
    "\n",
    "gNB = gNB.fit(x_data_train, y_data_train)\n",
    "\n",
    "answer_gNB = dtree.predict(x_data_test)\n",
    "print(\"Prediction All Done!\")\n",
    "\n",
    "print('\\n\\nThe classification report for GaussianNB:')\n",
    "print(classification_report(y_data_test, answer_gNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction All Done!\n",
      "\n",
      "\n",
      "The classification report for GaussianNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.65      0.42        17\n",
      "           1       0.14      0.04      0.06        26\n",
      "\n",
      "    accuracy                           0.28        43\n",
      "   macro avg       0.22      0.34      0.24        43\n",
      "weighted avg       0.21      0.28      0.20        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB  # 高斯朴素贝叶斯分类器\n",
    "gNB = BernoulliNB()\n",
    "\n",
    "gNB = gNB.fit(x_data_train, y_data_train)\n",
    "\n",
    "answer_gNB = dtree.predict(x_data_test)\n",
    "print(\"Prediction All Done!\")\n",
    "\n",
    "print('\\n\\nThe classification report for GaussianNB:')\n",
    "print(classification_report(y_data_test, answer_gNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "同样，我们尝试对文本进行先标准化再去做机器学习，查看相关的数据模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction All Done!\n",
      "\n",
      "\n",
      "The classification report for DecisionTree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        17\n",
      "           1       0.85      0.85      0.85        26\n",
      "\n",
      "    accuracy                           0.81        43\n",
      "   macro avg       0.81      0.81      0.81        43\n",
      "weighted avg       0.81      0.81      0.81        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gNB = gNB.fit(dataSet_xtrain_std, y_data_train)\n",
    "\n",
    "answer_gNB = gNB.predict(dataSet_xtest_std)\n",
    "print(\"Prediction All Done!\")\n",
    "\n",
    "print('\\n\\nThe classification report for DecisionTree:')\n",
    "print(classification_report(y_data_test, answer_gNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "接下来我们尝试对数据集进行交叉验证技术再进行操作,分别做KNN、决策树、贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  31  32  33  35  36  37  39\n",
      "  40  41  42  43  44  47  49  51  52  53  54  55  58  59  60  61  62  63\n",
      "  64  65  68  69  70  71  72  74  75  77  78  79  80  81  82  83  84  85\n",
      "  86  87  88  89  90  91  92  93  94  95  96  97  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 116 117 118 119 122 125 126 127\n",
      " 128 129 130 131 132 133 134 135 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149 151 152 153 154 155 156 157 158 159 160 161 162 164 166 167\n",
      " 168 170 171 172 173 174 175 176 178 179 180 181 182 183 184 185 186 187\n",
      " 188 189 190 191 193 194 195 196 197 198 199 200 201 202 204 205 206 207\n",
      " 208 210 211 212 213 214 215 216 218 219 220 221 222 223 224 225 226 227\n",
      " 229 230 231 232 233 234 236 237 238 239 241 242 243 244 245 246 247 248\n",
      " 249 250 251 252 253 254 255 256 257 258 260 261 262 263 264 265 266 267\n",
      " 268 269 270 271 274 275 276 277 278 279 280 281 283 284 285 286 287 288\n",
      " 289 290 291 292 293 295 296 297 298 299 300 301 302] \n",
      "TEST: [ 12  30  34  38  45  46  48  50  56  57  66  67  73  76  98 115 120 121\n",
      " 123 124 136 150 163 165 169 177 192 203 209 217 228 235 240 259 272 273\n",
      " 282 294]\n",
      "TRAIN: [  0   1   2   4   5   6   7   8   9  12  13  14  15  17  19  20  21  22\n",
      "  23  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n",
      "  43  44  45  46  47  48  50  52  53  54  55  56  57  58  59  60  61  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  88  89  91  92  94  95  96  97  98  99 100 101 102\n",
      " 103 104 105 106 107 109 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 131 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 147 148 150 151 152 153 155 156 157 158 160 161 162 163 164 165\n",
      " 166 168 169 170 171 172 173 174 175 176 177 179 180 181 182 183 184 185\n",
      " 186 187 188 189 190 191 192 193 195 196 197 198 200 201 202 203 204 205\n",
      " 208 209 210 211 212 214 215 216 217 218 219 220 221 222 223 225 226 227\n",
      " 228 229 230 231 232 233 235 236 237 238 240 242 243 244 245 246 247 248\n",
      " 249 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267\n",
      " 268 269 270 271 272 273 274 275 277 279 281 282 283 284 285 286 288 289\n",
      " 290 291 292 293 294 295 296 297 298 299 300 301 302] \n",
      "TEST: [  3  10  11  16  18  24  25  49  51  62  87  90  93 108 110 130 132 133\n",
      " 146 149 154 159 167 178 194 199 206 207 213 224 234 239 241 250 276 278\n",
      " 280 287]\n",
      "TRAIN: [  1   2   3   5   6   7   8   9  10  11  12  13  14  15  16  17  18  20\n",
      "  21  22  23  24  25  26  27  28  29  30  31  33  34  35  36  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  54  55  56  57  58  59\n",
      "  61  62  63  64  65  66  67  68  69  70  72  73  74  75  76  77  78  79\n",
      "  80  81  82  83  84  85  86  87  88  89  90  91  92  93  95  96  97  98\n",
      "  99 100 101 102 104 106 107 108 109 110 111 113 114 115 116 117 119 120\n",
      " 121 122 123 124 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
      " 140 141 142 144 146 147 148 149 150 151 154 155 157 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 173 174 175 176 177 178 179 180 181 182 183\n",
      " 184 185 186 188 190 191 192 194 196 197 198 199 200 201 203 204 205 206\n",
      " 207 208 209 210 211 213 214 215 216 217 218 219 220 221 222 223 224 225\n",
      " 226 228 229 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 264\n",
      " 266 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 285\n",
      " 286 287 291 292 293 294 295 296 297 298 299 301 302] \n",
      "TEST: [  0   4  19  32  37  53  60  71  94 103 105 112 118 125 143 145 152 153\n",
      " 156 158 171 172 187 189 193 195 202 212 227 230 263 265 267 284 288 289\n",
      " 290 300]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  18\n",
      "  19  20  21  22  23  24  25  26  27  30  32  33  34  36  37  38  40  41\n",
      "  42  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  62  63  64  65  66  67  68  69  71  72  73  74  76  77  79  80  81  83\n",
      "  84  85  86  87  88  89  90  92  93  94  96  97  98  99 101 102 103 104\n",
      " 105 106 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 130 132 133 134 135 136 140 141 142 143 144 145 146\n",
      " 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164\n",
      " 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 182 183\n",
      " 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201\n",
      " 202 203 206 207 208 209 210 211 212 213 215 216 217 218 219 221 223 224\n",
      " 226 227 228 229 230 231 233 234 235 236 238 239 240 241 242 243 245 246\n",
      " 247 248 249 250 251 252 254 256 257 258 259 261 262 263 264 265 266 267\n",
      " 269 270 271 272 273 274 275 276 278 279 280 282 283 284 285 286 287 288\n",
      " 289 290 291 292 293 294 295 296 298 299 300 301 302] \n",
      "TEST: [ 17  28  29  31  35  39  43  61  70  75  78  82  91  95 100 107 129 131\n",
      " 137 138 139 181 204 205 214 220 222 225 232 237 244 253 255 260 268 277\n",
      " 281 297]\n",
      "TRAIN: [  0   2   3   4   5   7   8   9  10  11  12  13  16  17  18  19  20  21\n",
      "  22  24  25  26  28  29  30  31  32  33  34  35  37  38  39  40  41  43\n",
      "  45  46  47  48  49  50  51  52  53  55  56  57  58  59  60  61  62  63\n",
      "  65  66  67  68  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  87  88  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n",
      " 104 105 107 108 110 111 112 113 114 115 117 118 119 120 121 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 142 143 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 158 159 160 162 163 165 166\n",
      " 167 168 169 171 172 173 174 175 176 177 178 179 180 181 182 183 185 186\n",
      " 187 189 190 192 193 194 195 197 198 199 200 201 202 203 204 205 206 207\n",
      " 208 209 210 211 212 213 214 215 217 218 219 220 221 222 223 224 225 226\n",
      " 227 228 229 230 231 232 233 234 235 237 238 239 240 241 242 243 244 245\n",
      " 247 248 249 250 251 252 253 254 255 257 258 259 260 261 262 263 264 265\n",
      " 267 268 269 270 271 272 273 274 276 277 278 280 281 282 283 284 285 287\n",
      " 288 289 290 291 293 294 295 296 297 298 299 300 302] \n",
      "TEST: [  1   6  14  15  23  27  36  42  44  54  64  69  86  89 106 109 116 122\n",
      " 141 144 157 161 164 170 184 188 191 196 216 236 246 256 266 275 279 286\n",
      " 292 301]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  80  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  98  99 100 101 102 103 105 106 107 108 109 110 111 112 114 115\n",
      " 116 117 118 119 120 121 122 123 124 125 126 127 129 130 131 132 133 134\n",
      " 136 137 138 139 140 141 143 144 145 146 149 150 151 152 153 154 155 156\n",
      " 157 158 159 160 161 162 163 164 165 167 168 169 170 171 172 173 174 177\n",
      " 178 181 184 185 186 187 188 189 191 192 193 194 195 196 197 199 200 202\n",
      " 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 220 221 222\n",
      " 223 224 225 226 227 228 229 230 232 233 234 235 236 237 238 239 240 241\n",
      " 244 245 246 247 248 250 251 252 253 254 255 256 257 258 259 260 262 263\n",
      " 265 266 267 268 272 273 274 275 276 277 278 279 280 281 282 283 284 285\n",
      " 286 287 288 289 290 292 293 294 295 297 299 300 301] \n",
      "TEST: [ 26  58  59  79  81  97 104 113 128 135 142 147 148 166 175 176 179 180\n",
      " 182 183 190 198 201 218 219 231 242 243 249 261 264 269 270 271 291 296\n",
      " 298 302]\n",
      "TRAIN: [  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  21  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39\n",
      "  41  42  43  44  45  46  48  49  50  51  52  53  54  56  57  58  59  60\n",
      "  61  62  63  64  65  66  67  69  70  71  73  75  76  78  79  80  81  82\n",
      "  86  87  89  90  91  92  93  94  95  97  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 115 116 118 120 121 122 123 124 125 127\n",
      " 128 129 130 131 132 133 134 135 136 137 138 139 141 142 143 144 145 146\n",
      " 147 148 149 150 152 153 154 155 156 157 158 159 161 162 163 164 165 166\n",
      " 167 169 170 171 172 174 175 176 177 178 179 180 181 182 183 184 187 188\n",
      " 189 190 191 192 193 194 195 196 198 199 200 201 202 203 204 205 206 207\n",
      " 208 209 212 213 214 216 217 218 219 220 221 222 224 225 226 227 228 229\n",
      " 230 231 232 234 235 236 237 238 239 240 241 242 243 244 245 246 247 249\n",
      " 250 251 252 253 254 255 256 258 259 260 261 262 263 264 265 266 267 268\n",
      " 269 270 271 272 273 274 275 276 277 278 279 280 281 282 284 285 286 287\n",
      " 288 289 290 291 292 294 295 296 297 298 300 301 302] \n",
      "TEST: [  2  20  22  33  40  47  55  68  72  74  77  83  84  85  88  96 114 117\n",
      " 119 126 140 151 160 168 173 185 186 197 210 211 215 223 233 248 257 283\n",
      " 293 299]\n",
      "TRAIN: [  0   1   2   3   4   6  10  11  12  14  15  16  17  18  19  20  22  23\n",
      "  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  42\n",
      "  43  44  45  46  47  48  49  50  51  53  54  55  56  57  58  59  60  61\n",
      "  62  64  66  67  68  69  70  71  72  73  74  75  76  77  78  79  81  82\n",
      "  83  84  85  86  87  88  89  90  91  93  94  95  96  97  98 100 103 104\n",
      " 105 106 107 108 109 110 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 128 129 130 131 132 133 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 156 157 158 159 160 161 163\n",
      " 164 165 166 167 168 169 170 171 172 173 175 176 177 178 179 180 181 182\n",
      " 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 201\n",
      " 202 203 204 205 206 207 209 210 211 212 213 214 215 216 217 218 219 220\n",
      " 222 223 224 225 227 228 230 231 232 233 234 235 236 237 239 240 241 242\n",
      " 243 244 246 248 249 250 253 255 256 257 259 260 261 263 264 265 266 267\n",
      " 268 269 270 271 272 273 275 276 277 278 279 280 281 282 283 284 286 287\n",
      " 288 289 290 291 292 293 294 296 297 298 299 300 301 302] \n",
      "TEST: [  5   7   8   9  13  21  41  52  63  65  80  92  99 101 102 111 127 134\n",
      " 155 162 174 200 208 221 226 229 238 245 247 251 252 254 258 262 274 285\n",
      " 295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training knn\n",
      "Training done\n",
      "Prediction done\n",
      "Start training DT\n",
      "Training done\n",
      "Prediction done\n",
      "Start training Bayes\n",
      "Training done\n",
      "Prediction done\n",
      "\n",
      "\n",
      "The classification report for knn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24        17\n",
      "           1       0.38      0.40      0.39        20\n",
      "\n",
      "    accuracy                           0.32        37\n",
      "   macro avg       0.32      0.32      0.32        37\n",
      "weighted avg       0.32      0.32      0.32        37\n",
      "\n",
      "\n",
      "\n",
      "The classification report for DT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.24      0.26        17\n",
      "           1       0.43      0.50      0.47        20\n",
      "\n",
      "    accuracy                           0.38        37\n",
      "   macro avg       0.36      0.37      0.36        37\n",
      "weighted avg       0.37      0.38      0.37        37\n",
      "\n",
      "\n",
      "\n",
      "The classification report for Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.35      0.35        17\n",
      "           1       0.45      0.45      0.45        20\n",
      "\n",
      "    accuracy                           0.41        37\n",
      "   macro avg       0.40      0.40      0.40        37\n",
      "weighted avg       0.41      0.41      0.41        37\n",
      "\n",
      "KNN精确度： 0.32432432432432434\n",
      "决策树精确度： 0.3783783783783784\n",
      "高斯贝叶斯精确度： 0.40540540540540543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler # 用于对数据进行标准化操作\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=8,shuffle=True, random_state=2021)\n",
    "y = dataSet['output']\n",
    "# print(y_data)\n",
    "x = dataSet.iloc[:,:-1]\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    print('TRAIN:', train_index, \"\\nTEST:\", test_index)\n",
    "#     .iloc[train_index,:]\n",
    "    X_train, X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train = StandardScaler().fit_transform(X_train)\n",
    "    X_test = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Start training knn')\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "print('Training done')\n",
    "answer_knn = knn.predict(X_test)\n",
    "print('Prediction done')\n",
    "\n",
    "print('Start training DT')\n",
    "dt = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print('Training done')\n",
    "answer_dt = dt.predict(X_test)\n",
    "print('Prediction done')\n",
    "\n",
    "print('Start training Bayes')\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "print('Training done')\n",
    "answer_gnb = gnb.predict(X_test)\n",
    "print('Prediction done')\n",
    "\n",
    "print('\\n\\nThe classification report for knn:')\n",
    "print(classification_report(y_test, answer_knn))\n",
    "print('\\n\\nThe classification report for DT:')\n",
    "print(classification_report(y_test, answer_dt))\n",
    "print('\\n\\nThe classification report for Bayes:')\n",
    "print(classification_report(y_test, answer_gnb))\n",
    "\n",
    "KNNscore = knn.score(X_test, y_test)\n",
    "\n",
    "print(\"KNN精确度：\",KNNscore)\n",
    "Tscore = dt.score(X_test, y_test)\n",
    "\n",
    "print(\"决策树精确度：\",Tscore)\n",
    "GSscore = gnb.score(X_test, y_test)\n",
    "print(\"高斯贝叶斯精确度：\",GSscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次的数据是两类的划分相关，主要还是不适合贝叶斯分析的分类技术，总体相对分类的结果也是不确定，\n",
    "可能准确度会低于前两种。\n",
    "\n",
    "## SVM 支持向量机\n",
    "支持向量机（support vector machines）是一种二分类模型，它的目的是寻找一个超平面来对样本进行分割，分割的原则是间隔最大化，最终转化为一个凸二次规划问题来求解。由简至繁的模型包括：\n",
    "\n",
    "    当训练样本线性可分时，通过硬间隔最大化，学习一个线性可分支持向量机；\n",
    "    当训练样本近似线性可分时，通过软间隔最大化，学习一个线性支持向量机；\n",
    "    当训练样本线性不可分时，通过核技巧和软间隔最大化，学习一个非线性支持向量机；\n",
    "\n",
    "线性可分支持向量机\n",
    "\n",
    "间隔最大化和支持向量\n",
    "\n",
    "如果一个线性函数能够将样本分开，称这些数据样本是线性可分的。那么什么是线性函数呢？\n",
    "其实很简单，在二维空间中就是一条直线，在三维空间中就是一个平面，\n",
    "以此类推，如果不考虑空间维数，这样的线性函数统称为超平面。\n",
    "O代表正类，X代表负类，样本是线性可分的，但是很显然不只有这一条直线可以将样本分开，\n",
    "而是有无数条，我们所说的线性可分支持向量机就对应着能将数据正确划分并且间隔最大的直线。\n",
    "\n",
    "![](Pic/SVM.JPG)\n",
    "\n",
    "### sklearn 中的SVM\n",
    "\n",
    "**sklearn.svm.SVC(C=1.0,kernel='rbf', degree=3, gamma='auto',coef0=0.0,shrinking=True,probability=False,tol=0.001,cache_size=200, class_weight=None,verbose=False,max_iter=-1,decision_function_shape=None,random_state=None)**\n",
    "\n",
    "    C：C-SVC的惩罚参数，默认值是1.0。C越大，相当于惩罚松弛变量，希望松弛变量接近0，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。\n",
    "    kernel:核函数，默认是rbf，可以是‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "\n",
    "        0– 线性：u’v1– 多项式：(gamma*u’*v + coef0)^degree\n",
    "        2– RBF函数：exp(-gamma|u-v|^2)\n",
    "        3–sigmoid：tanh(gamma*u'*v + coef0)\n",
    "    degree ：多项式poly函数的维度，默认是3，选择其他核函数时会被忽略。\n",
    "    gamma:'rbf','poly' 和‘sigmoid’的核函数参数。默认是'auto'，则会选择1/n_features\n",
    "    coef0:核函数的常数项。对于'poly'和 'sigmoid'有用。\n",
    "    probability ：是否采用概率估计？.默认为False\n",
    "    shrinking ：是否采用shrinking heuristic方法，默认为true\n",
    "\n",
    "注：\n",
    "\n",
    "    kernel='linear'时，为线性核，C越大分类效果越好，但有可能会过拟合（defaul C=1）。\n",
    "    kernel='rbf'时（default），为高斯核，gamma值越小，分类界面越连续；gamma值越大，分类界面越“散”，分类效果越好，但有可能会过拟合。\n",
    "    decision_function_shape='ovr'时，为one v rest，即一个类别与其他类别进行划分，\n",
    "    decision_function_shape='ovo'时，为one v one，即将类别两两之间进行划分，用二分类的方法模拟多分类的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training SVM\n",
      "Prediction All Done!\n",
      "\n",
      "\n",
      "The classification report for DecisionTree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        17\n",
      "           1       0.85      0.85      0.85        26\n",
      "\n",
      "    accuracy                           0.81        43\n",
      "   macro avg       0.81      0.81      0.81        43\n",
      "weighted avg       0.81      0.81      0.81        43\n",
      "\n",
      "SVM精确度： 0.6046511627906976\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(C=0.8, kernel='rbf', gamma=20, decision_function_shape='ovr')\n",
    "# clf.fit(x_train, y_train.ravel())\n",
    "\n",
    "print('Start training SVM')\n",
    "\n",
    "clf = clf.fit(dataSet_xtrain_std, y_data_train)\n",
    "\n",
    "SVMresult = clf.predict(dataSet_xtest_std)\n",
    "print(\"Prediction All Done!\")\n",
    "\n",
    "print('\\n\\nThe classification report for DecisionTree:')\n",
    "print(classification_report(y_data_test, answer_gNB))\n",
    "\n",
    "SVMscore = clf.score(dataSet_xtest_std, y_data_test)\n",
    "print(\"SVM精确度：\",SVMscore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}