{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Charpter 4 Data Cluster and Analization  数据聚类和分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验目的：\n",
    "\n",
    "练习常见聚类分析算法，体会不同聚类算法各自的特点，并学习分析聚类的结果。\n",
    "\n",
    "学习scikit-learn中聚类模块的用法。\n",
    "\n",
    "了解不同聚类方法中不同参数的影响。\n",
    "\n",
    "### 实验介绍：\n",
    "\n",
    "使用KMeans，DBScan，层次聚类，AP聚类算法，\n",
    "\n",
    "设置不同的参数，分别对两组数据进行聚类，比较结果的差别；\n",
    "\n",
    "分析聚类结果，并使用adjusted_rand_score测度来比较不同聚类算法在两个数据集上性能的差异。\n",
    "\n",
    "有关adjusted测度的说明，\n",
    "\n",
    "请参见：\n",
    "\n",
    "[http://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score)\n",
    "\n",
    "本实验采用的数据集为(带有标签的)wine与grass,放在data文件夹下。\n",
    "\n",
    "在挖掘前务必分析数据\n",
    "\n",
    "## A1 聚类\n",
    "\n",
    "聚类(clustering)，就是根据数据的“相似性”将数据分为多类的过程。\n",
    "\n",
    "评估两个不同样本之间的“相似性” ，通常使用的方法就是计算两个样本之间的“距离”。\n",
    "\n",
    "使用不同的方法计算样本间的距离会关系到聚类结果的好坏。\n",
    "\n",
    "相关内容参考: [https://github.com/JunTheRipper/Data-Mining-Access/blob/main/Summary-Of-Machine-Learning/A.unsupervised-learning/A1.clustering.ipynb](https://github.com/JunTheRipper/Data-Mining-Access/blob/main/Summary-Of-Machine-Learning/A.unsupervised-learning/A1.clustering.ipynb)\n",
    "\n",
    "### sklearn.cluster 中的聚类算法\n",
    "\n",
    "scikit-learn库（以后简称sklearn库）提供的常用聚类算法函数包含在\n",
    "\n",
    "sklearn.cluster这个模块中，如：K-Means，\n",
    "近邻传播算法，DBSCAN，等。\n",
    "\n",
    " 以同样的数据集应用于不同的算法，可能会得到不同的结果，算法所耗费的时间也不尽相同，这是由算法的特性决定的。\n",
    "\n",
    "**sklearn.cluster模块提供的各聚类算法函数可以使用不同的数据形式作为输入**\n",
    "\n",
    "标准数据输入格式:[样本个数，特征个数]定义的矩阵形式。\n",
    "\n",
    "相似性矩阵输入格式：即由[样本数目，样本数目]定义的矩阵形式，矩阵中的每一个元素为两个样本的相似度，\n",
    "如DBSCAN， AffinityPropagation(近邻传播算法)接受这种输入。\n",
    "\n",
    "先导入相关的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB A glass\n",
    "\n",
    "玻璃类型分类的研究是由犯罪学调查推动的。在案发现场，留下的玻璃可以作为证据\n",
    "\n",
    "实例数：214\n",
    "\n",
    "属性数：10（包括一个Id#）加上class属性——所有属性都是连续值\n",
    "\n",
    "    1. Id number: 1 to 214\n",
    "    2. RI: refractive index\n",
    "    3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n",
    "    4. Mg: Magnesium\n",
    "    5. Al: Aluminum\n",
    "    6. Si: Silicon\n",
    "    7. K: Potassium\n",
    "    8. Ca: Calcium\n",
    "    9. Ba: Barium\n",
    "    10. Fe: Iron\n",
    "    11. Type of glass: (class attribute)\n",
    "      -- 1 building_windows_float_processed\n",
    "      -- 2 building_windows_non_float_processed\n",
    "      -- 3 vehicle_windows_float_processed\n",
    "      -- 4 vehicle_windows_non_float_processed (none in this database)\n",
    "      -- 5 containers\n",
    "      -- 6 tableware\n",
    "      -- 7 headlamps\n",
    "\n",
    "下面我们读取数据,观察数据发现头部没有相关标签，由于第一列是IDnumber在聚类实验中没有意义，\n",
    "这里我们尝试进行处理，去掉第一列的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210</td>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211</td>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212</td>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213</td>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        1      2     3     4      5     6     7     8    9   10\n",
       "0      1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0   1\n",
       "1      2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0   1\n",
       "2      3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0   1\n",
       "3      4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0   1\n",
       "4      5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0   1\n",
       "..   ...      ...    ...   ...   ...    ...   ...   ...   ...  ...  ..\n",
       "209  210  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0   7\n",
       "210  211  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0   7\n",
       "211  212  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0   7\n",
       "212  213  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0   7\n",
       "213  214  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0   7\n",
       "\n",
       "[214 rows x 11 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_data = pd.read_csv('data/glass/glass.data', header=None)\n",
    "glass_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1      2     3     4      5     6     7     8    9\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0\n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0\n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0\n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0\n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0\n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...  ...\n",
       "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0\n",
       "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0\n",
       "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0\n",
       "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0\n",
       "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0\n",
       "\n",
       "[214 rows x 9 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_data\n",
    "resData = glass_data.iloc[:,1:-1]\n",
    "res_test_y =  glass_data.iloc[:,-1]\n",
    "resData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "209    7\n",
       "210    7\n",
       "211    7\n",
       "212    7\n",
       "213    7\n",
       "Name: 10, Length: 214, dtype: int64"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "\n",
    "去除重复或者缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "9    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resData.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "查看相关的参数信息，包括均值、方差、最大最小值等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.518365</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.057009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.097439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.516523</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.519157</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                1           2           3           4           5           6  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       "25%      1.516523   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       "\n",
       "                7           8           9  \n",
       "count  214.000000  214.000000  214.000000  \n",
       "mean     8.956963    0.175047    0.057009  \n",
       "std      1.423153    0.497219    0.097439  \n",
       "min      5.430000    0.000000    0.000000  \n",
       "25%      8.240000    0.000000    0.000000  \n",
       "50%      8.600000    0.000000    0.000000  \n",
       "75%      9.172500    0.000000    0.100000  \n",
       "max     16.190000    3.150000    0.510000  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "items =  glass_data[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5\n",
      " 1 5 5 1 1 1 5 1 5 1 5 5 5 5 1 1 1 1 1 1 1 1 1 1 5 5 5 5 5 5 5 5 5 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 3 3 3 2 2 3\n",
      " 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 5 1 1 1 1 1 5 1 1 1 1 5 1 2 2 2 2 2 2 2 4 4 2 2 2 5 5 5 5 0 0 2 2 0\n",
      " 1 1 1 5 5 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Expenses:101.45\n",
      "[181, 182, 185, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:101.37\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 45, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 164, 186, 187, 188]\n",
      "Expenses:101.36\n",
      "[109, 110, 130, 131, 165, 166, 167, 168, 169, 170, 171, 174, 175, 176, 183, 184, 202]\n",
      "Expenses:101.44\n",
      "[106, 107, 108, 111, 112, 113, 132]\n",
      "Expenses:101.30\n",
      "[172, 173]\n",
      "Expenses:101.45\n",
      "[1, 18, 19, 22, 37, 39, 40, 44, 46, 48, 49, 50, 51, 62, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 128, 129, 152, 158, 163, 177, 178, 179, 180, 189, 190]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 5,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 5, 5, 1, 1, 1, 5,\n",
       "       1, 5, 1, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 3, 3, 3, 2, 2,\n",
       "       3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 2, 2, 3,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1,\n",
       "       1, 1, 1, 5, 1, 1, 1, 1, 5, 1, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2,\n",
       "       5, 5, 5, 5, 0, 0, 2, 2, 0, 1, 1, 1, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def KMeansData(number):\n",
    "    '''\n",
    "\n",
    "    :param number: int\n",
    "    :return label: list\n",
    "    '''\n",
    "    lab = []\n",
    "    km = KMeans(n_clusters=number)\n",
    "    label = km.fit_predict(resData)\n",
    "    print(label)\n",
    "    expenses = np.sum(km.cluster_centers_,axis=1)\n",
    "    for i in range(number):\n",
    "        eptlists = []\n",
    "        lab.append(eptlists)\n",
    "    for i in range(len(items)):\n",
    "        lab[label[i]].append(items[i])\n",
    "    for i in range(len(lab)):\n",
    "        print(\"Expenses:%.2f\" % expenses[i])\n",
    "        print(lab[i])\n",
    "    return label\n",
    "\n",
    "KMeansData(6)\n",
    "#为每个类的样本创建散点图\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们尝试对k-MEANS聚类进行评估\n",
    "\n",
    "需要的包：sklearn.metrics\n",
    "\n",
    "#### sklearn.metrics.adjusted_rand_score()\n",
    "\n",
    "sklearn.metrics.adjusted_rand_score(labels_true, labels_pred)\n",
    "\n",
    "参考文档:[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html)\n",
    "\n",
    "原理：调整兰德系数 （Adjusted Rand index）\n",
    "\n",
    "设定已知先验知识的标签为labels_true，利用聚类算法预测的样本标签为label_pred，Adjusted Rand index函数是在计算样本预测值和真实值之间的相似度similarity：\n",
    "同属于这一类或都不属于这一类，而不考虑数据元素顺序和归一化。\n",
    "\n",
    "调整adjusted_rand_score函数中labels_true和labels_pred的位置，对结果没有影响。\n",
    "\n",
    "labels_true = [0, 0, 0, 1, 1, 1]\n",
    "\n",
    "labels_pred = [0, 0, 1, 1, 2, 2]\n",
    "\n",
    "labels_pred = [1, 1, 0, 0, 3, 3]\n",
    "\n",
    "后面两个的相关内容变化，调整预测集label_pred中元素0和1的位置，\n",
    "\n",
    "以及将数据集中为2的属性改名为3，不影响实验结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4\n",
      " 1 4 4 1 1 1 4 1 4 1 4 4 4 4 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 3 3 3 5 5 3\n",
      " 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 5 5 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 4 1 1 1 1 1 4 1 1 1 1 4 0 5 5 5 5 5 5 5 0 0 5 5 5 4 4 4 4 2 2 5 5 2\n",
      " 1 0 1 4 4 2 2 2 2 2 2 2 2 2 2 2 5 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Expenses:101.35\n",
      "[164, 172, 173, 187]\n",
      "Expenses:101.37\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 45, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 186, 188]\n",
      "Expenses:101.45\n",
      "[181, 182, 185, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:101.44\n",
      "[106, 107, 108, 111, 112, 113, 132]\n",
      "Expenses:101.45\n",
      "[1, 18, 19, 22, 37, 39, 40, 44, 46, 48, 49, 50, 51, 62, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 128, 129, 152, 158, 163, 177, 178, 179, 180, 189, 190]\n",
      "Expenses:101.36\n",
      "[109, 110, 130, 131, 165, 166, 167, 168, 169, 170, 171, 174, 175, 176, 183, 184, 202]\n",
      "scores:  0.26252788442108294\n",
      "\n",
      "KMEANS time: 0.0846332999999504 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "score = metrics.adjusted_rand_score(KMeansData(6),res_test_y)\n",
    "end = time.perf_counter()\n",
    "print(\"scores: \",score)\n",
    "print(\"\\nKMEANS time:\", end-start ,\"s\")\n",
    "kmeans_time = end - start\n",
    "kmeans_score = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "对于这个聚类的效果，我们可以切换参数观察，但是要验证的话，最好参考真实的分类结果进行测试。\n",
    "\n",
    "得到adjusted_rand_score值大约是0.26到0.27的变动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans neighbor = 2\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Expenses:101.39\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 177, 178, 179, 180, 181, 186, 187, 188, 189, 190, 191]\n",
      "Expenses:101.42\n",
      "[106, 107, 108, 109, 110, 111, 112, 113, 130, 131, 132, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 182, 183, 184, 185, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "\n",
      "score: 0.19261579063649878 \n",
      "\n",
      "kmeans neighbor = 3\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 2\n",
      " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 0 2 2 0 0 2 1 2 1 1 1 1 0 0 2 2 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Expenses:101.44\n",
      "[169, 172, 173, 181, 182, 185, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:101.38\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 175, 177, 178, 179, 180, 186, 187, 188, 189]\n",
      "Expenses:101.39\n",
      "[104, 106, 107, 108, 109, 110, 111, 112, 113, 130, 131, 132, 166, 167, 168, 170, 171, 174, 176, 183, 184]\n",
      "\n",
      "score: 0.22583722451857843 \n",
      "\n",
      "kmeans neighbor = 4\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 2 3\n",
      " 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 3 3 3 2 3 3 1 1 3 0 3 0 0 0 0 2 2 2 2 2\n",
      " 1 1 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2]\n",
      "Expenses:101.38\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 175, 177, 178, 179, 180, 188, 189]\n",
      "Expenses:101.36\n",
      "[164, 172, 173, 186, 187, 208]\n",
      "Expenses:101.43\n",
      "[110, 130, 169, 181, 182, 183, 184, 185, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:101.40\n",
      "[106, 107, 108, 109, 111, 112, 113, 131, 132, 166, 167, 168, 170, 171, 174, 176]\n",
      "\n",
      "score: 0.2465305668878762 \n",
      "\n",
      "kmeans neighbor = 5\n",
      "[0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0\n",
      " 2 0 0 2 2 2 0 2 0 2 0 0 0 0 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 4 4 4 4 4 4\n",
      " 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 2 2 2 0 0 0 0 2 0 3 0 4 4 4 1 4 4 3 3 4 0 4 0 0 0 0 1 1 4 4 1\n",
      " 3 3 2 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Expenses:101.44\n",
      "[1, 18, 19, 22, 37, 39, 40, 44, 46, 48, 49, 50, 51, 62, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 128, 129, 130, 152, 158, 159, 160, 161, 163, 165, 175, 177, 178, 179, 180, 189, 190]\n",
      "Expenses:101.44\n",
      "[169, 181, 182, 185, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:101.37\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 45, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 162, 188]\n",
      "Expenses:101.36\n",
      "[164, 172, 173, 186, 187]\n",
      "Expenses:101.39\n",
      "[106, 107, 108, 109, 110, 111, 112, 113, 131, 132, 166, 167, 168, 170, 171, 174, 176, 183, 184]\n",
      "\n",
      "score: 0.2745688979252487 \n",
      "\n",
      "kmeans neighbor = 6\n",
      "[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
      " 0 4 4 0 0 0 4 0 4 0 4 4 4 4 0 0 0 0 0 0 0 0 0 0 4 4 4 4 4 4 4 4 4 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 2 2 2 5 5 2\n",
      " 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 5 5 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 4 0 0 0 0 0 4 0 4 0 0 4 1 5 5 5 5 5 5 5 1 1 5 5 5 4 4 4 4 3 3 5 5 3\n",
      " 0 1 0 4 4 3 3 3 3 3 3 3 3 3 3 3 5 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Expenses:101.37\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 45, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 161, 162, 186, 188]\n",
      "Expenses:101.35\n",
      "[164, 172, 173, 187]\n",
      "Expenses:101.44\n",
      "[106, 107, 108, 111, 112, 113, 132]\n",
      "Expenses:101.45\n",
      "[181, 182, 185, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:101.45\n",
      "[1, 18, 19, 22, 37, 39, 40, 44, 46, 48, 49, 50, 51, 62, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 128, 129, 152, 158, 160, 163, 177, 178, 179, 180, 189, 190]\n",
      "Expenses:101.36\n",
      "[109, 110, 130, 131, 165, 166, 167, 168, 169, 170, 171, 174, 175, 176, 183, 184, 202]\n",
      "\n",
      "score: 0.26622967036052464 \n",
      "\n",
      "kmeans neighbor = 7\n",
      "[0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0\n",
      " 3 0 0 3 3 3 0 3 0 3 0 0 0 0 3 3 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 5 5 5 1 1 5\n",
      " 5 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 1 1 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 0 3 3 3 3 3 0 3 0 3 3 0 4 1 1 1 1 1 1 1 6 6 1 1 1 0 0 0 0 2 2 1 1 2\n",
      " 4 4 3 0 0 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Expenses:101.45\n",
      "[1, 18, 19, 22, 37, 39, 40, 44, 46, 48, 49, 50, 51, 62, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 128, 129, 152, 158, 160, 163, 177, 178, 179, 180, 189, 190]\n",
      "Expenses:101.36\n",
      "[109, 110, 130, 131, 165, 166, 167, 168, 169, 170, 171, 174, 175, 176, 183, 184, 202]\n",
      "Expenses:101.45\n",
      "[181, 182, 185, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:101.37\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 45, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 161, 162, 188]\n",
      "Expenses:101.40\n",
      "[164, 186, 187]\n",
      "Expenses:101.44\n",
      "[106, 107, 108, 111, 112, 113, 132]\n",
      "Expenses:101.30\n",
      "[172, 173]\n",
      "\n",
      "score: 0.27387616110946666 \n",
      "\n",
      "kmeans neighbor = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
      " 0 4 4 0 0 0 4 0 4 0 4 4 4 4 0 0 0 0 0 0 0 0 0 0 4 4 4 4 4 4 4 4 4 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 7 7 7 2 2 7\n",
      " 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 5 5 2 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 4 0 0 0 0 0 4 0 0 0 0 4 6 5 2 2 2 2 2 2 3 3 2 5 2 5 5 5 5 1 5 2 2 1\n",
      " 6 6 0 5 5 5 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Expenses:101.37\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 45, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 188]\n",
      "Expenses:101.45\n",
      "[181, 185, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:101.35\n",
      "[109, 110, 131, 166, 167, 168, 169, 170, 171, 174, 176, 183, 184, 202]\n",
      "Expenses:101.30\n",
      "[172, 173]\n",
      "Expenses:101.44\n",
      "[1, 18, 19, 22, 37, 39, 40, 44, 46, 48, 49, 50, 51, 62, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 152, 158, 163]\n",
      "Expenses:101.46\n",
      "[128, 129, 130, 165, 175, 177, 178, 179, 180, 182, 189, 190, 191]\n",
      "Expenses:101.40\n",
      "[164, 186, 187]\n",
      "Expenses:101.44\n",
      "[106, 107, 108, 111, 112, 113, 132]\n",
      "\n",
      "score: 0.27928753155331715 \n",
      "\n",
      "kmeans neighbor = 9\n",
      "[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3\n",
      " 0 3 3 0 0 0 3 0 3 0 3 3 3 3 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 6 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 8 8 8 7 7 8\n",
      " 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 3 0 0 0 0 0 3 0 0 0 0 3 6 1 4 4 7 4 7 7 5 5 7 1 7 1 1 1 1 2 1 7 7 2\n",
      " 6 6 0 1 1 1 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Expenses:101.37\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 45, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 188]\n",
      "Expenses:101.46\n",
      "[128, 129, 130, 165, 175, 177, 178, 179, 180, 182, 189, 190, 191]\n",
      "Expenses:101.45\n",
      "[181, 185, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:101.44\n",
      "[1, 18, 19, 22, 37, 39, 40, 44, 46, 48, 49, 50, 51, 62, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 152, 158, 163]\n",
      "Expenses:101.35\n",
      "[166, 167, 169, 202]\n",
      "Expenses:101.30\n",
      "[172, 173]\n",
      "Expenses:101.38\n",
      "[71, 85, 164, 186, 187]\n",
      "Expenses:101.37\n",
      "[109, 110, 131, 132, 168, 170, 171, 174, 176, 183, 184]\n",
      "Expenses:101.42\n",
      "[106, 107, 108, 111, 112, 113]\n",
      "\n",
      "score: 0.26985671470777334 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,10):\n",
    "    print(\"kmeans neighbor =\",i)\n",
    "    print(\"\\nscore:\",metrics.adjusted_rand_score(KMeansData(i),res_test_y),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DBSCAN 密度聚类\n",
    "\n",
    "相关内容参考个人gitHub: [https://github.com/JunTheRipper/Data-Mining-Access/blob/main/Summary-Of-Machine-Learning/A.unsupervised-learning/A1.clustering.ipynb](https://github.com/JunTheRipper/Data-Mining-Access/blob/main/Summary-Of-Machine-Learning/A.unsupervised-learning/A1.clustering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 0.1 min_samples = 5 \t 0.0\n",
      "eps = 0.1 min_samples = 6 \t 0.0\n",
      "eps = 0.1 min_samples = 7 \t 0.0\n",
      "eps = 0.1 min_samples = 8 \t 0.0\n",
      "eps = 0.1 min_samples = 9 \t 0.0\n",
      "eps = 0.1 min_samples = 10 \t 0.0\n",
      "eps = 0.1 min_samples = 11 \t 0.0\n",
      "eps = 0.1 min_samples = 12 \t 0.0\n",
      "eps = 0.1 min_samples = 13 \t 0.0\n",
      "eps = 0.1 min_samples = 14 \t 0.0\n",
      "eps = 0.2 min_samples = 5 \t 0.0\n",
      "eps = 0.2 min_samples = 6 \t 0.0\n",
      "eps = 0.2 min_samples = 7 \t 0.0\n",
      "eps = 0.2 min_samples = 8 \t 0.0\n",
      "eps = 0.2 min_samples = 9 \t 0.0\n",
      "eps = 0.2 min_samples = 10 \t 0.0\n",
      "eps = 0.2 min_samples = 11 \t 0.0\n",
      "eps = 0.2 min_samples = 12 \t 0.0\n",
      "eps = 0.2 min_samples = 13 \t 0.0\n",
      "eps = 0.2 min_samples = 14 \t 0.0\n",
      "eps = 0.30000000000000004 min_samples = 5 \t -0.02676150038391566\n",
      "eps = 0.30000000000000004 min_samples = 6 \t -0.014438454070166638\n",
      "eps = 0.30000000000000004 min_samples = 7 \t 0.0017427499684467618\n",
      "eps = 0.30000000000000004 min_samples = 8 \t -0.0004718252185076546\n",
      "eps = 0.30000000000000004 min_samples = 9 \t 0.01679103028449778\n",
      "eps = 0.30000000000000004 min_samples = 10 \t 0.01609373721434238\n",
      "eps = 0.30000000000000004 min_samples = 11 \t -0.0059240535046943335\n",
      "eps = 0.30000000000000004 min_samples = 12 \t -0.007627455006386755\n",
      "eps = 0.30000000000000004 min_samples = 13 \t 0.0\n",
      "eps = 0.30000000000000004 min_samples = 14 \t 0.0\n",
      "eps = 0.4 min_samples = 5 \t 0.07837365804917787\n",
      "eps = 0.4 min_samples = 6 \t 0.06297564130301192\n",
      "eps = 0.4 min_samples = 7 \t 0.0332193529929463\n",
      "eps = 0.4 min_samples = 8 \t 0.030119667930556985\n",
      "eps = 0.4 min_samples = 9 \t 0.02919197068013819\n",
      "eps = 0.4 min_samples = 10 \t 0.02017487067562046\n",
      "eps = 0.4 min_samples = 11 \t 0.010752223542813997\n",
      "eps = 0.4 min_samples = 12 \t 0.010752223542813997\n",
      "eps = 0.4 min_samples = 13 \t 0.005289012098782187\n",
      "eps = 0.4 min_samples = 14 \t 0.005289012098782187\n",
      "eps = 0.5 min_samples = 5 \t 0.16047685474691803\n",
      "eps = 0.5 min_samples = 6 \t 0.11836288781947837\n",
      "eps = 0.5 min_samples = 7 \t 0.0972064361463669\n",
      "eps = 0.5 min_samples = 8 \t 0.07601208085120995\n",
      "eps = 0.5 min_samples = 9 \t 0.06525912245642959\n",
      "eps = 0.5 min_samples = 10 \t 0.055107998802750316\n",
      "eps = 0.5 min_samples = 11 \t 0.055107998802750316\n",
      "eps = 0.5 min_samples = 12 \t 0.05192217324146647\n",
      "eps = 0.5 min_samples = 13 \t 0.05192217324146647\n",
      "eps = 0.5 min_samples = 14 \t 0.04113070971679954\n",
      "eps = 0.6000000000000001 min_samples = 5 \t 0.20298430536916598\n",
      "eps = 0.6000000000000001 min_samples = 6 \t 0.18421491285818337\n",
      "eps = 0.6000000000000001 min_samples = 7 \t 0.16762132442824987\n",
      "eps = 0.6000000000000001 min_samples = 8 \t 0.16335020336635628\n",
      "eps = 0.6000000000000001 min_samples = 9 \t 0.1254459154338304\n",
      "eps = 0.6000000000000001 min_samples = 10 \t 0.11118278751739047\n",
      "eps = 0.6000000000000001 min_samples = 11 \t 0.11118278751739047\n",
      "eps = 0.6000000000000001 min_samples = 12 \t 0.11118278751739047\n",
      "eps = 0.6000000000000001 min_samples = 13 \t 0.11118278751739047\n",
      "eps = 0.6000000000000001 min_samples = 14 \t 0.11118278751739047\n",
      "eps = 0.7000000000000001 min_samples = 5 \t 0.2420546724983992\n",
      "eps = 0.7000000000000001 min_samples = 6 \t 0.2420546724983992\n",
      "eps = 0.7000000000000001 min_samples = 7 \t 0.2211925185842888\n",
      "eps = 0.7000000000000001 min_samples = 8 \t 0.19845677001708056\n",
      "eps = 0.7000000000000001 min_samples = 9 \t 0.19075624380116088\n",
      "eps = 0.7000000000000001 min_samples = 10 \t 0.1831060091592728\n",
      "eps = 0.7000000000000001 min_samples = 11 \t 0.15662110928610218\n",
      "eps = 0.7000000000000001 min_samples = 12 \t 0.12530072404598835\n",
      "eps = 0.7000000000000001 min_samples = 13 \t 0.12530072404598835\n",
      "eps = 0.7000000000000001 min_samples = 14 \t 0.12530072404598835\n",
      "eps = 0.8 min_samples = 5 \t 0.2572388674281617\n",
      "eps = 0.8 min_samples = 6 \t 0.2512303952265874\n",
      "eps = 0.8 min_samples = 7 \t 0.2512303952265874\n",
      "eps = 0.8 min_samples = 8 \t 0.2512303952265874\n",
      "eps = 0.8 min_samples = 9 \t 0.2512303952265874\n",
      "eps = 0.8 min_samples = 10 \t 0.2096409872779319\n",
      "eps = 0.8 min_samples = 11 \t 0.20097505659099665\n",
      "eps = 0.8 min_samples = 12 \t 0.20097505659099665\n",
      "eps = 0.8 min_samples = 13 \t 0.1870396616432402\n",
      "eps = 0.8 min_samples = 14 \t 0.14510934731534558\n",
      "eps = 0.9 min_samples = 5 \t 0.2830302200131392\n",
      "eps = 0.9 min_samples = 6 \t 0.2830302200131392\n",
      "eps = 0.9 min_samples = 7 \t 0.2781044996046526\n",
      "eps = 0.9 min_samples = 8 \t 0.2781044996046526\n",
      "eps = 0.9 min_samples = 9 \t 0.26553760304709434\n",
      "eps = 0.9 min_samples = 10 \t 0.26553760304709434\n",
      "eps = 0.9 min_samples = 11 \t 0.2491219439168326\n",
      "eps = 0.9 min_samples = 12 \t 0.2491219439168326\n",
      "eps = 0.9 min_samples = 13 \t 0.2491219439168326\n",
      "eps = 0.9 min_samples = 14 \t 0.2417628828604701\n",
      "eps = 1.0 min_samples = 5 \t 0.284458577800376\n",
      "eps = 1.0 min_samples = 6 \t 0.284458577800376\n",
      "eps = 1.0 min_samples = 7 \t 0.27953331282374966\n",
      "eps = 1.0 min_samples = 8 \t 0.27953331282374966\n",
      "eps = 1.0 min_samples = 9 \t 0.27953331282374966\n",
      "eps = 1.0 min_samples = 10 \t 0.27953331282374966\n",
      "eps = 1.0 min_samples = 11 \t 0.2758538911443694\n",
      "eps = 1.0 min_samples = 12 \t 0.2758538911443694\n",
      "eps = 1.0 min_samples = 13 \t 0.25171680135631386\n",
      "eps = 1.0 min_samples = 14 \t 0.25171680135631386\n",
      "eps = 1.1 min_samples = 5 \t 0.2477715516384018\n",
      "eps = 1.1 min_samples = 6 \t 0.2477715516384018\n",
      "eps = 1.1 min_samples = 7 \t 0.2558500468361418\n",
      "eps = 1.1 min_samples = 8 \t 0.27247938248675696\n",
      "eps = 1.1 min_samples = 9 \t 0.27247938248675696\n",
      "eps = 1.1 min_samples = 10 \t 0.27247938248675696\n",
      "eps = 1.1 min_samples = 11 \t 0.27247938248675696\n",
      "eps = 1.1 min_samples = 12 \t 0.2688781116852445\n",
      "eps = 1.1 min_samples = 13 \t 0.2688781116852445\n",
      "eps = 1.1 min_samples = 14 \t 0.2623886707392525\n",
      "eps = 1.2000000000000002 min_samples = 5 \t 0.23300299344287534\n",
      "eps = 1.2000000000000002 min_samples = 6 \t 0.23300299344287534\n",
      "eps = 1.2000000000000002 min_samples = 7 \t 0.23300299344287534\n",
      "eps = 1.2000000000000002 min_samples = 8 \t 0.23999201388189578\n",
      "eps = 1.2000000000000002 min_samples = 9 \t 0.2558500468361418\n",
      "eps = 1.2000000000000002 min_samples = 10 \t 0.27247938248675696\n",
      "eps = 1.2000000000000002 min_samples = 11 \t 0.27247938248675696\n",
      "eps = 1.2000000000000002 min_samples = 12 \t 0.27247938248675696\n",
      "eps = 1.2000000000000002 min_samples = 13 \t 0.27247938248675696\n",
      "eps = 1.2000000000000002 min_samples = 14 \t 0.27247938248675696\n",
      "eps = 1.3 min_samples = 5 \t 0.23873519064842946\n",
      "eps = 1.3 min_samples = 6 \t 0.23619633320591044\n",
      "eps = 1.3 min_samples = 7 \t 0.23619633320591044\n",
      "eps = 1.3 min_samples = 8 \t 0.23449522934073383\n",
      "eps = 1.3 min_samples = 9 \t 0.24156267674386694\n",
      "eps = 1.3 min_samples = 10 \t 0.24156267674386694\n",
      "eps = 1.3 min_samples = 11 \t 0.2622177602648259\n",
      "eps = 1.3 min_samples = 12 \t 0.2622177602648259\n",
      "eps = 1.3 min_samples = 13 \t 0.2622177602648259\n",
      "eps = 1.3 min_samples = 14 \t 0.2622177602648259\n",
      "eps = 1.4000000000000001 min_samples = 5 \t 0.2422327542911591\n",
      "eps = 1.4000000000000001 min_samples = 6 \t 0.24021160425943083\n",
      "eps = 1.4000000000000001 min_samples = 7 \t 0.24021160425943083\n",
      "eps = 1.4000000000000001 min_samples = 8 \t 0.24021160425943083\n",
      "eps = 1.4000000000000001 min_samples = 9 \t 0.23810292769182664\n",
      "eps = 1.4000000000000001 min_samples = 10 \t 0.23810292769182664\n",
      "eps = 1.4000000000000001 min_samples = 11 \t 0.2453270846928288\n",
      "eps = 1.4000000000000001 min_samples = 12 \t 0.2599989176998489\n",
      "eps = 1.4000000000000001 min_samples = 13 \t 0.2599989176998489\n",
      "eps = 1.4000000000000001 min_samples = 14 \t 0.2599989176998489\n",
      "eps = 1.5 min_samples = 5 \t 0.24475991164365132\n",
      "eps = 1.5 min_samples = 6 \t 0.24475991164365132\n",
      "eps = 1.5 min_samples = 7 \t 0.24208285599700055\n",
      "eps = 1.5 min_samples = 8 \t 0.24208285599700055\n",
      "eps = 1.5 min_samples = 9 \t 0.24021160425943083\n",
      "eps = 1.5 min_samples = 10 \t 0.24021160425943083\n",
      "eps = 1.5 min_samples = 11 \t 0.2475140724461391\n",
      "eps = 1.5 min_samples = 12 \t 0.2475140724461391\n",
      "eps = 1.5 min_samples = 13 \t 0.2475140724461391\n",
      "eps = 1.5 min_samples = 14 \t 0.2475140724461391\n",
      "eps = 1.6 min_samples = 5 \t 0.1862412977845831\n",
      "eps = 1.6 min_samples = 6 \t 0.2456540346150783\n",
      "eps = 1.6 min_samples = 7 \t 0.24543104995489617\n",
      "eps = 1.6 min_samples = 8 \t 0.2429112032493843\n",
      "eps = 1.6 min_samples = 9 \t 0.2429112032493843\n",
      "eps = 1.6 min_samples = 10 \t 0.24021160425943083\n",
      "eps = 1.6 min_samples = 11 \t 0.24021160425943083\n",
      "eps = 1.6 min_samples = 12 \t 0.24021160425943083\n",
      "eps = 1.6 min_samples = 13 \t 0.24021160425943083\n",
      "eps = 1.6 min_samples = 14 \t 0.24021160425943083\n",
      "eps = 1.7000000000000002 min_samples = 5 \t 0.046459970668891036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 1.7000000000000002 min_samples = 6 \t 0.046459970668891036\n",
      "eps = 1.7000000000000002 min_samples = 7 \t 0.046459970668891036\n",
      "eps = 1.7000000000000002 min_samples = 8 \t 0.24445877169863703\n",
      "eps = 1.7000000000000002 min_samples = 9 \t 0.24464954284384077\n",
      "eps = 1.7000000000000002 min_samples = 10 \t 0.24247469439698957\n",
      "eps = 1.7000000000000002 min_samples = 11 \t 0.24026814722739998\n",
      "eps = 1.7000000000000002 min_samples = 12 \t 0.24026814722739998\n",
      "eps = 1.7000000000000002 min_samples = 13 \t 0.24026814722739998\n",
      "eps = 1.7000000000000002 min_samples = 14 \t 0.24026814722739998\n",
      "eps = 1.8 min_samples = 5 \t 0.046459970668891036\n",
      "eps = 1.8 min_samples = 6 \t 0.046459970668891036\n",
      "eps = 1.8 min_samples = 7 \t 0.046459970668891036\n",
      "eps = 1.8 min_samples = 8 \t 0.046459970668891036\n",
      "eps = 1.8 min_samples = 9 \t 0.23019480759920566\n",
      "eps = 1.8 min_samples = 10 \t 0.24040121041033197\n",
      "eps = 1.8 min_samples = 11 \t 0.23588465109260798\n",
      "eps = 1.8 min_samples = 12 \t 0.23588465109260798\n",
      "eps = 1.8 min_samples = 13 \t 0.23588465109260798\n",
      "eps = 1.8 min_samples = 14 \t 0.23588465109260798\n",
      "eps = 1.9000000000000001 min_samples = 5 \t 0.04066639299215132\n",
      "eps = 1.9000000000000001 min_samples = 6 \t 0.04066639299215132\n",
      "eps = 1.9000000000000001 min_samples = 7 \t 0.04066639299215132\n",
      "eps = 1.9000000000000001 min_samples = 8 \t 0.04066639299215132\n",
      "eps = 1.9000000000000001 min_samples = 9 \t 0.04066639299215132\n",
      "eps = 1.9000000000000001 min_samples = 10 \t 0.038640266487845035\n",
      "eps = 1.9000000000000001 min_samples = 11 \t 0.048431011669339566\n",
      "eps = 1.9000000000000001 min_samples = 12 \t 0.07850973679132714\n",
      "eps = 1.9000000000000001 min_samples = 13 \t 0.22390937373776434\n",
      "eps = 1.9000000000000001 min_samples = 14 \t 0.23021610535649834\n",
      "\n",
      "The maxvalue is 0.284458577800376 where i = 1.0 and j = 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "def DBSS(e,ms):\n",
    "    DBS = DBSCAN(eps=e, min_samples=ms, metric='euclidean').fit(resData)\n",
    "    labels = DBS.labels_\n",
    "    return labels\n",
    "maxvalue = 0\n",
    "maxi = 0\n",
    "maxj = 0\n",
    "for i in range(1, 20,1):\n",
    "    for j in range(5,15,1):\n",
    "        score = metrics.adjusted_rand_score(DBSS(i*0.1, j) , res_test_y)\n",
    "        if maxvalue < score:\n",
    "            maxvalue = score\n",
    "            maxi = i\n",
    "            maxj = j\n",
    "        print('eps =',i*0.1,'min_samples =',j,'\\t',score)\n",
    "print(\"\\nThe maxvalue is\",maxvalue,\"where i =\",maxi*0.1,\"and j =\",maxj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们对密度聚类进行遍历以尝试通过修改eps和min_simples的参数以获得最优的结果，得到最优的大致值为0.28\n",
    "\n",
    "i=1 j=5 。我们对运行时间也进行了测试，可以看到DBSCAN速度相对更快，得到的准确度相对更大："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.284458577800376\n",
      "DBSCAN time: 0.011593299999731244 s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "score = metrics.adjusted_rand_score(DBSS(1, 5) , res_test_y)\n",
    "print(\"score: \", score)\n",
    "end = time.perf_counter()\n",
    "print(\"DBSCAN time:\", end-start ,\"s\")\n",
    "DBSCAN_time = end-start\n",
    "DBSCAN_score = maxvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 层次聚类\n",
    "\n",
    "层次聚类(Hierarchical Clustering)是聚类算法的一种，\n",
    "通过计算不同类别数据点间的相似度来创建一棵有层次的嵌套聚类树。\n",
    "\n",
    "在聚类树中，不同类别的原始数据点是树的最低层，树的顶层是一个聚类的根节点。\n",
    "\n",
    "层次聚类算法相比划分聚类算法的优点之一是可以在不同的尺度上（层次）展示数据集的聚类情况。\n",
    "\n",
    "根据创建聚类树有的两种方式：自下而上合并和自上而下。基于层次的聚类算法可以分为：\n",
    "\n",
    "凝聚的（Agglomerative）或者分裂的（Divisive）\n",
    "\n",
    "### 自底向上的层次算法\n",
    "\n",
    "层次聚类的合并算法通过计算两类数据点间的相似性，\n",
    "\n",
    "对所有数据点中最为相似的两个数据点进行组合，并反复迭代这一过程。\n",
    "\n",
    "简单的说层次聚类的合并算法是通过计算每一个类别的数据点与所有数据点之间的距离来确定它们之间的相似性，\n",
    "\n",
    "距离越小，相似度越高。并将距离最近的两个数据点或类别进行组合，生成聚类树。\n",
    "\n",
    "绝大多数层次聚类属于凝聚型层次聚类， 它的算法流程如下：\n",
    "\n",
    "    (1) 将每个对象看作一类，计算两两之间的距离；\n",
    "    (2) 将距离最小的两个类合并成一个新类；\n",
    "    (3) 重新计算新类与所有类之间的距离；\n",
    "    (4) 重复(2)、(3)，直到所有类最后合并成一类。\n",
    "\n",
    "![](Pic/level.JPG)\n",
    "\n",
    "整个过程就是建立一棵树，在建立的过程中，可以在步骤四设置所需分类的类别个数，\n",
    "\n",
    "作为迭代的终止条件，毕竟都归为一类并不实际。\n",
    "\n",
    "### sklearn 中的层次聚类\n",
    "\n",
    "sklearn库下的层次聚类是在sklearn.cluster的 AgglomerativeClustering 聚类\n",
    "\n",
    "    n_clusters：（簇的个数）是需要用户指定的，按照常理来说，凝聚层次聚类是不需要指定簇的个数的，但是sklearn的这个类需要指定簇的个数。算法会根据簇的个数判断最终的合并依据，这个参数会影响聚类质量。\n",
    "    linkage：（连接方法）指的是衡量簇与簇之间的远近程度的方法。具体说来包括最小距离，最大距离和平均距离三种方式。对应于簇融合的方法，即簇间观测点之间的最小距离作为簇的距离，簇间观测点之间的最大距离作为簇的距离，以及簇间观测点之间的平均距离作为簇的距离。一般说来，平均距离是一种折中的方法。\n",
    "    affinity：（连接度量选项）是一个簇间距离的计算方法，包括各种欧式空间的距离计算方法以及非欧式空间的距离计算方法。此外，该参数还可以设置为precomputed，即用户输入计算好的距离矩阵。距离矩阵的生成方法：假设用户有n个观测点，那么先依次构造这n个点两两间的距离列表，即长度为n*(n-1)/2的距离列表，然后通过scipy.spatial.distance的dist库的squareform函数就可以构造距离矩阵了。这种方式的好处是用户可以使用自己定义的方法计算任意两个观测点的距离，然后再进行聚类。 。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "AgglomerativeClustering (\n",
    "affinity=‘euclidean’,\n",
    "compute_full_tree=‘auto’,\n",
    "connectivity=None,\n",
    "linkage=‘ward’,\n",
    "memory=None,\n",
    "n_clusters=2,\n",
    "pooling_func=<function mean at 0x110d8f840>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  0.2620306253377113\n",
      "\n",
      "AgglomerativeClustering time: 0.009965899999770045 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering as agg\n",
    "def agg_test(num):\n",
    "    clustering = agg(n_clusters=6).fit(resData)\n",
    "    return clustering.labels_\n",
    "\n",
    "start = time.perf_counter()\n",
    "score = metrics.adjusted_rand_score(agg_test(6), res_test_y)\n",
    "end = time.perf_counter()\n",
    "print(\"scores: \",score)\n",
    "print(\"\\nAgglomerativeClustering time:\", end-start ,\"s\")\n",
    "AgglomerativeClustering_time = end-start\n",
    "AgglomerativeClustering_score = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "同KMeans，我们做一些比对,批量地修改聚类总数观察聚类下分类状况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgglomerativeClustering = 2\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Expenses:77.00\n",
      "[106, 107, 108, 109, 110, 111, 112, 113, 130, 131, 132, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 181, 182, 183, 184, 185, 186, 187, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:149.00\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 175, 177, 178, 179, 180, 188, 189, 190, 191]\n",
      "\n",
      "score: 0.20767588291268393 \n",
      "\n",
      "AgglomerativeClustering = 3\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
      " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 2 2 2 2 2 2 0 0 2 1 2 1 1 1 1 0 2 2 2 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Expenses:77.00\n",
      "[164, 172, 173, 181, 185, 186, 187, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:149.00\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 175, 177, 178, 179, 180, 188, 189, 190, 191]\n",
      "Expenses:133.00\n",
      "[106, 107, 108, 109, 110, 111, 112, 113, 130, 131, 132, 166, 167, 168, 169, 170, 171, 174, 176, 182, 183, 184, 202]\n",
      "\n",
      "score: 0.23207987402252414 \n",
      "\n",
      "AgglomerativeClustering = 4\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2\n",
      " 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 2 2 2 2 2 1 1 2 0 2 0 0 0 0 3 2 2 2 3\n",
      " 1 1 0 0 0 0 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Expenses:77.00\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 175, 177, 178, 179, 180, 188, 189, 190, 191]\n",
      "Expenses:149.00\n",
      "[164, 172, 173, 186, 187]\n",
      "Expenses:133.00\n",
      "[106, 107, 108, 109, 110, 111, 112, 113, 130, 131, 132, 166, 167, 168, 169, 170, 171, 174, 176, 182, 183, 184, 202]\n",
      "Expenses:84.00\n",
      "[181, 185, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "\n",
      "score: 0.23109394162696856 \n",
      "\n",
      "AgglomerativeClustering = 5\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 2 2 4 4 4 2 4 4 4 2 2 4 2 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 2 2 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 0 0 0 0 0 0\n",
      " 0 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 0 0 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 2 4 4 4 4 4 2 4 4 4 4 2 1 2 0 0 0 0 0 0 1 1 0 2 0 2 2 2 2 3 0 0 0 3\n",
      " 1 1 4 2 2 2 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Expenses:77.00\n",
      "[106, 107, 108, 109, 110, 111, 112, 113, 130, 131, 132, 166, 167, 168, 169, 170, 171, 174, 176, 182, 183, 184, 202]\n",
      "Expenses:149.00\n",
      "[164, 172, 173, 186, 187]\n",
      "Expenses:133.00\n",
      "[18, 22, 39, 40, 44, 48, 49, 51, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 128, 129, 152, 158, 163, 165, 175, 177, 178, 179, 180, 189, 190, 191]\n",
      "Expenses:84.00\n",
      "[181, 185, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:34.00\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 188]\n",
      "\n",
      "score: 0.26147175255085586 \n",
      "\n",
      "AgglomerativeClustering = 6\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 2 2 1 1 1 2 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 5 5 5 4 4 5\n",
      " 5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 0 2 4 4 4 4 4 4 0 0 4 2 4 2 2 2 2 3 4 4 4 3\n",
      " 0 0 1 2 2 2 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Expenses:77.00\n",
      "[164, 172, 173, 186, 187]\n",
      "Expenses:149.00\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 188]\n",
      "Expenses:133.00\n",
      "[18, 22, 39, 40, 44, 48, 49, 51, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 128, 129, 152, 158, 163, 165, 175, 177, 178, 179, 180, 189, 190, 191]\n",
      "Expenses:84.00\n",
      "[181, 185, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:34.00\n",
      "[109, 110, 130, 131, 132, 166, 167, 168, 169, 170, 171, 174, 176, 182, 183, 184, 202]\n",
      "Expenses:71.00\n",
      "[106, 107, 108, 111, 112, 113]\n",
      "\n",
      "score: 0.2620306253377113 \n",
      "\n",
      "AgglomerativeClustering = 7\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 2 2 4 4 2\n",
      " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 5 0 4 4 4 4 4 4 6 6 4 0 4 0 0 0 0 3 4 4 4 3\n",
      " 5 5 1 0 0 0 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Expenses:77.00\n",
      "[18, 22, 39, 40, 44, 48, 49, 51, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 128, 129, 152, 158, 163, 165, 175, 177, 178, 179, 180, 189, 190, 191]\n",
      "Expenses:149.00\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 188]\n",
      "Expenses:133.00\n",
      "[106, 107, 108, 111, 112, 113]\n",
      "Expenses:84.00\n",
      "[181, 185, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:34.00\n",
      "[109, 110, 130, 131, 132, 166, 167, 168, 169, 170, 171, 174, 176, 182, 183, 184, 202]\n",
      "Expenses:71.00\n",
      "[164, 186, 187]\n",
      "Expenses:165.00\n",
      "[172, 173]\n",
      "\n",
      "score: 0.2620183917864067 \n",
      "\n",
      "AgglomerativeClustering = 8\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 7 7 0 0 0 7 0 0 0 7 7 0 7 0 0 0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 7 7 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 7 2 2 2 4 4 2\n",
      " 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 7 0 0 0 0 0 7 0 0 0 0 7 5 3 4 4 4 4 4 4 6 6 4 3 4 3 3 3 3 1 4 4 4 1\n",
      " 5 5 0 3 3 3 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Expenses:77.00\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 188]\n",
      "Expenses:149.00\n",
      "[181, 185, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:133.00\n",
      "[106, 107, 108, 111, 112, 113]\n",
      "Expenses:84.00\n",
      "[128, 129, 165, 175, 177, 178, 179, 180, 189, 190, 191]\n",
      "Expenses:34.00\n",
      "[109, 110, 130, 131, 132, 166, 167, 168, 169, 170, 171, 174, 176, 182, 183, 184, 202]\n",
      "Expenses:71.00\n",
      "[164, 186, 187]\n",
      "Expenses:165.00\n",
      "[172, 173]\n",
      "Expenses:10.00\n",
      "[18, 22, 39, 40, 44, 48, 49, 51, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 152, 158, 163]\n",
      "\n",
      "score: 0.27573955711181874 \n",
      "\n",
      "AgglomerativeClustering = 9\n",
      "[8 8 4 8 8 4 8 8 8 4 4 4 4 4 4 4 4 7 8 4 4 7 4 4 8 4 8 4 4 4 4 4 4 4 4 8 8\n",
      " 4 7 7 4 4 8 7 4 8 4 7 7 8 7 8 4 4 4 4 4 4 8 8 8 8 7 7 7 7 7 7 7 7 8 8 4 4\n",
      " 4 4 8 4 8 4 4 4 8 4 8 8 4 8 4 4 8 4 4 4 4 8 8 4 4 4 4 4 4 7 7 2 2 2 1 1 2\n",
      " 2 2 8 8 8 8 8 8 8 8 4 8 8 8 4 4 3 3 1 1 1 8 8 8 8 8 4 4 4 8 8 4 4 4 4 8 8\n",
      " 8 4 4 7 8 8 4 4 8 7 8 8 8 8 7 5 3 1 1 1 1 1 1 6 6 1 3 1 3 3 3 3 0 1 1 1 0\n",
      " 5 5 8 3 3 3 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Expenses:77.00\n",
      "[181, 185, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Expenses:149.00\n",
      "[109, 110, 130, 131, 132, 166, 167, 168, 169, 170, 171, 174, 176, 182, 183, 184, 202]\n",
      "Expenses:133.00\n",
      "[106, 107, 108, 111, 112, 113]\n",
      "Expenses:84.00\n",
      "[128, 129, 165, 175, 177, 178, 179, 180, 189, 190, 191]\n",
      "Expenses:34.00\n",
      "[3, 6, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 41, 42, 45, 47, 53, 54, 55, 56, 57, 58, 73, 74, 75, 76, 78, 80, 81, 82, 84, 87, 89, 90, 92, 93, 94, 95, 98, 99, 100, 101, 102, 103, 122, 126, 127, 138, 139, 140, 143, 144, 145, 146, 150, 151, 155, 156]\n",
      "Expenses:71.00\n",
      "[164, 186, 187]\n",
      "Expenses:165.00\n",
      "[172, 173]\n",
      "Expenses:10.00\n",
      "[18, 22, 39, 40, 44, 48, 49, 51, 63, 64, 65, 66, 67, 68, 69, 70, 104, 105, 152, 158, 163]\n",
      "Expenses:287.00\n",
      "[1, 2, 4, 5, 7, 8, 9, 19, 25, 27, 36, 37, 43, 46, 50, 52, 59, 60, 61, 62, 71, 72, 77, 79, 83, 85, 86, 88, 91, 96, 97, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 133, 134, 135, 136, 137, 141, 142, 147, 148, 149, 153, 154, 157, 159, 160, 161, 162, 188]\n",
      "\n",
      "score: 0.20831137594102542 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def AggTst(number):\n",
    "    '''\n",
    "\n",
    "    :param number: int\n",
    "    :return label: list\n",
    "    '''\n",
    "    lab = []\n",
    "    clustering = agg(n_clusters=number)\n",
    "    label = clustering.fit_predict(resData)\n",
    "    print(label)\n",
    "    expenses = np.sum(clustering.children_,axis=1)\n",
    "    for i in range(number):\n",
    "        eptlists = []\n",
    "        lab.append(eptlists)\n",
    "    for i in range(len(items)):\n",
    "        lab[label[i]].append(items[i])\n",
    "    for i in range(len(lab)):\n",
    "        print(\"Expenses:%.2f\" % expenses[i])\n",
    "        print(lab[i])\n",
    "    return label\n",
    "\n",
    "for i in range(2,10):\n",
    "    print(\"AgglomerativeClustering =\",i)\n",
    "    print(\"\\nscore:\",metrics.adjusted_rand_score(AggTst(i),res_test_y),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次实验层次聚类AgglomerativeClustering的大致adjusted_rand_score为0.23左右，是和6类条件基本符合的情况下，\n",
    "\n",
    "但是对于AggTst(number)函数中选择输入 number=8 的时候，可以达到0.275左右的结果，略低于最优化的DBSCAN算法。\n",
    "\n",
    "### 层次聚类优缺点\n",
    "\n",
    "优点：\n",
    "\n",
    "    1，距离和规则的相似度容易定义，限制少；\n",
    "    2，不需要预先制定聚类数；\n",
    "    3，可以发现类的层次关系；\n",
    "    4，可以聚类成其它形状\n",
    "\n",
    "缺点：\n",
    "\n",
    "    1，计算复杂度太高；\n",
    "    2，奇异值也能产生很大影响；\n",
    "    3，算法很可能聚类成链状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AP聚类算法\n",
    "\n",
    "AP(Affinity Propagation)通常被翻译为近邻传播算法或者亲和力传播算法。\n",
    "\n",
    "是2007年的Science杂志上提出的一种新的聚类算法。\n",
    "\n",
    "AP算法的基本思想是将全部数据点都当作潜在的聚类中心（称为exemplar），\n",
    "然后数据点两两之间连线构成一个网络（相似度矩阵），\n",
    "再通过网络中各条边的消息（吸引度responsibility和归属度availability）传递计算出各样本的聚类中心。\n",
    "直到产生m个高质量的Exemplar（类似于质心），\n",
    "同时将其余的数据点分配到相应的聚类中。\n",
    "\n",
    "参考图片：\n",
    "![](Pic/AP.JPG)\n",
    "\n",
    "吸引度（responsibility）矩阵R：其中r(i,k)描述了数据对象k适合作为数据对象i的聚类中心的程度，表示的是从i到k的消息；\n",
    "\n",
    "归属度（availability）矩阵A：其中a(i,k)描述了数据对象i选择数据对象k作为其据聚类中心的适合程度，表示从k到i的消息。\n",
    "\n",
    "Step1：算法初始，这两个矩阵均初始化为0矩阵。\n",
    "\n",
    "Step2：更新吸引度矩阵\n",
    "![](Pic/AP2.png)\n",
    "Step3：更新归属度矩阵\n",
    "![](Pic/AP3.png)\n",
    "Step4：根据衰减系数λ对两个公式进行衰减\n",
    "![](Pic/AP4.png)\n",
    "重复步骤2/3/4直至矩阵稳定或者达到最大迭代次数，算法结束。补充一下S为相似度矩阵，通常S（i，j）取i，j的欧氏距离的负值，当i=j时，通常取整个矩阵的最小值或者中位数(Scikit-learn中默认为中位数)，取得值越大则最终产生的类数量越多。\n",
    "\n",
    "最终取a+r最大的k作为聚类中心。\n",
    "\n",
    "### sklearn 中的AP聚类算法 Affinity Propagation Clustering\n",
    "\n",
    "**sklearn.cluster.AffinityPropagation()**\n",
    "\n",
    "主要参数：\n",
    "\n",
    "    damping : 阻尼系数，取值[0.5,1)\n",
    "    convergence_iter ：比较多少次聚类中心不变之后停止迭代，默认15\n",
    "    max_iter ：最大迭代次数\n",
    "    preference :参考度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2867620503230211 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "def aff():\n",
    "    clustering = AffinityPropagation(preference=-40)\n",
    "    lab = []\n",
    "    label = clustering.fit_predict(resData)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "print(\"\\nscore:\",metrics.adjusted_rand_score(aff(),res_test_y),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "下面我们尝试修改阻尼系数和preference来观察聚类的效度\n",
    "\n",
    "Affinity Propagation 算法可以根据提供的数据决定聚类的数目。\n",
    "\n",
    "因此有两个比较重要的参数:\n",
    "\n",
    "**preference**: 参考度或称为偏好参数：是相似度矩阵中横轴纵轴索引相同的点，如s(i,i)，若按欧氏距离计算其值应为0，但在AP聚类中其表示数据点i作为聚类中心的程度，因此不能为0。迭代开始前假设所有点成为聚类中心的能力相同，因此参考度一般设为相似度矩阵中所有值得最小值或者中位数，但是参考度越大则说明个数据点成为聚类中心的能力越强，则最终聚类中心的个数则越多；\n",
    "\n",
    "**damping factor**: 阻尼因子,用于减少吸引信息和归属信息以防止更新减少吸引度和归属度信息时数据振荡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 10 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.22130555101736402 \n",
      "\n",
      "i = 10 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0 \n",
      "\n",
      "i = 10 and j = -80\n",
      "\n",
      "score: 0.2424036666549525 \n",
      "\n",
      "i = 10 and j = -70\n",
      "\n",
      "score: 0.2424036666549525 \n",
      "\n",
      "i = 10 and j = -60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2524653095400037 \n",
      "\n",
      "i = 10 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2477940972762721 \n",
      "\n",
      "i = 10 and j = -40\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.2867620503230211 \n",
      "\n",
      "i = 10 and j = -30\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.2637075992272916 \n",
      "\n",
      "i = 10 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.27740142875893903 \n",
      "\n",
      "i = 10 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.19054452927540896 \n",
      "\n",
      "i = 11 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0 \n",
      "\n",
      "i = 11 and j = -90\n",
      "\n",
      "score: 0.2198485053340287 \n",
      "\n",
      "i = 11 and j = -80\n",
      "\n",
      "score: 0.24088078782405975 \n",
      "\n",
      "i = 11 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2477940972762721 \n",
      "\n",
      "i = 11 and j = -60\n",
      "\n",
      "score: 0.2477940972762721 \n",
      "\n",
      "i = 11 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 11 and j = -40\n",
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 11 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2757541777280504 \n",
      "\n",
      "i = 11 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.23904519682991363 \n",
      "\n",
      "i = 11 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.19054452927540896 \n",
      "\n",
      "i = 12 and j = -100\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.2502316833661681 \n",
      "\n",
      "i = 12 and j = -90\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.2198485053340287 \n",
      "\n",
      "i = 12 and j = -80\n",
      "\n",
      "score: 0.24088078782405975 \n",
      "\n",
      "i = 12 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 12 and j = -60\n",
      "\n",
      "score: 0.2424036666549525 \n",
      "\n",
      "i = 12 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 12 and j = -40\n",
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 12 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 12 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2214986353874805 \n",
      "\n",
      "i = 12 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2115866425321522 \n",
      "\n",
      "i = 13 and j = -100\n",
      "\n",
      "score: 0.2198485053340287 \n",
      "\n",
      "i = 13 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2198485053340287 \n",
      "\n",
      "i = 13 and j = -80\n",
      "\n",
      "score: 0.24088078782405975 \n",
      "\n",
      "i = 13 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2424036666549525 \n",
      "\n",
      "i = 13 and j = -60\n",
      "\n",
      "score: 0.2424036666549525 \n",
      "\n",
      "i = 13 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 13 and j = -40\n",
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 13 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 13 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.3010971108500713 \n",
      "\n",
      "i = 13 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.20086812335343202 \n",
      "\n",
      "i = 14 and j = -100\n",
      "\n",
      "score: 0.2198485053340287 \n",
      "\n",
      "i = 14 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2198485053340287 \n",
      "\n",
      "i = 14 and j = -80\n",
      "\n",
      "score: 0.2424036666549525 \n",
      "\n",
      "i = 14 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2424036666549525 \n",
      "\n",
      "i = 14 and j = -60\n",
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 14 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2424036666549525 \n",
      "\n",
      "i = 14 and j = -40\n",
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 14 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 14 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2771403117215968 \n",
      "\n",
      "i = 14 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.19054452927540896 \n",
      "\n",
      "i = 15 and j = -100\n",
      "\n",
      "score: 0.2198485053340287 \n",
      "\n",
      "i = 15 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2198485053340287 \n",
      "\n",
      "i = 15 and j = -80\n",
      "\n",
      "score: 0.24088078782405975 \n",
      "\n",
      "i = 15 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2424036666549525 \n",
      "\n",
      "i = 15 and j = -60\n",
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 15 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 15 and j = -40\n",
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 15 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 15 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.21313038745168217 \n",
      "\n",
      "i = 15 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.19474800009691687 \n",
      "\n",
      "i = 16 and j = -100\n",
      "\n",
      "score: 0.2198485053340287 \n",
      "\n",
      "i = 16 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2198485053340287 \n",
      "\n",
      "i = 16 and j = -80\n",
      "\n",
      "score: 0.2463622373452916 \n",
      "\n",
      "i = 16 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 16 and j = -60\n",
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 16 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 16 and j = -40\n",
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 16 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 16 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.3010971108500713 \n",
      "\n",
      "i = 16 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.19474800009691687 \n",
      "\n",
      "i = 17 and j = -100\n",
      "\n",
      "score: 0.2198485053340287 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 17 and j = -90\n",
      "\n",
      "score: 0.2198485053340287 \n",
      "\n",
      "i = 17 and j = -80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2463622373452916 \n",
      "\n",
      "i = 17 and j = -70\n",
      "\n",
      "score: 0.2506667340235373 \n",
      "\n",
      "i = 17 and j = -60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 17 and j = -50\n",
      "\n",
      "score: 0.25079955926230085 \n",
      "\n",
      "i = 17 and j = -40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2867620503230211 \n",
      "\n",
      "i = 17 and j = -30\n",
      "\n",
      "score: 0.2866269766588598 \n",
      "\n",
      "i = 17 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2129623178669593 \n",
      "\n",
      "i = 17 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.1947875829101398 \n",
      "\n",
      "i = 18 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2197395247730038 \n",
      "\n",
      "i = 18 and j = -90\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.24623018905943686 \n",
      "\n",
      "i = 18 and j = -80\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.24623018905943686 \n",
      "\n",
      "i = 18 and j = -70\n",
      "\n",
      "score: 0.2506667340235373 \n",
      "\n",
      "i = 18 and j = -60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2506667340235373 \n",
      "\n",
      "i = 18 and j = -50\n",
      "\n",
      "score: 0.2506667340235373 \n",
      "\n",
      "i = 18 and j = -40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2866269766588598 \n",
      "\n",
      "i = 18 and j = -30\n",
      "\n",
      "score: 0.2866269766588598 \n",
      "\n",
      "i = 18 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2771485389550673 \n",
      "\n",
      "i = 18 and j = -10\n",
      "\n",
      "score: 0.1945769694530989 \n",
      "\n",
      "i = 19 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.21739551707671634 \n",
      "\n",
      "i = 19 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.24623018905943686 \n",
      "\n",
      "i = 19 and j = -80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.24623018905943686 \n",
      "\n",
      "i = 19 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2506667340235373 \n",
      "\n",
      "i = 19 and j = -60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2506667340235373 \n",
      "\n",
      "i = 19 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2506667340235373 \n",
      "\n",
      "i = 19 and j = -40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2866269766588598 \n",
      "\n",
      "i = 19 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.2866269766588598 \n",
      "\n",
      "i = 19 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.30096045806310234 \n",
      "\n",
      "i = 19 and j = -10\n",
      "\n",
      "score: 0.16871336020540914 \n",
      "\n",
      "\n",
      "The maxvalue is 0.3010971108500713 where i = 0.65 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def affs(damp, pre):\n",
    "    '''\n",
    "\n",
    "    :param damp: 阻尼系数/阻尼因子\n",
    "    :param pre: preference 参考度\n",
    "    :return:\n",
    "    '''\n",
    "    clustering = AffinityPropagation(damping=damp,preference=pre)\n",
    "    label = clustering.fit_predict(resData)\n",
    "    return label\n",
    "maxvalue = 0\n",
    "maxi = 0\n",
    "maxj = 0\n",
    "for i in range(10,20):\n",
    "    for j in range(-100,0,10):\n",
    "        print('i =',i,'and j =',j)\n",
    "        score_2 = metrics.adjusted_rand_score(affs(0.05*i, j),res_test_y)\n",
    "        print(\"\\nscore:\",score_2,'\\n')\n",
    "        if maxvalue < score_2:\n",
    "            maxvalue = score_2\n",
    "            maxi = i\n",
    "            maxj = j\n",
    "print(\"\\nThe maxvalue is\",maxvalue,\"where i =\",maxi*0.05,\"and j =\",maxj)\n",
    "AffinityPropagation_score = maxvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "当阻尼因子为0.65，参考度为-20的时候，得到了最大的adjusted_rand_score——0.30\n",
    "\n",
    "我们再试一试当阻尼因子为0.65，参考度为-20的运行时间情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.3010971108500713\n",
      "AffinityPropagation time:  0.2837698999992426 s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "print(\"Score: \",metrics.adjusted_rand_score(affs(0.65, -20),res_test_y))\n",
    "end = time.perf_counter()\n",
    "print(\"AffinityPropagation time: \",end-start,\"s\")\n",
    "AffinityPropagation_time = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### AP算法评价\n",
    "\n",
    "#### AP算法的优点\n",
    "\n",
    "    1） 不需要制定最终聚类族的个数\n",
    "    2） 已有的数据点作为最终的聚类中心，而不是新生成一个族中心。\n",
    "    3）模型对数据的初始值不敏感。\n",
    "    4）对初始相似度矩阵数据的对称性没有要求。\n",
    "    5）.相比与k-centers聚类方法，其结果的平方差误差较小。\n",
    "\n",
    "#### AP算法的不足\n",
    "\n",
    "    1）AP算法需要事先计算每对数据对象之间的相似度，如果数据对象太多的话，内存放不下，若存在数据库，频繁访问数据库也需要时间。\n",
    "    2）AP算法的时间复杂度较高，一次迭代大概O(N^3)\n",
    "    3）聚类的好坏受到参考度和阻尼系数的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 总结和对比分析\n",
    "\n",
    "下面我们会绘制图表进行观察相关的结果，比如运行时间和得到的**adjusted_rand_score**结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TABLE A  时间和相关算法的关系柱状图\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "xlabels = ['kmeans','DBSCAN','Agglomerative','AffinityPropagation']\n",
    "ylabels = [kmeans_time, DBSCAN_time, AgglomerativeClustering_time, AffinityPropagation_time]\n",
    "plt.bar(range(len(xlabels)), ylabels, tick_label=xlabels)\n",
    "plt.title('时间运行和算法相关参数图,纵坐标单位：s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TABLE B  adjusted_rand_score和相关算法的关系柱状图\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "ylabels = [kmeans_score, DBSCAN_score, AgglomerativeClustering_score, AffinityPropagation_score]\n",
    "plt.bar(range(len(xlabels)), ylabels, tick_label=xlabels)\n",
    "plt.title('adjusted_rand_score和算法相关参数图')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "时间上，总体的运算还是有区别,相对而言层次聚类算法和密度聚类DBSCAN算法消耗的时间更少，\n",
    "\n",
    "而K-Means和AP聚类消耗时间更多一点,AP聚类耗时比较高\n",
    "\n",
    "在运行效率上，总体的分值并不高，在0.2-0.3左右，4个算法之间,DBSCAN和合理调参的AP算法可以得到更好一点的聚类效果\n",
    "\n",
    "## LAB B Wine\n",
    "\n",
    "数据名称：葡萄酒识别数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3     4    5     6     7     8     9      10    11  \\\n",
       "0     1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29   5.64  1.04   \n",
       "1     1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28   4.38  1.05   \n",
       "2     1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81   5.68  1.03   \n",
       "3     1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18   7.80  0.86   \n",
       "4     1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82   4.32  1.04   \n",
       "..   ..    ...   ...   ...   ...  ...   ...   ...   ...   ...    ...   ...   \n",
       "173   3  13.71  5.65  2.45  20.5   95  1.68  0.61  0.52  1.06   7.70  0.64   \n",
       "174   3  13.40  3.91  2.48  23.0  102  1.80  0.75  0.43  1.41   7.30  0.70   \n",
       "175   3  13.27  4.28  2.26  20.0  120  1.59  0.69  0.43  1.35  10.20  0.59   \n",
       "176   3  13.17  2.59  2.37  20.0  120  1.65  0.68  0.53  1.46   9.30  0.60   \n",
       "177   3  14.13  4.10  2.74  24.5   96  2.05  0.76  0.56  1.35   9.20  0.61   \n",
       "\n",
       "       12    13  \n",
       "0    3.92  1065  \n",
       "1    3.40  1050  \n",
       "2    3.17  1185  \n",
       "3    3.45  1480  \n",
       "4    2.93   735  \n",
       "..    ...   ...  \n",
       "173  1.74   740  \n",
       "174  1.56   750  \n",
       "175  1.56   835  \n",
       "176  1.62   840  \n",
       "177  1.60   560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = pd.read_csv('data/wine/wine.data', header=None)\n",
    "wine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "第一列是基准分的类，我们提取作为ylabel验证,其他列作为xlabel测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "173    3\n",
       "174    3\n",
       "175    3\n",
       "176    3\n",
       "177    3\n",
       "Name: 0, Length: 178, dtype: int64"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test_y = wine_data[0]\n",
    "res_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2     3     4    5     6     7     8     9      10    11    12  \\\n",
       "0    14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29   5.64  1.04  3.92   \n",
       "1    13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28   4.38  1.05  3.40   \n",
       "2    13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81   5.68  1.03  3.17   \n",
       "3    14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18   7.80  0.86  3.45   \n",
       "4    13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82   4.32  1.04  2.93   \n",
       "..     ...   ...   ...   ...  ...   ...   ...   ...   ...    ...   ...   ...   \n",
       "173  13.71  5.65  2.45  20.5   95  1.68  0.61  0.52  1.06   7.70  0.64  1.74   \n",
       "174  13.40  3.91  2.48  23.0  102  1.80  0.75  0.43  1.41   7.30  0.70  1.56   \n",
       "175  13.27  4.28  2.26  20.0  120  1.59  0.69  0.43  1.35  10.20  0.59  1.56   \n",
       "176  13.17  2.59  2.37  20.0  120  1.65  0.68  0.53  1.46   9.30  0.60  1.62   \n",
       "177  14.13  4.10  2.74  24.5   96  2.05  0.76  0.56  1.35   9.20  0.61  1.60   \n",
       "\n",
       "       13  \n",
       "0    1065  \n",
       "1    1050  \n",
       "2    1185  \n",
       "3    1480  \n",
       "4     735  \n",
       "..    ...  \n",
       "173   740  \n",
       "174   750  \n",
       "175   835  \n",
       "176   840  \n",
       "177   560  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resData = wine_data.iloc[:,1:]\n",
    "resData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "下面的代码只需要对resData进行算法验证即可\n",
    "\n",
    "### 1. Kmeans 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  0.37111371823084754\n",
      "\n",
      "KMEANS time: 0.053639700000530866 s\n"
     ]
    }
   ],
   "source": [
    "def kms(number):\n",
    "    km = KMeans(n_clusters=number)\n",
    "    label = km.fit_predict(resData)\n",
    "    return label\n",
    "\n",
    "from sklearn import metrics\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "score = metrics.adjusted_rand_score(kms(3),res_test_y)\n",
    "end = time.perf_counter()\n",
    "print(\"scores: \",score)\n",
    "print(\"\\nKMEANS time:\", end-start ,\"s\")\n",
    "kmeans_time = end - start\n",
    "kmeans_score = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DBSCAN 算法\n",
    "\n",
    "DBSCAN遍历预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 21.0 min_samples = 5 \t 0.21778242126618605\n",
      "eps = 21.0 min_samples = 6 \t 0.17215791358184698\n",
      "eps = 21.0 min_samples = 7 \t 0.13609521942541547\n",
      "eps = 21.0 min_samples = 8 \t 0.09678513231640234\n",
      "eps = 21.0 min_samples = 9 \t 0.13592970679470343\n",
      "eps = 21.0 min_samples = 10 \t 0.04536748543907908\n",
      "eps = 21.0 min_samples = 11 \t 0.02601327113127157\n",
      "eps = 21.0 min_samples = 12 \t 0.0187541949279269\n",
      "eps = 21.0 min_samples = 13 \t 0.014804748082355396\n",
      "eps = 21.0 min_samples = 14 \t 0.014804748082355396\n",
      "eps = 21.0 min_samples = 15 \t 0.0\n",
      "eps = 21.0 min_samples = 16 \t 0.0\n",
      "eps = 21.0 min_samples = 17 \t 0.0\n",
      "eps = 21.0 min_samples = 18 \t 0.0\n",
      "eps = 21.0 min_samples = 19 \t 0.0\n",
      "eps = 21.1 min_samples = 5 \t 0.21778242126618605\n",
      "eps = 21.1 min_samples = 6 \t 0.1740693594696876\n",
      "eps = 21.1 min_samples = 7 \t 0.15142318094084173\n",
      "eps = 21.1 min_samples = 8 \t 0.09868236175864128\n",
      "eps = 21.1 min_samples = 9 \t 0.09937836969984502\n",
      "eps = 21.1 min_samples = 10 \t 0.05592227136018124\n",
      "eps = 21.1 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 21.1 min_samples = 12 \t 0.017699799293785862\n",
      "eps = 21.1 min_samples = 13 \t 0.014804748082355396\n",
      "eps = 21.1 min_samples = 14 \t 0.014804748082355396\n",
      "eps = 21.1 min_samples = 15 \t 0.0\n",
      "eps = 21.1 min_samples = 16 \t 0.0\n",
      "eps = 21.1 min_samples = 17 \t 0.0\n",
      "eps = 21.1 min_samples = 18 \t 0.0\n",
      "eps = 21.1 min_samples = 19 \t 0.0\n",
      "eps = 21.200000000000003 min_samples = 5 \t 0.21778242126618605\n",
      "eps = 21.200000000000003 min_samples = 6 \t 0.1740693594696876\n",
      "eps = 21.200000000000003 min_samples = 7 \t 0.158726139700211\n",
      "eps = 21.200000000000003 min_samples = 8 \t 0.103281357559411\n",
      "eps = 21.200000000000003 min_samples = 9 \t 0.11561225796758075\n",
      "eps = 21.200000000000003 min_samples = 10 \t 0.05592227136018124\n",
      "eps = 21.200000000000003 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 21.200000000000003 min_samples = 12 \t 0.017699799293785862\n",
      "eps = 21.200000000000003 min_samples = 13 \t 0.014804748082355396\n",
      "eps = 21.200000000000003 min_samples = 14 \t 0.014804748082355396\n",
      "eps = 21.200000000000003 min_samples = 15 \t 0.0\n",
      "eps = 21.200000000000003 min_samples = 16 \t 0.0\n",
      "eps = 21.200000000000003 min_samples = 17 \t 0.0\n",
      "eps = 21.200000000000003 min_samples = 18 \t 0.0\n",
      "eps = 21.200000000000003 min_samples = 19 \t 0.0\n",
      "eps = 21.3 min_samples = 5 \t 0.21778242126618605\n",
      "eps = 21.3 min_samples = 6 \t 0.1740693594696876\n",
      "eps = 21.3 min_samples = 7 \t 0.158726139700211\n",
      "eps = 21.3 min_samples = 8 \t 0.14555551916081388\n",
      "eps = 21.3 min_samples = 9 \t 0.11561225796758075\n",
      "eps = 21.3 min_samples = 10 \t 0.05592227136018124\n",
      "eps = 21.3 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 21.3 min_samples = 12 \t 0.017699799293785862\n",
      "eps = 21.3 min_samples = 13 \t 0.014804748082355396\n",
      "eps = 21.3 min_samples = 14 \t 0.014804748082355396\n",
      "eps = 21.3 min_samples = 15 \t 0.0\n",
      "eps = 21.3 min_samples = 16 \t 0.0\n",
      "eps = 21.3 min_samples = 17 \t 0.0\n",
      "eps = 21.3 min_samples = 18 \t 0.0\n",
      "eps = 21.3 min_samples = 19 \t 0.0\n",
      "eps = 21.400000000000002 min_samples = 5 \t 0.21616000936539545\n",
      "eps = 21.400000000000002 min_samples = 6 \t 0.20076379020135812\n",
      "eps = 21.400000000000002 min_samples = 7 \t 0.158726139700211\n",
      "eps = 21.400000000000002 min_samples = 8 \t 0.14427451987815243\n",
      "eps = 21.400000000000002 min_samples = 9 \t 0.08307453520158413\n",
      "eps = 21.400000000000002 min_samples = 10 \t 0.07094815488931999\n",
      "eps = 21.400000000000002 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 21.400000000000002 min_samples = 12 \t 0.017699799293785862\n",
      "eps = 21.400000000000002 min_samples = 13 \t 0.014804748082355396\n",
      "eps = 21.400000000000002 min_samples = 14 \t 0.014804748082355396\n",
      "eps = 21.400000000000002 min_samples = 15 \t 0.0\n",
      "eps = 21.400000000000002 min_samples = 16 \t 0.0\n",
      "eps = 21.400000000000002 min_samples = 17 \t 0.0\n",
      "eps = 21.400000000000002 min_samples = 18 \t 0.0\n",
      "eps = 21.400000000000002 min_samples = 19 \t 0.0\n",
      "eps = 21.5 min_samples = 5 \t 0.20553586430488893\n",
      "eps = 21.5 min_samples = 6 \t 0.20659632030029296\n",
      "eps = 21.5 min_samples = 7 \t 0.158726139700211\n",
      "eps = 21.5 min_samples = 8 \t 0.14427451987815243\n",
      "eps = 21.5 min_samples = 9 \t 0.08307453520158413\n",
      "eps = 21.5 min_samples = 10 \t 0.08063767739156631\n",
      "eps = 21.5 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 21.5 min_samples = 12 \t 0.017699799293785862\n",
      "eps = 21.5 min_samples = 13 \t 0.014804748082355396\n",
      "eps = 21.5 min_samples = 14 \t 0.014804748082355396\n",
      "eps = 21.5 min_samples = 15 \t 0.0\n",
      "eps = 21.5 min_samples = 16 \t 0.0\n",
      "eps = 21.5 min_samples = 17 \t 0.0\n",
      "eps = 21.5 min_samples = 18 \t 0.0\n",
      "eps = 21.5 min_samples = 19 \t 0.0\n",
      "eps = 21.6 min_samples = 5 \t 0.20553586430488893\n",
      "eps = 21.6 min_samples = 6 \t 0.20659632030029296\n",
      "eps = 21.6 min_samples = 7 \t 0.158726139700211\n",
      "eps = 21.6 min_samples = 8 \t 0.14427451987815243\n",
      "eps = 21.6 min_samples = 9 \t 0.08307453520158413\n",
      "eps = 21.6 min_samples = 10 \t 0.09055570694389738\n",
      "eps = 21.6 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 21.6 min_samples = 12 \t 0.02580905990186401\n",
      "eps = 21.6 min_samples = 13 \t 0.01822916201366507\n",
      "eps = 21.6 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 21.6 min_samples = 15 \t 0.003389187137356976\n",
      "eps = 21.6 min_samples = 16 \t 0.0\n",
      "eps = 21.6 min_samples = 17 \t 0.0\n",
      "eps = 21.6 min_samples = 18 \t 0.0\n",
      "eps = 21.6 min_samples = 19 \t 0.0\n",
      "eps = 21.700000000000003 min_samples = 5 \t 0.20553586430488893\n",
      "eps = 21.700000000000003 min_samples = 6 \t 0.2009985339761231\n",
      "eps = 21.700000000000003 min_samples = 7 \t 0.16409964149215944\n",
      "eps = 21.700000000000003 min_samples = 8 \t 0.14427451987815243\n",
      "eps = 21.700000000000003 min_samples = 9 \t 0.08827042303243739\n",
      "eps = 21.700000000000003 min_samples = 10 \t 0.09055570694389738\n",
      "eps = 21.700000000000003 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 21.700000000000003 min_samples = 12 \t 0.02580905990186401\n",
      "eps = 21.700000000000003 min_samples = 13 \t 0.01822916201366507\n",
      "eps = 21.700000000000003 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 21.700000000000003 min_samples = 15 \t 0.003389187137356976\n",
      "eps = 21.700000000000003 min_samples = 16 \t 0.0\n",
      "eps = 21.700000000000003 min_samples = 17 \t 0.0\n",
      "eps = 21.700000000000003 min_samples = 18 \t 0.0\n",
      "eps = 21.700000000000003 min_samples = 19 \t 0.0\n",
      "eps = 21.8 min_samples = 5 \t 0.20553586430488893\n",
      "eps = 21.8 min_samples = 6 \t 0.20004668596792968\n",
      "eps = 21.8 min_samples = 7 \t 0.16409964149215944\n",
      "eps = 21.8 min_samples = 8 \t 0.14427451987815243\n",
      "eps = 21.8 min_samples = 9 \t 0.08827042303243739\n",
      "eps = 21.8 min_samples = 10 \t 0.09055570694389738\n",
      "eps = 21.8 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 21.8 min_samples = 12 \t 0.02580905990186401\n",
      "eps = 21.8 min_samples = 13 \t 0.01822916201366507\n",
      "eps = 21.8 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 21.8 min_samples = 15 \t 0.003389187137356976\n",
      "eps = 21.8 min_samples = 16 \t 0.0\n",
      "eps = 21.8 min_samples = 17 \t 0.0\n",
      "eps = 21.8 min_samples = 18 \t 0.0\n",
      "eps = 21.8 min_samples = 19 \t 0.0\n",
      "eps = 21.900000000000002 min_samples = 5 \t 0.24492671339619418\n",
      "eps = 21.900000000000002 min_samples = 6 \t 0.2460466147935232\n",
      "eps = 21.900000000000002 min_samples = 7 \t 0.178775830415633\n",
      "eps = 21.900000000000002 min_samples = 8 \t 0.14427451987815243\n",
      "eps = 21.900000000000002 min_samples = 9 \t 0.08827042303243739\n",
      "eps = 21.900000000000002 min_samples = 10 \t 0.09055570694389738\n",
      "eps = 21.900000000000002 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 21.900000000000002 min_samples = 12 \t 0.02580905990186401\n",
      "eps = 21.900000000000002 min_samples = 13 \t 0.01822916201366507\n",
      "eps = 21.900000000000002 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 21.900000000000002 min_samples = 15 \t 0.003389187137356976\n",
      "eps = 21.900000000000002 min_samples = 16 \t 0.0\n",
      "eps = 21.900000000000002 min_samples = 17 \t 0.0\n",
      "eps = 21.900000000000002 min_samples = 18 \t 0.0\n",
      "eps = 21.900000000000002 min_samples = 19 \t 0.0\n",
      "eps = 22.0 min_samples = 5 \t 0.2515922345470868\n",
      "eps = 22.0 min_samples = 6 \t 0.2460466147935232\n",
      "eps = 22.0 min_samples = 7 \t 0.18229337298986395\n",
      "eps = 22.0 min_samples = 8 \t 0.14427451987815243\n",
      "eps = 22.0 min_samples = 9 \t 0.08827042303243739\n",
      "eps = 22.0 min_samples = 10 \t 0.09055570694389738\n",
      "eps = 22.0 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 22.0 min_samples = 12 \t 0.02580905990186401\n",
      "eps = 22.0 min_samples = 13 \t 0.01822916201366507\n",
      "eps = 22.0 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 22.0 min_samples = 15 \t 0.003389187137356976\n",
      "eps = 22.0 min_samples = 16 \t 0.0\n",
      "eps = 22.0 min_samples = 17 \t 0.0\n",
      "eps = 22.0 min_samples = 18 \t 0.0\n",
      "eps = 22.0 min_samples = 19 \t 0.0\n",
      "eps = 22.1 min_samples = 5 \t 0.2524996862375912\n",
      "eps = 22.1 min_samples = 6 \t 0.24678170408120456\n",
      "eps = 22.1 min_samples = 7 \t 0.18468685484569256\n",
      "eps = 22.1 min_samples = 8 \t 0.15784788797247726\n",
      "eps = 22.1 min_samples = 9 \t 0.09668010232533521\n",
      "eps = 22.1 min_samples = 10 \t 0.12345931644989865\n",
      "eps = 22.1 min_samples = 11 \t 0.02580905990186401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 22.1 min_samples = 12 \t 0.02580905990186401\n",
      "eps = 22.1 min_samples = 13 \t 0.01822916201366507\n",
      "eps = 22.1 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 22.1 min_samples = 15 \t 0.003389187137356976\n",
      "eps = 22.1 min_samples = 16 \t 0.0\n",
      "eps = 22.1 min_samples = 17 \t 0.0\n",
      "eps = 22.1 min_samples = 18 \t 0.0\n",
      "eps = 22.1 min_samples = 19 \t 0.0\n",
      "eps = 22.200000000000003 min_samples = 5 \t 0.2524996862375912\n",
      "eps = 22.200000000000003 min_samples = 6 \t 0.24678170408120456\n",
      "eps = 22.200000000000003 min_samples = 7 \t 0.18468685484569256\n",
      "eps = 22.200000000000003 min_samples = 8 \t 0.15784788797247726\n",
      "eps = 22.200000000000003 min_samples = 9 \t 0.1471648789531411\n",
      "eps = 22.200000000000003 min_samples = 10 \t 0.12345931644989865\n",
      "eps = 22.200000000000003 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 22.200000000000003 min_samples = 12 \t 0.02580905990186401\n",
      "eps = 22.200000000000003 min_samples = 13 \t 0.01822916201366507\n",
      "eps = 22.200000000000003 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 22.200000000000003 min_samples = 15 \t 0.003389187137356976\n",
      "eps = 22.200000000000003 min_samples = 16 \t 0.0\n",
      "eps = 22.200000000000003 min_samples = 17 \t 0.0\n",
      "eps = 22.200000000000003 min_samples = 18 \t 0.0\n",
      "eps = 22.200000000000003 min_samples = 19 \t 0.0\n",
      "eps = 22.3 min_samples = 5 \t 0.2524996862375912\n",
      "eps = 22.3 min_samples = 6 \t 0.24678170408120456\n",
      "eps = 22.3 min_samples = 7 \t 0.19127535662724265\n",
      "eps = 22.3 min_samples = 8 \t 0.16197231924735056\n",
      "eps = 22.3 min_samples = 9 \t 0.14903175324102583\n",
      "eps = 22.3 min_samples = 10 \t 0.15212441191795406\n",
      "eps = 22.3 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 22.3 min_samples = 12 \t 0.02580905990186401\n",
      "eps = 22.3 min_samples = 13 \t 0.01822916201366507\n",
      "eps = 22.3 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 22.3 min_samples = 15 \t 0.00292238877935216\n",
      "eps = 22.3 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 22.3 min_samples = 17 \t 0.0\n",
      "eps = 22.3 min_samples = 18 \t 0.0\n",
      "eps = 22.3 min_samples = 19 \t 0.0\n",
      "eps = 22.400000000000002 min_samples = 5 \t 0.26768278966636666\n",
      "eps = 22.400000000000002 min_samples = 6 \t 0.28861303851159237\n",
      "eps = 22.400000000000002 min_samples = 7 \t 0.20678820419699215\n",
      "eps = 22.400000000000002 min_samples = 8 \t 0.15974193817353596\n",
      "eps = 22.400000000000002 min_samples = 9 \t 0.14683943405652633\n",
      "eps = 22.400000000000002 min_samples = 10 \t 0.15733115654891602\n",
      "eps = 22.400000000000002 min_samples = 11 \t 0.02580905990186401\n",
      "eps = 22.400000000000002 min_samples = 12 \t 0.02580905990186401\n",
      "eps = 22.400000000000002 min_samples = 13 \t 0.01822916201366507\n",
      "eps = 22.400000000000002 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 22.400000000000002 min_samples = 15 \t 0.00292238877935216\n",
      "eps = 22.400000000000002 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 22.400000000000002 min_samples = 17 \t 0.0\n",
      "eps = 22.400000000000002 min_samples = 18 \t 0.0\n",
      "eps = 22.400000000000002 min_samples = 19 \t 0.0\n",
      "eps = 22.5 min_samples = 5 \t 0.26768278966636666\n",
      "eps = 22.5 min_samples = 6 \t 0.28861303851159237\n",
      "eps = 22.5 min_samples = 7 \t 0.20678820419699215\n",
      "eps = 22.5 min_samples = 8 \t 0.1653293526417011\n",
      "eps = 22.5 min_samples = 9 \t 0.1631775048894561\n",
      "eps = 22.5 min_samples = 10 \t 0.15733115654891602\n",
      "eps = 22.5 min_samples = 11 \t 0.030080625362751003\n",
      "eps = 22.5 min_samples = 12 \t 0.030080625362751003\n",
      "eps = 22.5 min_samples = 13 \t 0.022362936274554407\n",
      "eps = 22.5 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 22.5 min_samples = 15 \t 0.00292238877935216\n",
      "eps = 22.5 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 22.5 min_samples = 17 \t 0.0\n",
      "eps = 22.5 min_samples = 18 \t 0.0\n",
      "eps = 22.5 min_samples = 19 \t 0.0\n",
      "eps = 22.6 min_samples = 5 \t 0.26768278966636666\n",
      "eps = 22.6 min_samples = 6 \t 0.28861303851159237\n",
      "eps = 22.6 min_samples = 7 \t 0.26763882564463004\n",
      "eps = 22.6 min_samples = 8 \t 0.1653293526417011\n",
      "eps = 22.6 min_samples = 9 \t 0.1656642276003292\n",
      "eps = 22.6 min_samples = 10 \t 0.15733115654891602\n",
      "eps = 22.6 min_samples = 11 \t 0.03469792543724899\n",
      "eps = 22.6 min_samples = 12 \t 0.030080625362751003\n",
      "eps = 22.6 min_samples = 13 \t 0.022362936274554407\n",
      "eps = 22.6 min_samples = 14 \t 0.01822916201366507\n",
      "eps = 22.6 min_samples = 15 \t 0.00292238877935216\n",
      "eps = 22.6 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 22.6 min_samples = 17 \t 0.0\n",
      "eps = 22.6 min_samples = 18 \t 0.0\n",
      "eps = 22.6 min_samples = 19 \t 0.0\n",
      "eps = 22.700000000000003 min_samples = 5 \t 0.2812152649698522\n",
      "eps = 22.700000000000003 min_samples = 6 \t 0.2879182230642413\n",
      "eps = 22.700000000000003 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 22.700000000000003 min_samples = 8 \t 0.1653293526417011\n",
      "eps = 22.700000000000003 min_samples = 9 \t 0.1656642276003292\n",
      "eps = 22.700000000000003 min_samples = 10 \t 0.15733115654891602\n",
      "eps = 22.700000000000003 min_samples = 11 \t 0.03469792543724899\n",
      "eps = 22.700000000000003 min_samples = 12 \t 0.030080625362751003\n",
      "eps = 22.700000000000003 min_samples = 13 \t 0.02245505614367763\n",
      "eps = 22.700000000000003 min_samples = 14 \t 0.018378041982564826\n",
      "eps = 22.700000000000003 min_samples = 15 \t 0.002728285408361865\n",
      "eps = 22.700000000000003 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 22.700000000000003 min_samples = 17 \t 0.0\n",
      "eps = 22.700000000000003 min_samples = 18 \t 0.0\n",
      "eps = 22.700000000000003 min_samples = 19 \t 0.0\n",
      "eps = 22.8 min_samples = 5 \t 0.2812152649698522\n",
      "eps = 22.8 min_samples = 6 \t 0.2879182230642413\n",
      "eps = 22.8 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 22.8 min_samples = 8 \t 0.1653293526417011\n",
      "eps = 22.8 min_samples = 9 \t 0.1656642276003292\n",
      "eps = 22.8 min_samples = 10 \t 0.15733115654891602\n",
      "eps = 22.8 min_samples = 11 \t 0.03469792543724899\n",
      "eps = 22.8 min_samples = 12 \t 0.030080625362751003\n",
      "eps = 22.8 min_samples = 13 \t 0.02245505614367763\n",
      "eps = 22.8 min_samples = 14 \t 0.018378041982564826\n",
      "eps = 22.8 min_samples = 15 \t 0.002728285408361865\n",
      "eps = 22.8 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 22.8 min_samples = 17 \t 0.0\n",
      "eps = 22.8 min_samples = 18 \t 0.0\n",
      "eps = 22.8 min_samples = 19 \t 0.0\n",
      "eps = 22.900000000000002 min_samples = 5 \t 0.2812152649698522\n",
      "eps = 22.900000000000002 min_samples = 6 \t 0.2879182230642413\n",
      "eps = 22.900000000000002 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 22.900000000000002 min_samples = 8 \t 0.1653293526417011\n",
      "eps = 22.900000000000002 min_samples = 9 \t 0.1656642276003292\n",
      "eps = 22.900000000000002 min_samples = 10 \t 0.16423746204531467\n",
      "eps = 22.900000000000002 min_samples = 11 \t 0.03469792543724899\n",
      "eps = 22.900000000000002 min_samples = 12 \t 0.030080625362751003\n",
      "eps = 22.900000000000002 min_samples = 13 \t 0.022847633727993266\n",
      "eps = 22.900000000000002 min_samples = 14 \t 0.018378041982564826\n",
      "eps = 22.900000000000002 min_samples = 15 \t 0.002728285408361865\n",
      "eps = 22.900000000000002 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 22.900000000000002 min_samples = 17 \t 0.0\n",
      "eps = 22.900000000000002 min_samples = 18 \t 0.0\n",
      "eps = 22.900000000000002 min_samples = 19 \t 0.0\n",
      "eps = 23.0 min_samples = 5 \t 0.2797181055527435\n",
      "eps = 23.0 min_samples = 6 \t 0.2879182230642413\n",
      "eps = 23.0 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 23.0 min_samples = 8 \t 0.1653293526417011\n",
      "eps = 23.0 min_samples = 9 \t 0.1692285855669936\n",
      "eps = 23.0 min_samples = 10 \t 0.1854577757385656\n",
      "eps = 23.0 min_samples = 11 \t 0.04639890882511958\n",
      "eps = 23.0 min_samples = 12 \t 0.030080625362751003\n",
      "eps = 23.0 min_samples = 13 \t 0.022847633727993266\n",
      "eps = 23.0 min_samples = 14 \t 0.018378041982564826\n",
      "eps = 23.0 min_samples = 15 \t 0.002728285408361865\n",
      "eps = 23.0 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 23.0 min_samples = 17 \t 0.0\n",
      "eps = 23.0 min_samples = 18 \t 0.0\n",
      "eps = 23.0 min_samples = 19 \t 0.0\n",
      "eps = 23.1 min_samples = 5 \t 0.2830677968328494\n",
      "eps = 23.1 min_samples = 6 \t 0.2879182230642413\n",
      "eps = 23.1 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 23.1 min_samples = 8 \t 0.1653293526417011\n",
      "eps = 23.1 min_samples = 9 \t 0.1692285855669936\n",
      "eps = 23.1 min_samples = 10 \t 0.1854577757385656\n",
      "eps = 23.1 min_samples = 11 \t 0.05251070985529785\n",
      "eps = 23.1 min_samples = 12 \t 0.030080625362751003\n",
      "eps = 23.1 min_samples = 13 \t 0.02720819088052893\n",
      "eps = 23.1 min_samples = 14 \t 0.02245505614367763\n",
      "eps = 23.1 min_samples = 15 \t 0.02245505614367763\n",
      "eps = 23.1 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 23.1 min_samples = 17 \t 0.0\n",
      "eps = 23.1 min_samples = 18 \t 0.0\n",
      "eps = 23.1 min_samples = 19 \t 0.0\n",
      "eps = 23.200000000000003 min_samples = 5 \t 0.2830677968328494\n",
      "eps = 23.200000000000003 min_samples = 6 \t 0.2879182230642413\n",
      "eps = 23.200000000000003 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 23.200000000000003 min_samples = 8 \t 0.1653293526417011\n",
      "eps = 23.200000000000003 min_samples = 9 \t 0.1692285855669936\n",
      "eps = 23.200000000000003 min_samples = 10 \t 0.1854577757385656\n",
      "eps = 23.200000000000003 min_samples = 11 \t 0.06118058582599105\n",
      "eps = 23.200000000000003 min_samples = 12 \t 0.030080625362751003\n",
      "eps = 23.200000000000003 min_samples = 13 \t 0.03106578422608695\n",
      "eps = 23.200000000000003 min_samples = 14 \t 0.02245505614367763\n",
      "eps = 23.200000000000003 min_samples = 15 \t 0.02245505614367763\n",
      "eps = 23.200000000000003 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 23.200000000000003 min_samples = 17 \t 0.0\n",
      "eps = 23.200000000000003 min_samples = 18 \t 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 23.200000000000003 min_samples = 19 \t 0.0\n",
      "eps = 23.3 min_samples = 5 \t 0.2830677968328494\n",
      "eps = 23.3 min_samples = 6 \t 0.2914821558447815\n",
      "eps = 23.3 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 23.3 min_samples = 8 \t 0.1653293526417011\n",
      "eps = 23.3 min_samples = 9 \t 0.1692285855669936\n",
      "eps = 23.3 min_samples = 10 \t 0.1854577757385656\n",
      "eps = 23.3 min_samples = 11 \t 0.07120832280260699\n",
      "eps = 23.3 min_samples = 12 \t 0.030080625362751003\n",
      "eps = 23.3 min_samples = 13 \t 0.03106578422608695\n",
      "eps = 23.3 min_samples = 14 \t 0.02245505614367763\n",
      "eps = 23.3 min_samples = 15 \t 0.02245505614367763\n",
      "eps = 23.3 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 23.3 min_samples = 17 \t 0.0\n",
      "eps = 23.3 min_samples = 18 \t 0.0\n",
      "eps = 23.3 min_samples = 19 \t 0.0\n",
      "eps = 23.400000000000002 min_samples = 5 \t 0.2830677968328494\n",
      "eps = 23.400000000000002 min_samples = 6 \t 0.2914821558447815\n",
      "eps = 23.400000000000002 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 23.400000000000002 min_samples = 8 \t 0.1653293526417011\n",
      "eps = 23.400000000000002 min_samples = 9 \t 0.1692285855669936\n",
      "eps = 23.400000000000002 min_samples = 10 \t 0.1854577757385656\n",
      "eps = 23.400000000000002 min_samples = 11 \t 0.07120832280260699\n",
      "eps = 23.400000000000002 min_samples = 12 \t 0.03089191684479359\n",
      "eps = 23.400000000000002 min_samples = 13 \t 0.031570850461962674\n",
      "eps = 23.400000000000002 min_samples = 14 \t 0.027076728970156207\n",
      "eps = 23.400000000000002 min_samples = 15 \t 0.02245505614367763\n",
      "eps = 23.400000000000002 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 23.400000000000002 min_samples = 17 \t 0.0\n",
      "eps = 23.400000000000002 min_samples = 18 \t 0.0\n",
      "eps = 23.400000000000002 min_samples = 19 \t 0.0\n",
      "eps = 23.5 min_samples = 5 \t 0.2830677968328494\n",
      "eps = 23.5 min_samples = 6 \t 0.2914821558447815\n",
      "eps = 23.5 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 23.5 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 23.5 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 23.5 min_samples = 10 \t 0.22637430589195073\n",
      "eps = 23.5 min_samples = 11 \t 0.07120832280260699\n",
      "eps = 23.5 min_samples = 12 \t 0.03089191684479359\n",
      "eps = 23.5 min_samples = 13 \t 0.03089191684479359\n",
      "eps = 23.5 min_samples = 14 \t 0.027076728970156207\n",
      "eps = 23.5 min_samples = 15 \t 0.02245505614367763\n",
      "eps = 23.5 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 23.5 min_samples = 17 \t 0.0\n",
      "eps = 23.5 min_samples = 18 \t 0.0\n",
      "eps = 23.5 min_samples = 19 \t 0.0\n",
      "eps = 23.6 min_samples = 5 \t 0.2830677968328494\n",
      "eps = 23.6 min_samples = 6 \t 0.2914821558447815\n",
      "eps = 23.6 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 23.6 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 23.6 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 23.6 min_samples = 10 \t 0.23806038609060845\n",
      "eps = 23.6 min_samples = 11 \t 0.07614545107390414\n",
      "eps = 23.6 min_samples = 12 \t 0.040365703162529784\n",
      "eps = 23.6 min_samples = 13 \t 0.03089191684479359\n",
      "eps = 23.6 min_samples = 14 \t 0.027076728970156207\n",
      "eps = 23.6 min_samples = 15 \t 0.02245505614367763\n",
      "eps = 23.6 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 23.6 min_samples = 17 \t 0.0\n",
      "eps = 23.6 min_samples = 18 \t 0.0\n",
      "eps = 23.6 min_samples = 19 \t 0.0\n",
      "eps = 23.700000000000003 min_samples = 5 \t 0.2830677968328494\n",
      "eps = 23.700000000000003 min_samples = 6 \t 0.2914821558447815\n",
      "eps = 23.700000000000003 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 23.700000000000003 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 23.700000000000003 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 23.700000000000003 min_samples = 10 \t 0.23806038609060845\n",
      "eps = 23.700000000000003 min_samples = 11 \t 0.07614545107390414\n",
      "eps = 23.700000000000003 min_samples = 12 \t 0.040365703162529784\n",
      "eps = 23.700000000000003 min_samples = 13 \t 0.03089191684479359\n",
      "eps = 23.700000000000003 min_samples = 14 \t 0.027076728970156207\n",
      "eps = 23.700000000000003 min_samples = 15 \t 0.02245505614367763\n",
      "eps = 23.700000000000003 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 23.700000000000003 min_samples = 17 \t 0.0\n",
      "eps = 23.700000000000003 min_samples = 18 \t 0.0\n",
      "eps = 23.700000000000003 min_samples = 19 \t 0.0\n",
      "eps = 23.8 min_samples = 5 \t 0.2830677968328494\n",
      "eps = 23.8 min_samples = 6 \t 0.2914821558447815\n",
      "eps = 23.8 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 23.8 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 23.8 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 23.8 min_samples = 10 \t 0.23806038609060845\n",
      "eps = 23.8 min_samples = 11 \t 0.07614545107390414\n",
      "eps = 23.8 min_samples = 12 \t 0.040365703162529784\n",
      "eps = 23.8 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 23.8 min_samples = 14 \t 0.027076728970156207\n",
      "eps = 23.8 min_samples = 15 \t 0.02245505614367763\n",
      "eps = 23.8 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 23.8 min_samples = 17 \t 0.0\n",
      "eps = 23.8 min_samples = 18 \t 0.0\n",
      "eps = 23.8 min_samples = 19 \t 0.0\n",
      "eps = 23.900000000000002 min_samples = 5 \t 0.28993244611704927\n",
      "eps = 23.900000000000002 min_samples = 6 \t 0.2987071958972167\n",
      "eps = 23.900000000000002 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 23.900000000000002 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 23.900000000000002 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 23.900000000000002 min_samples = 10 \t 0.23806038609060845\n",
      "eps = 23.900000000000002 min_samples = 11 \t 0.07614545107390414\n",
      "eps = 23.900000000000002 min_samples = 12 \t 0.040365703162529784\n",
      "eps = 23.900000000000002 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 23.900000000000002 min_samples = 14 \t 0.031570850461962674\n",
      "eps = 23.900000000000002 min_samples = 15 \t 0.02245505614367763\n",
      "eps = 23.900000000000002 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 23.900000000000002 min_samples = 17 \t 0.0\n",
      "eps = 23.900000000000002 min_samples = 18 \t 0.0\n",
      "eps = 23.900000000000002 min_samples = 19 \t 0.0\n",
      "eps = 24.0 min_samples = 5 \t 0.28993244611704927\n",
      "eps = 24.0 min_samples = 6 \t 0.2987071958972167\n",
      "eps = 24.0 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 24.0 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 24.0 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 24.0 min_samples = 10 \t 0.2551983065666343\n",
      "eps = 24.0 min_samples = 11 \t 0.07614545107390414\n",
      "eps = 24.0 min_samples = 12 \t 0.040365703162529784\n",
      "eps = 24.0 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 24.0 min_samples = 14 \t 0.03641205350647418\n",
      "eps = 24.0 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 24.0 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 24.0 min_samples = 17 \t 0.0\n",
      "eps = 24.0 min_samples = 18 \t 0.0\n",
      "eps = 24.0 min_samples = 19 \t 0.0\n",
      "eps = 24.1 min_samples = 5 \t 0.28993244611704927\n",
      "eps = 24.1 min_samples = 6 \t 0.2987071958972167\n",
      "eps = 24.1 min_samples = 7 \t 0.2824794077178072\n",
      "eps = 24.1 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 24.1 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 24.1 min_samples = 10 \t 0.2551983065666343\n",
      "eps = 24.1 min_samples = 11 \t 0.07614545107390414\n",
      "eps = 24.1 min_samples = 12 \t 0.056548138989528075\n",
      "eps = 24.1 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 24.1 min_samples = 14 \t 0.03641205350647418\n",
      "eps = 24.1 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 24.1 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 24.1 min_samples = 17 \t 0.0\n",
      "eps = 24.1 min_samples = 18 \t 0.0\n",
      "eps = 24.1 min_samples = 19 \t 0.0\n",
      "eps = 24.200000000000003 min_samples = 5 \t 0.28993244611704927\n",
      "eps = 24.200000000000003 min_samples = 6 \t 0.2987071958972167\n",
      "eps = 24.200000000000003 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 24.200000000000003 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 24.200000000000003 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 24.200000000000003 min_samples = 10 \t 0.2551983065666343\n",
      "eps = 24.200000000000003 min_samples = 11 \t 0.07614545107390414\n",
      "eps = 24.200000000000003 min_samples = 12 \t 0.056548138989528075\n",
      "eps = 24.200000000000003 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 24.200000000000003 min_samples = 14 \t 0.03641205350647418\n",
      "eps = 24.200000000000003 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 24.200000000000003 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 24.200000000000003 min_samples = 17 \t 0.0\n",
      "eps = 24.200000000000003 min_samples = 18 \t 0.0\n",
      "eps = 24.200000000000003 min_samples = 19 \t 0.0\n",
      "eps = 24.3 min_samples = 5 \t 0.28993244611704927\n",
      "eps = 24.3 min_samples = 6 \t 0.2987071958972167\n",
      "eps = 24.3 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 24.3 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 24.3 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 24.3 min_samples = 10 \t 0.2551983065666343\n",
      "eps = 24.3 min_samples = 11 \t 0.07614545107390414\n",
      "eps = 24.3 min_samples = 12 \t 0.06313749574103895\n",
      "eps = 24.3 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 24.3 min_samples = 14 \t 0.04160415325597694\n",
      "eps = 24.3 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 24.3 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 24.3 min_samples = 17 \t 0.0\n",
      "eps = 24.3 min_samples = 18 \t 0.0\n",
      "eps = 24.3 min_samples = 19 \t 0.0\n",
      "eps = 24.400000000000002 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 24.400000000000002 min_samples = 6 \t 0.3002779168587494\n",
      "eps = 24.400000000000002 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 24.400000000000002 min_samples = 8 \t 0.18228994172389365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 24.400000000000002 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 24.400000000000002 min_samples = 10 \t 0.2551983065666343\n",
      "eps = 24.400000000000002 min_samples = 11 \t 0.08524238018499276\n",
      "eps = 24.400000000000002 min_samples = 12 \t 0.06313749574103895\n",
      "eps = 24.400000000000002 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 24.400000000000002 min_samples = 14 \t 0.04160415325597694\n",
      "eps = 24.400000000000002 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 24.400000000000002 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 24.400000000000002 min_samples = 17 \t 0.0\n",
      "eps = 24.400000000000002 min_samples = 18 \t 0.0\n",
      "eps = 24.400000000000002 min_samples = 19 \t 0.0\n",
      "eps = 24.5 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 24.5 min_samples = 6 \t 0.3002779168587494\n",
      "eps = 24.5 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 24.5 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 24.5 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 24.5 min_samples = 10 \t 0.2551983065666343\n",
      "eps = 24.5 min_samples = 11 \t 0.08524238018499276\n",
      "eps = 24.5 min_samples = 12 \t 0.06313749574103895\n",
      "eps = 24.5 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 24.5 min_samples = 14 \t 0.04160415325597694\n",
      "eps = 24.5 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 24.5 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 24.5 min_samples = 17 \t 0.0\n",
      "eps = 24.5 min_samples = 18 \t 0.0\n",
      "eps = 24.5 min_samples = 19 \t 0.0\n",
      "eps = 24.6 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 24.6 min_samples = 6 \t 0.3002779168587494\n",
      "eps = 24.6 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 24.6 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 24.6 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 24.6 min_samples = 10 \t 0.2708002174824593\n",
      "eps = 24.6 min_samples = 11 \t 0.11804741836223719\n",
      "eps = 24.6 min_samples = 12 \t 0.06313749574103895\n",
      "eps = 24.6 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 24.6 min_samples = 14 \t 0.04160415325597694\n",
      "eps = 24.6 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 24.6 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 24.6 min_samples = 17 \t 0.0\n",
      "eps = 24.6 min_samples = 18 \t 0.0\n",
      "eps = 24.6 min_samples = 19 \t 0.0\n",
      "eps = 24.700000000000003 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 24.700000000000003 min_samples = 6 \t 0.3002779168587494\n",
      "eps = 24.700000000000003 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 24.700000000000003 min_samples = 8 \t 0.18228994172389365\n",
      "eps = 24.700000000000003 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 24.700000000000003 min_samples = 10 \t 0.2708002174824593\n",
      "eps = 24.700000000000003 min_samples = 11 \t 0.13590762411758825\n",
      "eps = 24.700000000000003 min_samples = 12 \t 0.06313749574103895\n",
      "eps = 24.700000000000003 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 24.700000000000003 min_samples = 14 \t 0.04160415325597694\n",
      "eps = 24.700000000000003 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 24.700000000000003 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 24.700000000000003 min_samples = 17 \t 0.0\n",
      "eps = 24.700000000000003 min_samples = 18 \t 0.0\n",
      "eps = 24.700000000000003 min_samples = 19 \t 0.0\n",
      "eps = 24.8 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 24.8 min_samples = 6 \t 0.3002779168587494\n",
      "eps = 24.8 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 24.8 min_samples = 8 \t 0.18004128119528595\n",
      "eps = 24.8 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 24.8 min_samples = 10 \t 0.2708002174824593\n",
      "eps = 24.8 min_samples = 11 \t 0.13590762411758825\n",
      "eps = 24.8 min_samples = 12 \t 0.06313749574103895\n",
      "eps = 24.8 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 24.8 min_samples = 14 \t 0.04160415325597694\n",
      "eps = 24.8 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 24.8 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 24.8 min_samples = 17 \t 0.0\n",
      "eps = 24.8 min_samples = 18 \t 0.0\n",
      "eps = 24.8 min_samples = 19 \t 0.0\n",
      "eps = 24.900000000000002 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 24.900000000000002 min_samples = 6 \t 0.3002779168587494\n",
      "eps = 24.900000000000002 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 24.900000000000002 min_samples = 8 \t 0.18004128119528595\n",
      "eps = 24.900000000000002 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 24.900000000000002 min_samples = 10 \t 0.2708002174824593\n",
      "eps = 24.900000000000002 min_samples = 11 \t 0.13590762411758825\n",
      "eps = 24.900000000000002 min_samples = 12 \t 0.06313749574103895\n",
      "eps = 24.900000000000002 min_samples = 13 \t 0.040365703162529784\n",
      "eps = 24.900000000000002 min_samples = 14 \t 0.04160415325597694\n",
      "eps = 24.900000000000002 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 24.900000000000002 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 24.900000000000002 min_samples = 17 \t 0.0\n",
      "eps = 24.900000000000002 min_samples = 18 \t 0.0\n",
      "eps = 24.900000000000002 min_samples = 19 \t 0.0\n",
      "eps = 25.0 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 25.0 min_samples = 6 \t 0.3002779168587494\n",
      "eps = 25.0 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 25.0 min_samples = 8 \t 0.18295735910668942\n",
      "eps = 25.0 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 25.0 min_samples = 10 \t 0.2708002174824593\n",
      "eps = 25.0 min_samples = 11 \t 0.18393320966458923\n",
      "eps = 25.0 min_samples = 12 \t 0.06582783713254309\n",
      "eps = 25.0 min_samples = 13 \t 0.05910970822069591\n",
      "eps = 25.0 min_samples = 14 \t 0.04160415325597694\n",
      "eps = 25.0 min_samples = 15 \t 0.03162995140308045\n",
      "eps = 25.0 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 25.0 min_samples = 17 \t 0.0\n",
      "eps = 25.0 min_samples = 18 \t 0.0\n",
      "eps = 25.0 min_samples = 19 \t 0.0\n",
      "eps = 25.1 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 25.1 min_samples = 6 \t 0.3002779168587494\n",
      "eps = 25.1 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 25.1 min_samples = 8 \t 0.18295735910668942\n",
      "eps = 25.1 min_samples = 9 \t 0.18600007053732667\n",
      "eps = 25.1 min_samples = 10 \t 0.2708002174824593\n",
      "eps = 25.1 min_samples = 11 \t 0.18393320966458923\n",
      "eps = 25.1 min_samples = 12 \t 0.06582783713254309\n",
      "eps = 25.1 min_samples = 13 \t 0.05910970822069591\n",
      "eps = 25.1 min_samples = 14 \t 0.04160415325597694\n",
      "eps = 25.1 min_samples = 15 \t 0.03191237331491448\n",
      "eps = 25.1 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 25.1 min_samples = 17 \t 0.0\n",
      "eps = 25.1 min_samples = 18 \t 0.0\n",
      "eps = 25.1 min_samples = 19 \t 0.0\n",
      "eps = 25.200000000000003 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 25.200000000000003 min_samples = 6 \t 0.3002779168587494\n",
      "eps = 25.200000000000003 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 25.200000000000003 min_samples = 8 \t 0.18295735910668942\n",
      "eps = 25.200000000000003 min_samples = 9 \t 0.18396405263226573\n",
      "eps = 25.200000000000003 min_samples = 10 \t 0.21995417804914233\n",
      "eps = 25.200000000000003 min_samples = 11 \t 0.18393320966458923\n",
      "eps = 25.200000000000003 min_samples = 12 \t 0.06582783713254309\n",
      "eps = 25.200000000000003 min_samples = 13 \t 0.05910970822069591\n",
      "eps = 25.200000000000003 min_samples = 14 \t 0.04160415325597694\n",
      "eps = 25.200000000000003 min_samples = 15 \t 0.03191237331491448\n",
      "eps = 25.200000000000003 min_samples = 16 \t 0.00292238877935216\n",
      "eps = 25.200000000000003 min_samples = 17 \t 0.0\n",
      "eps = 25.200000000000003 min_samples = 18 \t 0.0\n",
      "eps = 25.200000000000003 min_samples = 19 \t 0.0\n",
      "eps = 25.3 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 25.3 min_samples = 6 \t 0.3002779168587494\n",
      "eps = 25.3 min_samples = 7 \t 0.28979428859210626\n",
      "eps = 25.3 min_samples = 8 \t 0.224074122649008\n",
      "eps = 25.3 min_samples = 9 \t 0.1868612245794787\n",
      "eps = 25.3 min_samples = 10 \t 0.18396405263226573\n",
      "eps = 25.3 min_samples = 11 \t 0.18393320966458923\n",
      "eps = 25.3 min_samples = 12 \t 0.06582783713254309\n",
      "eps = 25.3 min_samples = 13 \t 0.05910970822069591\n",
      "eps = 25.3 min_samples = 14 \t 0.040365703162529784\n",
      "eps = 25.3 min_samples = 15 \t 0.03696402074343708\n",
      "eps = 25.3 min_samples = 16 \t 0.026834945587130628\n",
      "eps = 25.3 min_samples = 17 \t 0.0\n",
      "eps = 25.3 min_samples = 18 \t 0.0\n",
      "eps = 25.3 min_samples = 19 \t 0.0\n",
      "eps = 25.400000000000002 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 25.400000000000002 min_samples = 6 \t 0.2987330173203814\n",
      "eps = 25.400000000000002 min_samples = 7 \t 0.288544491880282\n",
      "eps = 25.400000000000002 min_samples = 8 \t 0.2231398407105287\n",
      "eps = 25.400000000000002 min_samples = 9 \t 0.18183051244143247\n",
      "eps = 25.400000000000002 min_samples = 10 \t 0.18228994172389365\n",
      "eps = 25.400000000000002 min_samples = 11 \t 0.1832909600697825\n",
      "eps = 25.400000000000002 min_samples = 12 \t 0.09616611288442914\n",
      "eps = 25.400000000000002 min_samples = 13 \t 0.06202303650349245\n",
      "eps = 25.400000000000002 min_samples = 14 \t 0.06202303650349245\n",
      "eps = 25.400000000000002 min_samples = 15 \t 0.03696402074343708\n",
      "eps = 25.400000000000002 min_samples = 16 \t 0.026834945587130628\n",
      "eps = 25.400000000000002 min_samples = 17 \t 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 25.400000000000002 min_samples = 18 \t 0.0\n",
      "eps = 25.400000000000002 min_samples = 19 \t 0.0\n",
      "eps = 25.5 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 25.5 min_samples = 6 \t 0.2987330173203814\n",
      "eps = 25.5 min_samples = 7 \t 0.288544491880282\n",
      "eps = 25.5 min_samples = 8 \t 0.2600431162843535\n",
      "eps = 25.5 min_samples = 9 \t 0.18183051244143247\n",
      "eps = 25.5 min_samples = 10 \t 0.18228994172389365\n",
      "eps = 25.5 min_samples = 11 \t 0.1832909600697825\n",
      "eps = 25.5 min_samples = 12 \t 0.09616611288442914\n",
      "eps = 25.5 min_samples = 13 \t 0.06887307904625202\n",
      "eps = 25.5 min_samples = 14 \t 0.06202303650349245\n",
      "eps = 25.5 min_samples = 15 \t 0.03696402074343708\n",
      "eps = 25.5 min_samples = 16 \t 0.02687105409545025\n",
      "eps = 25.5 min_samples = 17 \t 0.002728285408361865\n",
      "eps = 25.5 min_samples = 18 \t 0.0\n",
      "eps = 25.5 min_samples = 19 \t 0.0\n",
      "eps = 25.6 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 25.6 min_samples = 6 \t 0.2987330173203814\n",
      "eps = 25.6 min_samples = 7 \t 0.288544491880282\n",
      "eps = 25.6 min_samples = 8 \t 0.2600431162843535\n",
      "eps = 25.6 min_samples = 9 \t 0.18183051244143247\n",
      "eps = 25.6 min_samples = 10 \t 0.18228994172389365\n",
      "eps = 25.6 min_samples = 11 \t 0.1832909600697825\n",
      "eps = 25.6 min_samples = 12 \t 0.10742860129477527\n",
      "eps = 25.6 min_samples = 13 \t 0.06887307904625202\n",
      "eps = 25.6 min_samples = 14 \t 0.06202303650349245\n",
      "eps = 25.6 min_samples = 15 \t 0.03696402074343708\n",
      "eps = 25.6 min_samples = 16 \t 0.02687105409545025\n",
      "eps = 25.6 min_samples = 17 \t 0.002728285408361865\n",
      "eps = 25.6 min_samples = 18 \t 0.0\n",
      "eps = 25.6 min_samples = 19 \t 0.0\n",
      "eps = 25.700000000000003 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 25.700000000000003 min_samples = 6 \t 0.2987330173203814\n",
      "eps = 25.700000000000003 min_samples = 7 \t 0.29612387239841104\n",
      "eps = 25.700000000000003 min_samples = 8 \t 0.2600431162843535\n",
      "eps = 25.700000000000003 min_samples = 9 \t 0.19399510962345978\n",
      "eps = 25.700000000000003 min_samples = 10 \t 0.18228994172389365\n",
      "eps = 25.700000000000003 min_samples = 11 \t 0.18950836118577205\n",
      "eps = 25.700000000000003 min_samples = 12 \t 0.11607674764122226\n",
      "eps = 25.700000000000003 min_samples = 13 \t 0.06887307904625202\n",
      "eps = 25.700000000000003 min_samples = 14 \t 0.06202303650349245\n",
      "eps = 25.700000000000003 min_samples = 15 \t 0.04160415325597694\n",
      "eps = 25.700000000000003 min_samples = 16 \t 0.03106578422608695\n",
      "eps = 25.700000000000003 min_samples = 17 \t 0.002728285408361865\n",
      "eps = 25.700000000000003 min_samples = 18 \t 0.0\n",
      "eps = 25.700000000000003 min_samples = 19 \t 0.0\n",
      "eps = 25.8 min_samples = 5 \t 0.29707739612695294\n",
      "eps = 25.8 min_samples = 6 \t 0.2987330173203814\n",
      "eps = 25.8 min_samples = 7 \t 0.2968557278302087\n",
      "eps = 25.8 min_samples = 8 \t 0.26837487583718234\n",
      "eps = 25.8 min_samples = 9 \t 0.19399510962345978\n",
      "eps = 25.8 min_samples = 10 \t 0.18519323863390996\n",
      "eps = 25.8 min_samples = 11 \t 0.18950836118577205\n",
      "eps = 25.8 min_samples = 12 \t 0.11607674764122226\n",
      "eps = 25.8 min_samples = 13 \t 0.06887307904625202\n",
      "eps = 25.8 min_samples = 14 \t 0.06202303650349245\n",
      "eps = 25.8 min_samples = 15 \t 0.04160415325597694\n",
      "eps = 25.8 min_samples = 16 \t 0.03106578422608695\n",
      "eps = 25.8 min_samples = 17 \t 0.002728285408361865\n",
      "eps = 25.8 min_samples = 18 \t 0.0\n",
      "eps = 25.8 min_samples = 19 \t 0.0\n",
      "eps = 25.900000000000002 min_samples = 5 \t 0.29469115202959606\n",
      "eps = 25.900000000000002 min_samples = 6 \t 0.2987330173203814\n",
      "eps = 25.900000000000002 min_samples = 7 \t 0.2968557278302087\n",
      "eps = 25.900000000000002 min_samples = 8 \t 0.26837487583718234\n",
      "eps = 25.900000000000002 min_samples = 9 \t 0.23485123129855023\n",
      "eps = 25.900000000000002 min_samples = 10 \t 0.18519323863390996\n",
      "eps = 25.900000000000002 min_samples = 11 \t 0.18950836118577205\n",
      "eps = 25.900000000000002 min_samples = 12 \t 0.11645829797692525\n",
      "eps = 25.900000000000002 min_samples = 13 \t 0.06887307904625202\n",
      "eps = 25.900000000000002 min_samples = 14 \t 0.06202303650349245\n",
      "eps = 25.900000000000002 min_samples = 15 \t 0.04160415325597694\n",
      "eps = 25.900000000000002 min_samples = 16 \t 0.031570850461962674\n",
      "eps = 25.900000000000002 min_samples = 17 \t 0.00573674127536055\n",
      "eps = 25.900000000000002 min_samples = 18 \t 0.0\n",
      "eps = 25.900000000000002 min_samples = 19 \t 0.0\n",
      "eps = 26.0 min_samples = 5 \t 0.29469115202959606\n",
      "eps = 26.0 min_samples = 6 \t 0.2797181055527435\n",
      "eps = 26.0 min_samples = 7 \t 0.2963688625765011\n",
      "eps = 26.0 min_samples = 8 \t 0.27132487042436787\n",
      "eps = 26.0 min_samples = 9 \t 0.23865019155923334\n",
      "eps = 26.0 min_samples = 10 \t 0.1912672158245538\n",
      "eps = 26.0 min_samples = 11 \t 0.19612249327014256\n",
      "eps = 26.0 min_samples = 12 \t 0.12290140507719191\n",
      "eps = 26.0 min_samples = 13 \t 0.07403591051347637\n",
      "eps = 26.0 min_samples = 14 \t 0.06703802654032727\n",
      "eps = 26.0 min_samples = 15 \t 0.045631472956387704\n",
      "eps = 26.0 min_samples = 16 \t 0.04160415325597694\n",
      "eps = 26.0 min_samples = 17 \t 0.00573674127536055\n",
      "eps = 26.0 min_samples = 18 \t 0.0\n",
      "eps = 26.0 min_samples = 19 \t 0.0\n",
      "eps = 26.1 min_samples = 5 \t 0.29469115202959606\n",
      "eps = 26.1 min_samples = 6 \t 0.2797181055527435\n",
      "eps = 26.1 min_samples = 7 \t 0.2963688625765011\n",
      "eps = 26.1 min_samples = 8 \t 0.2797393266888249\n",
      "eps = 26.1 min_samples = 9 \t 0.23865019155923334\n",
      "eps = 26.1 min_samples = 10 \t 0.1912672158245538\n",
      "eps = 26.1 min_samples = 11 \t 0.19612249327014256\n",
      "eps = 26.1 min_samples = 12 \t 0.12290140507719191\n",
      "eps = 26.1 min_samples = 13 \t 0.07403591051347637\n",
      "eps = 26.1 min_samples = 14 \t 0.06703802654032727\n",
      "eps = 26.1 min_samples = 15 \t 0.045631472956387704\n",
      "eps = 26.1 min_samples = 16 \t 0.04160415325597694\n",
      "eps = 26.1 min_samples = 17 \t 0.00573674127536055\n",
      "eps = 26.1 min_samples = 18 \t 0.0\n",
      "eps = 26.1 min_samples = 19 \t 0.0\n",
      "eps = 26.200000000000003 min_samples = 5 \t 0.29469115202959606\n",
      "eps = 26.200000000000003 min_samples = 6 \t 0.2797181055527435\n",
      "eps = 26.200000000000003 min_samples = 7 \t 0.29742941641149856\n",
      "eps = 26.200000000000003 min_samples = 8 \t 0.2797393266888249\n",
      "eps = 26.200000000000003 min_samples = 9 \t 0.23865019155923334\n",
      "eps = 26.200000000000003 min_samples = 10 \t 0.18846449463493017\n",
      "eps = 26.200000000000003 min_samples = 11 \t 0.19612249327014256\n",
      "eps = 26.200000000000003 min_samples = 12 \t 0.12290140507719191\n",
      "eps = 26.200000000000003 min_samples = 13 \t 0.07403591051347637\n",
      "eps = 26.200000000000003 min_samples = 14 \t 0.06703802654032727\n",
      "eps = 26.200000000000003 min_samples = 15 \t 0.045631472956387704\n",
      "eps = 26.200000000000003 min_samples = 16 \t 0.04160415325597694\n",
      "eps = 26.200000000000003 min_samples = 17 \t 0.00573674127536055\n",
      "eps = 26.200000000000003 min_samples = 18 \t 0.0028109650661179457\n",
      "eps = 26.200000000000003 min_samples = 19 \t 0.0\n",
      "eps = 26.3 min_samples = 5 \t 0.28161785780360943\n",
      "eps = 26.3 min_samples = 6 \t 0.2698815927506256\n",
      "eps = 26.3 min_samples = 7 \t 0.2983445664791074\n",
      "eps = 26.3 min_samples = 8 \t 0.2833867611135268\n",
      "eps = 26.3 min_samples = 9 \t 0.23865019155923334\n",
      "eps = 26.3 min_samples = 10 \t 0.18846449463493017\n",
      "eps = 26.3 min_samples = 11 \t 0.19612249327014256\n",
      "eps = 26.3 min_samples = 12 \t 0.12290140507719191\n",
      "eps = 26.3 min_samples = 13 \t 0.07403591051347637\n",
      "eps = 26.3 min_samples = 14 \t 0.06703802654032727\n",
      "eps = 26.3 min_samples = 15 \t 0.045631472956387704\n",
      "eps = 26.3 min_samples = 16 \t 0.04160415325597694\n",
      "eps = 26.3 min_samples = 17 \t 0.00573674127536055\n",
      "eps = 26.3 min_samples = 18 \t 0.0028109650661179457\n",
      "eps = 26.3 min_samples = 19 \t 0.0\n",
      "eps = 26.400000000000002 min_samples = 5 \t 0.28161785780360943\n",
      "eps = 26.400000000000002 min_samples = 6 \t 0.2698815927506256\n",
      "eps = 26.400000000000002 min_samples = 7 \t 0.2983445664791074\n",
      "eps = 26.400000000000002 min_samples = 8 \t 0.2833867611135268\n",
      "eps = 26.400000000000002 min_samples = 9 \t 0.23865019155923334\n",
      "eps = 26.400000000000002 min_samples = 10 \t 0.18846449463493017\n",
      "eps = 26.400000000000002 min_samples = 11 \t 0.19612249327014256\n",
      "eps = 26.400000000000002 min_samples = 12 \t 0.12973123598691116\n",
      "eps = 26.400000000000002 min_samples = 13 \t 0.07403591051347637\n",
      "eps = 26.400000000000002 min_samples = 14 \t 0.06703802654032727\n",
      "eps = 26.400000000000002 min_samples = 15 \t 0.045631472956387704\n",
      "eps = 26.400000000000002 min_samples = 16 \t 0.04160415325597694\n",
      "eps = 26.400000000000002 min_samples = 17 \t 0.00573674127536055\n",
      "eps = 26.400000000000002 min_samples = 18 \t 0.0028109650661179457\n",
      "eps = 26.400000000000002 min_samples = 19 \t 0.0\n",
      "eps = 26.5 min_samples = 5 \t 0.28161785780360943\n",
      "eps = 26.5 min_samples = 6 \t 0.2698815927506256\n",
      "eps = 26.5 min_samples = 7 \t 0.2983445664791074\n",
      "eps = 26.5 min_samples = 8 \t 0.2833867611135268\n",
      "eps = 26.5 min_samples = 9 \t 0.23865019155923334\n",
      "eps = 26.5 min_samples = 10 \t 0.18846449463493017\n",
      "eps = 26.5 min_samples = 11 \t 0.19612249327014256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 26.5 min_samples = 12 \t 0.12973123598691116\n",
      "eps = 26.5 min_samples = 13 \t 0.07403591051347637\n",
      "eps = 26.5 min_samples = 14 \t 0.07124549540377832\n",
      "eps = 26.5 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 26.5 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 26.5 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 26.5 min_samples = 18 \t 0.0028109650661179457\n",
      "eps = 26.5 min_samples = 19 \t 0.0\n",
      "eps = 26.6 min_samples = 5 \t 0.28161785780360943\n",
      "eps = 26.6 min_samples = 6 \t 0.2698815927506256\n",
      "eps = 26.6 min_samples = 7 \t 0.2983445664791074\n",
      "eps = 26.6 min_samples = 8 \t 0.2833867611135268\n",
      "eps = 26.6 min_samples = 9 \t 0.23865019155923334\n",
      "eps = 26.6 min_samples = 10 \t 0.18846449463493017\n",
      "eps = 26.6 min_samples = 11 \t 0.19612249327014256\n",
      "eps = 26.6 min_samples = 12 \t 0.12973123598691116\n",
      "eps = 26.6 min_samples = 13 \t 0.07403591051347637\n",
      "eps = 26.6 min_samples = 14 \t 0.07124549540377832\n",
      "eps = 26.6 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 26.6 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 26.6 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 26.6 min_samples = 18 \t 0.0028109650661179457\n",
      "eps = 26.6 min_samples = 19 \t 0.0\n",
      "eps = 26.700000000000003 min_samples = 5 \t 0.2818000847284245\n",
      "eps = 26.700000000000003 min_samples = 6 \t 0.2694385364970712\n",
      "eps = 26.700000000000003 min_samples = 7 \t 0.2983445664791074\n",
      "eps = 26.700000000000003 min_samples = 8 \t 0.28645998772837156\n",
      "eps = 26.700000000000003 min_samples = 9 \t 0.23865019155923334\n",
      "eps = 26.700000000000003 min_samples = 10 \t 0.18846449463493017\n",
      "eps = 26.700000000000003 min_samples = 11 \t 0.19919602727429336\n",
      "eps = 26.700000000000003 min_samples = 12 \t 0.13042966415330112\n",
      "eps = 26.700000000000003 min_samples = 13 \t 0.07855697022269133\n",
      "eps = 26.700000000000003 min_samples = 14 \t 0.07124549540377832\n",
      "eps = 26.700000000000003 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 26.700000000000003 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 26.700000000000003 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 26.700000000000003 min_samples = 18 \t 0.005502525253746608\n",
      "eps = 26.700000000000003 min_samples = 19 \t 0.005502525253746608\n",
      "eps = 26.8 min_samples = 5 \t 0.2818000847284245\n",
      "eps = 26.8 min_samples = 6 \t 0.2694385364970712\n",
      "eps = 26.8 min_samples = 7 \t 0.2983445664791074\n",
      "eps = 26.8 min_samples = 8 \t 0.28645998772837156\n",
      "eps = 26.8 min_samples = 9 \t 0.2461014226935655\n",
      "eps = 26.8 min_samples = 10 \t 0.18846449463493017\n",
      "eps = 26.8 min_samples = 11 \t 0.19919602727429336\n",
      "eps = 26.8 min_samples = 12 \t 0.1361239293615368\n",
      "eps = 26.8 min_samples = 13 \t 0.07855697022269133\n",
      "eps = 26.8 min_samples = 14 \t 0.07124549540377832\n",
      "eps = 26.8 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 26.8 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 26.8 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 26.8 min_samples = 18 \t 0.005502525253746608\n",
      "eps = 26.8 min_samples = 19 \t 0.005502525253746608\n",
      "eps = 26.900000000000002 min_samples = 5 \t 0.2818000847284245\n",
      "eps = 26.900000000000002 min_samples = 6 \t 0.2694385364970712\n",
      "eps = 26.900000000000002 min_samples = 7 \t 0.2983445664791074\n",
      "eps = 26.900000000000002 min_samples = 8 \t 0.28645998772837156\n",
      "eps = 26.900000000000002 min_samples = 9 \t 0.2461014226935655\n",
      "eps = 26.900000000000002 min_samples = 10 \t 0.19026973491394555\n",
      "eps = 26.900000000000002 min_samples = 11 \t 0.2061285839747621\n",
      "eps = 26.900000000000002 min_samples = 12 \t 0.1361239293615368\n",
      "eps = 26.900000000000002 min_samples = 13 \t 0.1176632891568803\n",
      "eps = 26.900000000000002 min_samples = 14 \t 0.07124549540377832\n",
      "eps = 26.900000000000002 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 26.900000000000002 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 26.900000000000002 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 26.900000000000002 min_samples = 18 \t 0.005502525253746608\n",
      "eps = 26.900000000000002 min_samples = 19 \t 0.005502525253746608\n",
      "eps = 27.0 min_samples = 5 \t 0.2818000847284245\n",
      "eps = 27.0 min_samples = 6 \t 0.2694385364970712\n",
      "eps = 27.0 min_samples = 7 \t 0.2983445664791074\n",
      "eps = 27.0 min_samples = 8 \t 0.28645998772837156\n",
      "eps = 27.0 min_samples = 9 \t 0.2461014226935655\n",
      "eps = 27.0 min_samples = 10 \t 0.19026973491394555\n",
      "eps = 27.0 min_samples = 11 \t 0.2061285839747621\n",
      "eps = 27.0 min_samples = 12 \t 0.15297965781151784\n",
      "eps = 27.0 min_samples = 13 \t 0.1176632891568803\n",
      "eps = 27.0 min_samples = 14 \t 0.07124549540377832\n",
      "eps = 27.0 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 27.0 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 27.0 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 27.0 min_samples = 18 \t 0.005502525253746608\n",
      "eps = 27.0 min_samples = 19 \t 0.005502525253746608\n",
      "eps = 27.1 min_samples = 5 \t 0.2818000847284245\n",
      "eps = 27.1 min_samples = 6 \t 0.2694385364970712\n",
      "eps = 27.1 min_samples = 7 \t 0.2983445664791074\n",
      "eps = 27.1 min_samples = 8 \t 0.28645998772837156\n",
      "eps = 27.1 min_samples = 9 \t 0.25000897112700937\n",
      "eps = 27.1 min_samples = 10 \t 0.19026973491394555\n",
      "eps = 27.1 min_samples = 11 \t 0.2061285839747621\n",
      "eps = 27.1 min_samples = 12 \t 0.20543093876759855\n",
      "eps = 27.1 min_samples = 13 \t 0.1176632891568803\n",
      "eps = 27.1 min_samples = 14 \t 0.07124549540377832\n",
      "eps = 27.1 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 27.1 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 27.1 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 27.1 min_samples = 18 \t 0.005502525253746608\n",
      "eps = 27.1 min_samples = 19 \t 0.005502525253746608\n",
      "eps = 27.200000000000003 min_samples = 5 \t 0.2818000847284245\n",
      "eps = 27.200000000000003 min_samples = 6 \t 0.28289102697188656\n",
      "eps = 27.200000000000003 min_samples = 7 \t 0.2983445664791074\n",
      "eps = 27.200000000000003 min_samples = 8 \t 0.294789461353248\n",
      "eps = 27.200000000000003 min_samples = 9 \t 0.2571772586169324\n",
      "eps = 27.200000000000003 min_samples = 10 \t 0.2509819080849893\n",
      "eps = 27.200000000000003 min_samples = 11 \t 0.2061285839747621\n",
      "eps = 27.200000000000003 min_samples = 12 \t 0.20543093876759855\n",
      "eps = 27.200000000000003 min_samples = 13 \t 0.1176632891568803\n",
      "eps = 27.200000000000003 min_samples = 14 \t 0.07403591051347637\n",
      "eps = 27.200000000000003 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 27.200000000000003 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 27.200000000000003 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 27.200000000000003 min_samples = 18 \t 0.00573674127536055\n",
      "eps = 27.200000000000003 min_samples = 19 \t 0.00573674127536055\n",
      "eps = 27.3 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 27.3 min_samples = 6 \t 0.28289102697188656\n",
      "eps = 27.3 min_samples = 7 \t 0.3060866331684706\n",
      "eps = 27.3 min_samples = 8 \t 0.3034164240068025\n",
      "eps = 27.3 min_samples = 9 \t 0.2571772586169324\n",
      "eps = 27.3 min_samples = 10 \t 0.2509819080849893\n",
      "eps = 27.3 min_samples = 11 \t 0.2061285839747621\n",
      "eps = 27.3 min_samples = 12 \t 0.20680626739891758\n",
      "eps = 27.3 min_samples = 13 \t 0.12350269086434834\n",
      "eps = 27.3 min_samples = 14 \t 0.1184122307407369\n",
      "eps = 27.3 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 27.3 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 27.3 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 27.3 min_samples = 18 \t 0.00573674127536055\n",
      "eps = 27.3 min_samples = 19 \t 0.00573674127536055\n",
      "eps = 27.400000000000002 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 27.400000000000002 min_samples = 6 \t 0.28289102697188656\n",
      "eps = 27.400000000000002 min_samples = 7 \t 0.3060866331684706\n",
      "eps = 27.400000000000002 min_samples = 8 \t 0.3074866352962857\n",
      "eps = 27.400000000000002 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 27.400000000000002 min_samples = 10 \t 0.2810222437767688\n",
      "eps = 27.400000000000002 min_samples = 11 \t 0.23011256216392667\n",
      "eps = 27.400000000000002 min_samples = 12 \t 0.23674971745574017\n",
      "eps = 27.400000000000002 min_samples = 13 \t 0.12864879270165064\n",
      "eps = 27.400000000000002 min_samples = 14 \t 0.12864879270165064\n",
      "eps = 27.400000000000002 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 27.400000000000002 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 27.400000000000002 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 27.400000000000002 min_samples = 18 \t 0.00573674127536055\n",
      "eps = 27.400000000000002 min_samples = 19 \t 0.00573674127536055\n",
      "eps = 27.5 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 27.5 min_samples = 6 \t 0.28289102697188656\n",
      "eps = 27.5 min_samples = 7 \t 0.29346097023957446\n",
      "eps = 27.5 min_samples = 8 \t 0.3074866352962857\n",
      "eps = 27.5 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 27.5 min_samples = 10 \t 0.2810222437767688\n",
      "eps = 27.5 min_samples = 11 \t 0.23011256216392667\n",
      "eps = 27.5 min_samples = 12 \t 0.23674971745574017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 27.5 min_samples = 13 \t 0.14518154168715763\n",
      "eps = 27.5 min_samples = 14 \t 0.12864879270165064\n",
      "eps = 27.5 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 27.5 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 27.5 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 27.5 min_samples = 18 \t 0.00573674127536055\n",
      "eps = 27.5 min_samples = 19 \t 0.00573674127536055\n",
      "eps = 27.6 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 27.6 min_samples = 6 \t 0.28289102697188656\n",
      "eps = 27.6 min_samples = 7 \t 0.29346097023957446\n",
      "eps = 27.6 min_samples = 8 \t 0.3074866352962857\n",
      "eps = 27.6 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 27.6 min_samples = 10 \t 0.2810222437767688\n",
      "eps = 27.6 min_samples = 11 \t 0.23011256216392667\n",
      "eps = 27.6 min_samples = 12 \t 0.23674971745574017\n",
      "eps = 27.6 min_samples = 13 \t 0.14518154168715763\n",
      "eps = 27.6 min_samples = 14 \t 0.12864879270165064\n",
      "eps = 27.6 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 27.6 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 27.6 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 27.6 min_samples = 18 \t 0.00573674127536055\n",
      "eps = 27.6 min_samples = 19 \t 0.00573674127536055\n",
      "eps = 27.700000000000003 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 27.700000000000003 min_samples = 6 \t 0.28289102697188656\n",
      "eps = 27.700000000000003 min_samples = 7 \t 0.28682347535271474\n",
      "eps = 27.700000000000003 min_samples = 8 \t 0.3074866352962857\n",
      "eps = 27.700000000000003 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 27.700000000000003 min_samples = 10 \t 0.2810222437767688\n",
      "eps = 27.700000000000003 min_samples = 11 \t 0.23011256216392667\n",
      "eps = 27.700000000000003 min_samples = 12 \t 0.23674971745574017\n",
      "eps = 27.700000000000003 min_samples = 13 \t 0.14518154168715763\n",
      "eps = 27.700000000000003 min_samples = 14 \t 0.12864879270165064\n",
      "eps = 27.700000000000003 min_samples = 15 \t 0.050151172921068674\n",
      "eps = 27.700000000000003 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 27.700000000000003 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 27.700000000000003 min_samples = 18 \t 0.00573674127536055\n",
      "eps = 27.700000000000003 min_samples = 19 \t 0.00573674127536055\n",
      "eps = 27.8 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 27.8 min_samples = 6 \t 0.28289102697188656\n",
      "eps = 27.8 min_samples = 7 \t 0.28682347535271474\n",
      "eps = 27.8 min_samples = 8 \t 0.3074866352962857\n",
      "eps = 27.8 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 27.8 min_samples = 10 \t 0.2810222437767688\n",
      "eps = 27.8 min_samples = 11 \t 0.23011256216392667\n",
      "eps = 27.8 min_samples = 12 \t 0.23674971745574017\n",
      "eps = 27.8 min_samples = 13 \t 0.14518154168715763\n",
      "eps = 27.8 min_samples = 14 \t 0.12864879270165064\n",
      "eps = 27.8 min_samples = 15 \t 0.08611003326513131\n",
      "eps = 27.8 min_samples = 16 \t 0.04605348415851363\n",
      "eps = 27.8 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 27.8 min_samples = 18 \t 0.00573674127536055\n",
      "eps = 27.8 min_samples = 19 \t 0.00573674127536055\n",
      "eps = 27.900000000000002 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 27.900000000000002 min_samples = 6 \t 0.28176339529532857\n",
      "eps = 27.900000000000002 min_samples = 7 \t 0.28682347535271474\n",
      "eps = 27.900000000000002 min_samples = 8 \t 0.3074866352962857\n",
      "eps = 27.900000000000002 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 27.900000000000002 min_samples = 10 \t 0.2810222437767688\n",
      "eps = 27.900000000000002 min_samples = 11 \t 0.2319029243863369\n",
      "eps = 27.900000000000002 min_samples = 12 \t 0.2384152452094805\n",
      "eps = 27.900000000000002 min_samples = 13 \t 0.1541409055661141\n",
      "eps = 27.900000000000002 min_samples = 14 \t 0.12864879270165064\n",
      "eps = 27.900000000000002 min_samples = 15 \t 0.08611003326513131\n",
      "eps = 27.900000000000002 min_samples = 16 \t 0.045219618642112734\n",
      "eps = 27.900000000000002 min_samples = 17 \t 0.008605988686100527\n",
      "eps = 27.900000000000002 min_samples = 18 \t 0.00573674127536055\n",
      "eps = 27.900000000000002 min_samples = 19 \t 0.00573674127536055\n",
      "eps = 28.0 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 28.0 min_samples = 6 \t 0.28176339529532857\n",
      "eps = 28.0 min_samples = 7 \t 0.28682347535271474\n",
      "eps = 28.0 min_samples = 8 \t 0.3108846018450044\n",
      "eps = 28.0 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 28.0 min_samples = 10 \t 0.2810222437767688\n",
      "eps = 28.0 min_samples = 11 \t 0.2319029243863369\n",
      "eps = 28.0 min_samples = 12 \t 0.2384152452094805\n",
      "eps = 28.0 min_samples = 13 \t 0.1541409055661141\n",
      "eps = 28.0 min_samples = 14 \t 0.12864879270165064\n",
      "eps = 28.0 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 28.0 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 28.0 min_samples = 17 \t 0.0117860147094922\n",
      "eps = 28.0 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 28.0 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 28.1 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 28.1 min_samples = 6 \t 0.28176339529532857\n",
      "eps = 28.1 min_samples = 7 \t 0.28682347535271474\n",
      "eps = 28.1 min_samples = 8 \t 0.3108846018450044\n",
      "eps = 28.1 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 28.1 min_samples = 10 \t 0.28416478039778875\n",
      "eps = 28.1 min_samples = 11 \t 0.2319029243863369\n",
      "eps = 28.1 min_samples = 12 \t 0.2516308882299932\n",
      "eps = 28.1 min_samples = 13 \t 0.1541409055661141\n",
      "eps = 28.1 min_samples = 14 \t 0.12864879270165064\n",
      "eps = 28.1 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 28.1 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 28.1 min_samples = 17 \t 0.0117860147094922\n",
      "eps = 28.1 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 28.1 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 28.200000000000003 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 28.200000000000003 min_samples = 6 \t 0.28176339529532857\n",
      "eps = 28.200000000000003 min_samples = 7 \t 0.28682347535271474\n",
      "eps = 28.200000000000003 min_samples = 8 \t 0.29839470115217465\n",
      "eps = 28.200000000000003 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 28.200000000000003 min_samples = 10 \t 0.28416478039778875\n",
      "eps = 28.200000000000003 min_samples = 11 \t 0.2319029243863369\n",
      "eps = 28.200000000000003 min_samples = 12 \t 0.2516308882299932\n",
      "eps = 28.200000000000003 min_samples = 13 \t 0.1541409055661141\n",
      "eps = 28.200000000000003 min_samples = 14 \t 0.12864879270165064\n",
      "eps = 28.200000000000003 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 28.200000000000003 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 28.200000000000003 min_samples = 17 \t 0.0117860147094922\n",
      "eps = 28.200000000000003 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 28.200000000000003 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 28.3 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 28.3 min_samples = 6 \t 0.28176339529532857\n",
      "eps = 28.3 min_samples = 7 \t 0.28682347535271474\n",
      "eps = 28.3 min_samples = 8 \t 0.29839470115217465\n",
      "eps = 28.3 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 28.3 min_samples = 10 \t 0.28416478039778875\n",
      "eps = 28.3 min_samples = 11 \t 0.2319029243863369\n",
      "eps = 28.3 min_samples = 12 \t 0.268592590407727\n",
      "eps = 28.3 min_samples = 13 \t 0.1541409055661141\n",
      "eps = 28.3 min_samples = 14 \t 0.12864879270165064\n",
      "eps = 28.3 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 28.3 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 28.3 min_samples = 17 \t 0.0117860147094922\n",
      "eps = 28.3 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 28.3 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 28.400000000000002 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 28.400000000000002 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 28.400000000000002 min_samples = 7 \t 0.2935141614385811\n",
      "eps = 28.400000000000002 min_samples = 8 \t 0.29511046623266207\n",
      "eps = 28.400000000000002 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 28.400000000000002 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 28.400000000000002 min_samples = 11 \t 0.1861935430910556\n",
      "eps = 28.400000000000002 min_samples = 12 \t 0.268592590407727\n",
      "eps = 28.400000000000002 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 28.400000000000002 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 28.400000000000002 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 28.400000000000002 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 28.400000000000002 min_samples = 17 \t 0.0117860147094922\n",
      "eps = 28.400000000000002 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 28.400000000000002 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 28.5 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 28.5 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 28.5 min_samples = 7 \t 0.28289102697188656\n",
      "eps = 28.5 min_samples = 8 \t 0.29511046623266207\n",
      "eps = 28.5 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 28.5 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 28.5 min_samples = 11 \t 0.1903735453006941\n",
      "eps = 28.5 min_samples = 12 \t 0.268592590407727\n",
      "eps = 28.5 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 28.5 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 28.5 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 28.5 min_samples = 16 \t 0.049953130582089535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 28.5 min_samples = 17 \t 0.0117860147094922\n",
      "eps = 28.5 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 28.5 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 28.6 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 28.6 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 28.6 min_samples = 7 \t 0.28289102697188656\n",
      "eps = 28.6 min_samples = 8 \t 0.29511046623266207\n",
      "eps = 28.6 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 28.6 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 28.6 min_samples = 11 \t 0.19373475093193745\n",
      "eps = 28.6 min_samples = 12 \t 0.268592590407727\n",
      "eps = 28.6 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 28.6 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 28.6 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 28.6 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 28.6 min_samples = 17 \t 0.0117860147094922\n",
      "eps = 28.6 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 28.6 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 28.700000000000003 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 28.700000000000003 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 28.700000000000003 min_samples = 7 \t 0.28289102697188656\n",
      "eps = 28.700000000000003 min_samples = 8 \t 0.29511046623266207\n",
      "eps = 28.700000000000003 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 28.700000000000003 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 28.700000000000003 min_samples = 11 \t 0.19373475093193745\n",
      "eps = 28.700000000000003 min_samples = 12 \t 0.268592590407727\n",
      "eps = 28.700000000000003 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 28.700000000000003 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 28.700000000000003 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 28.700000000000003 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 28.700000000000003 min_samples = 17 \t 0.0117860147094922\n",
      "eps = 28.700000000000003 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 28.700000000000003 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 28.8 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 28.8 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 28.8 min_samples = 7 \t 0.28289102697188656\n",
      "eps = 28.8 min_samples = 8 \t 0.29511046623266207\n",
      "eps = 28.8 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 28.8 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 28.8 min_samples = 11 \t 0.19373475093193745\n",
      "eps = 28.8 min_samples = 12 \t 0.268592590407727\n",
      "eps = 28.8 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 28.8 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 28.8 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 28.8 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 28.8 min_samples = 17 \t 0.045262535354964446\n",
      "eps = 28.8 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 28.8 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 28.900000000000002 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 28.900000000000002 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 28.900000000000002 min_samples = 7 \t 0.28289102697188656\n",
      "eps = 28.900000000000002 min_samples = 8 \t 0.29511046623266207\n",
      "eps = 28.900000000000002 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 28.900000000000002 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 28.900000000000002 min_samples = 11 \t 0.19373475093193745\n",
      "eps = 28.900000000000002 min_samples = 12 \t 0.268592590407727\n",
      "eps = 28.900000000000002 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 28.900000000000002 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 28.900000000000002 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 28.900000000000002 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 28.900000000000002 min_samples = 17 \t 0.045262535354964446\n",
      "eps = 28.900000000000002 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 28.900000000000002 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 29.0 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 29.0 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 29.0 min_samples = 7 \t 0.28289102697188656\n",
      "eps = 29.0 min_samples = 8 \t 0.29283403958233645\n",
      "eps = 29.0 min_samples = 9 \t 0.2912760113360555\n",
      "eps = 29.0 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 29.0 min_samples = 11 \t 0.19373475093193745\n",
      "eps = 29.0 min_samples = 12 \t 0.268592590407727\n",
      "eps = 29.0 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 29.0 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 29.0 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 29.0 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 29.0 min_samples = 17 \t 0.045262535354964446\n",
      "eps = 29.0 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 29.0 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 29.1 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 29.1 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 29.1 min_samples = 7 \t 0.28289102697188656\n",
      "eps = 29.1 min_samples = 8 \t 0.29283403958233645\n",
      "eps = 29.1 min_samples = 9 \t 0.2927741076132534\n",
      "eps = 29.1 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 29.1 min_samples = 11 \t 0.19373475093193745\n",
      "eps = 29.1 min_samples = 12 \t 0.268592590407727\n",
      "eps = 29.1 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 29.1 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 29.1 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 29.1 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 29.1 min_samples = 17 \t 0.045262535354964446\n",
      "eps = 29.1 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 29.1 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 29.200000000000003 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 29.200000000000003 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 29.200000000000003 min_samples = 7 \t 0.28289102697188656\n",
      "eps = 29.200000000000003 min_samples = 8 \t 0.29283403958233645\n",
      "eps = 29.200000000000003 min_samples = 9 \t 0.2927741076132534\n",
      "eps = 29.200000000000003 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 29.200000000000003 min_samples = 11 \t 0.19373475093193745\n",
      "eps = 29.200000000000003 min_samples = 12 \t 0.268592590407727\n",
      "eps = 29.200000000000003 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 29.200000000000003 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 29.200000000000003 min_samples = 15 \t 0.0921445172556959\n",
      "eps = 29.200000000000003 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 29.200000000000003 min_samples = 17 \t 0.045262535354964446\n",
      "eps = 29.200000000000003 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 29.200000000000003 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 29.3 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 29.3 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 29.3 min_samples = 7 \t 0.28289102697188656\n",
      "eps = 29.3 min_samples = 8 \t 0.29283403958233645\n",
      "eps = 29.3 min_samples = 9 \t 0.2927741076132534\n",
      "eps = 29.3 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 29.3 min_samples = 11 \t 0.19373475093193745\n",
      "eps = 29.3 min_samples = 12 \t 0.268592590407727\n",
      "eps = 29.3 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 29.3 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 29.3 min_samples = 15 \t 0.10091039272321778\n",
      "eps = 29.3 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 29.3 min_samples = 17 \t 0.045262535354964446\n",
      "eps = 29.3 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 29.3 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 29.400000000000002 min_samples = 5 \t 0.28865052377860184\n",
      "eps = 29.400000000000002 min_samples = 6 \t 0.28161785780360943\n",
      "eps = 29.400000000000002 min_samples = 7 \t 0.28289102697188656\n",
      "eps = 29.400000000000002 min_samples = 8 \t 0.29283403958233645\n",
      "eps = 29.400000000000002 min_samples = 9 \t 0.2927741076132534\n",
      "eps = 29.400000000000002 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 29.400000000000002 min_samples = 11 \t 0.19373475093193745\n",
      "eps = 29.400000000000002 min_samples = 12 \t 0.268592590407727\n",
      "eps = 29.400000000000002 min_samples = 13 \t 0.1665484225033555\n",
      "eps = 29.400000000000002 min_samples = 14 \t 0.15921841203069922\n",
      "eps = 29.400000000000002 min_samples = 15 \t 0.10091039272321778\n",
      "eps = 29.400000000000002 min_samples = 16 \t 0.049953130582089535\n",
      "eps = 29.400000000000002 min_samples = 17 \t 0.045262535354964446\n",
      "eps = 29.400000000000002 min_samples = 18 \t 0.008605988686100527\n",
      "eps = 29.400000000000002 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 29.5 min_samples = 5 \t 0.2759801973216664\n",
      "eps = 29.5 min_samples = 6 \t 0.2689687171806848\n",
      "eps = 29.5 min_samples = 7 \t 0.2699229034025578\n",
      "eps = 29.5 min_samples = 8 \t 0.2889647047403317\n",
      "eps = 29.5 min_samples = 9 \t 0.2927741076132534\n",
      "eps = 29.5 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 29.5 min_samples = 11 \t 0.1958090946577663\n",
      "eps = 29.5 min_samples = 12 \t 0.27340708209762704\n",
      "eps = 29.5 min_samples = 13 \t 0.17195092122682318\n",
      "eps = 29.5 min_samples = 14 \t 0.16440657247134557\n",
      "eps = 29.5 min_samples = 15 \t 0.10729306279692781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 29.5 min_samples = 16 \t 0.05503852174917022\n",
      "eps = 29.5 min_samples = 17 \t 0.05020881666243166\n",
      "eps = 29.5 min_samples = 18 \t 0.015280550902522845\n",
      "eps = 29.5 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 29.6 min_samples = 5 \t 0.2759801973216664\n",
      "eps = 29.6 min_samples = 6 \t 0.2689687171806848\n",
      "eps = 29.6 min_samples = 7 \t 0.2699229034025578\n",
      "eps = 29.6 min_samples = 8 \t 0.2889647047403317\n",
      "eps = 29.6 min_samples = 9 \t 0.2927741076132534\n",
      "eps = 29.6 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 29.6 min_samples = 11 \t 0.1958090946577663\n",
      "eps = 29.6 min_samples = 12 \t 0.27340708209762704\n",
      "eps = 29.6 min_samples = 13 \t 0.17195092122682318\n",
      "eps = 29.6 min_samples = 14 \t 0.16440657247134557\n",
      "eps = 29.6 min_samples = 15 \t 0.10729306279692781\n",
      "eps = 29.6 min_samples = 16 \t 0.05503852174917022\n",
      "eps = 29.6 min_samples = 17 \t 0.05020881666243166\n",
      "eps = 29.6 min_samples = 18 \t 0.015280550902522845\n",
      "eps = 29.6 min_samples = 19 \t 0.008605988686100527\n",
      "eps = 29.700000000000003 min_samples = 5 \t 0.2759801973216664\n",
      "eps = 29.700000000000003 min_samples = 6 \t 0.2689687171806848\n",
      "eps = 29.700000000000003 min_samples = 7 \t 0.2699229034025578\n",
      "eps = 29.700000000000003 min_samples = 8 \t 0.2889647047403317\n",
      "eps = 29.700000000000003 min_samples = 9 \t 0.2927741076132534\n",
      "eps = 29.700000000000003 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 29.700000000000003 min_samples = 11 \t 0.1958090946577663\n",
      "eps = 29.700000000000003 min_samples = 12 \t 0.27340708209762704\n",
      "eps = 29.700000000000003 min_samples = 13 \t 0.2085059420504204\n",
      "eps = 29.700000000000003 min_samples = 14 \t 0.16994590720506142\n",
      "eps = 29.700000000000003 min_samples = 15 \t 0.10825675279983255\n",
      "eps = 29.700000000000003 min_samples = 16 \t 0.055479274038154607\n",
      "eps = 29.700000000000003 min_samples = 17 \t 0.05055228916690529\n",
      "eps = 29.700000000000003 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 29.700000000000003 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 29.8 min_samples = 5 \t 0.2744513535439396\n",
      "eps = 29.8 min_samples = 6 \t 0.26663600752119676\n",
      "eps = 29.8 min_samples = 7 \t 0.2699229034025578\n",
      "eps = 29.8 min_samples = 8 \t 0.2889647047403317\n",
      "eps = 29.8 min_samples = 9 \t 0.2927741076132534\n",
      "eps = 29.8 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 29.8 min_samples = 11 \t 0.1958090946577663\n",
      "eps = 29.8 min_samples = 12 \t 0.27340708209762704\n",
      "eps = 29.8 min_samples = 13 \t 0.2085059420504204\n",
      "eps = 29.8 min_samples = 14 \t 0.16994590720506142\n",
      "eps = 29.8 min_samples = 15 \t 0.10825675279983255\n",
      "eps = 29.8 min_samples = 16 \t 0.055479274038154607\n",
      "eps = 29.8 min_samples = 17 \t 0.05055228916690529\n",
      "eps = 29.8 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 29.8 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 29.900000000000002 min_samples = 5 \t 0.2744513535439396\n",
      "eps = 29.900000000000002 min_samples = 6 \t 0.26663600752119676\n",
      "eps = 29.900000000000002 min_samples = 7 \t 0.2699229034025578\n",
      "eps = 29.900000000000002 min_samples = 8 \t 0.2889647047403317\n",
      "eps = 29.900000000000002 min_samples = 9 \t 0.2927741076132534\n",
      "eps = 29.900000000000002 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 29.900000000000002 min_samples = 11 \t 0.1958090946577663\n",
      "eps = 29.900000000000002 min_samples = 12 \t 0.27340708209762704\n",
      "eps = 29.900000000000002 min_samples = 13 \t 0.2085059420504204\n",
      "eps = 29.900000000000002 min_samples = 14 \t 0.16994590720506142\n",
      "eps = 29.900000000000002 min_samples = 15 \t 0.10825675279983255\n",
      "eps = 29.900000000000002 min_samples = 16 \t 0.055479274038154607\n",
      "eps = 29.900000000000002 min_samples = 17 \t 0.05055228916690529\n",
      "eps = 29.900000000000002 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 29.900000000000002 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 30.0 min_samples = 5 \t 0.2744513535439396\n",
      "eps = 30.0 min_samples = 6 \t 0.26663600752119676\n",
      "eps = 30.0 min_samples = 7 \t 0.2699229034025578\n",
      "eps = 30.0 min_samples = 8 \t 0.2889647047403317\n",
      "eps = 30.0 min_samples = 9 \t 0.2927741076132534\n",
      "eps = 30.0 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 30.0 min_samples = 11 \t 0.23048526797402236\n",
      "eps = 30.0 min_samples = 12 \t 0.27340708209762704\n",
      "eps = 30.0 min_samples = 13 \t 0.2085059420504204\n",
      "eps = 30.0 min_samples = 14 \t 0.16994590720506142\n",
      "eps = 30.0 min_samples = 15 \t 0.10825675279983255\n",
      "eps = 30.0 min_samples = 16 \t 0.054977055806068986\n",
      "eps = 30.0 min_samples = 17 \t 0.04952691251835472\n",
      "eps = 30.0 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 30.0 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 30.1 min_samples = 5 \t 0.2744513535439396\n",
      "eps = 30.1 min_samples = 6 \t 0.26714115149358053\n",
      "eps = 30.1 min_samples = 7 \t 0.2699229034025578\n",
      "eps = 30.1 min_samples = 8 \t 0.2889647047403317\n",
      "eps = 30.1 min_samples = 9 \t 0.2917661154333891\n",
      "eps = 30.1 min_samples = 10 \t 0.29273894831520114\n",
      "eps = 30.1 min_samples = 11 \t 0.23048526797402236\n",
      "eps = 30.1 min_samples = 12 \t 0.27340708209762704\n",
      "eps = 30.1 min_samples = 13 \t 0.26492285041363217\n",
      "eps = 30.1 min_samples = 14 \t 0.16994590720506142\n",
      "eps = 30.1 min_samples = 15 \t 0.10825675279983255\n",
      "eps = 30.1 min_samples = 16 \t 0.054977055806068986\n",
      "eps = 30.1 min_samples = 17 \t 0.04952691251835472\n",
      "eps = 30.1 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 30.1 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 30.200000000000003 min_samples = 5 \t 0.2744513535439396\n",
      "eps = 30.200000000000003 min_samples = 6 \t 0.26714115149358053\n",
      "eps = 30.200000000000003 min_samples = 7 \t 0.2699229034025578\n",
      "eps = 30.200000000000003 min_samples = 8 \t 0.2889647047403317\n",
      "eps = 30.200000000000003 min_samples = 9 \t 0.2917661154333891\n",
      "eps = 30.200000000000003 min_samples = 10 \t 0.29013972380356945\n",
      "eps = 30.200000000000003 min_samples = 11 \t 0.23048526797402236\n",
      "eps = 30.200000000000003 min_samples = 12 \t 0.27340708209762704\n",
      "eps = 30.200000000000003 min_samples = 13 \t 0.26492285041363217\n",
      "eps = 30.200000000000003 min_samples = 14 \t 0.16994590720506142\n",
      "eps = 30.200000000000003 min_samples = 15 \t 0.10825675279983255\n",
      "eps = 30.200000000000003 min_samples = 16 \t 0.054977055806068986\n",
      "eps = 30.200000000000003 min_samples = 17 \t 0.04952691251835472\n",
      "eps = 30.200000000000003 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 30.200000000000003 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 30.3 min_samples = 5 \t 0.2744513535439396\n",
      "eps = 30.3 min_samples = 6 \t 0.26714115149358053\n",
      "eps = 30.3 min_samples = 7 \t 0.2699229034025578\n",
      "eps = 30.3 min_samples = 8 \t 0.2889647047403317\n",
      "eps = 30.3 min_samples = 9 \t 0.2917661154333891\n",
      "eps = 30.3 min_samples = 10 \t 0.29013972380356945\n",
      "eps = 30.3 min_samples = 11 \t 0.24926692716924392\n",
      "eps = 30.3 min_samples = 12 \t 0.27340708209762704\n",
      "eps = 30.3 min_samples = 13 \t 0.26492285041363217\n",
      "eps = 30.3 min_samples = 14 \t 0.16994590720506142\n",
      "eps = 30.3 min_samples = 15 \t 0.10825675279983255\n",
      "eps = 30.3 min_samples = 16 \t 0.054977055806068986\n",
      "eps = 30.3 min_samples = 17 \t 0.04952691251835472\n",
      "eps = 30.3 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 30.3 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 30.400000000000002 min_samples = 5 \t 0.2744513535439396\n",
      "eps = 30.400000000000002 min_samples = 6 \t 0.26714115149358053\n",
      "eps = 30.400000000000002 min_samples = 7 \t 0.2699229034025578\n",
      "eps = 30.400000000000002 min_samples = 8 \t 0.2632369291925975\n",
      "eps = 30.400000000000002 min_samples = 9 \t 0.29267592748414817\n",
      "eps = 30.400000000000002 min_samples = 10 \t 0.2931822855227094\n",
      "eps = 30.400000000000002 min_samples = 11 \t 0.29441459897754274\n",
      "eps = 30.400000000000002 min_samples = 12 \t 0.2821611855382782\n",
      "eps = 30.400000000000002 min_samples = 13 \t 0.27374805141239983\n",
      "eps = 30.400000000000002 min_samples = 14 \t 0.1774252635786749\n",
      "eps = 30.400000000000002 min_samples = 15 \t 0.11757415090200454\n",
      "eps = 30.400000000000002 min_samples = 16 \t 0.06777235825671044\n",
      "eps = 30.400000000000002 min_samples = 17 \t 0.050497494453761685\n",
      "eps = 30.400000000000002 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 30.400000000000002 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 30.5 min_samples = 5 \t 0.2744513535439396\n",
      "eps = 30.5 min_samples = 6 \t 0.2679745071448736\n",
      "eps = 30.5 min_samples = 7 \t 0.26977342553301487\n",
      "eps = 30.5 min_samples = 8 \t 0.26318543545439216\n",
      "eps = 30.5 min_samples = 9 \t 0.29663198884200404\n",
      "eps = 30.5 min_samples = 10 \t 0.29860700316984495\n",
      "eps = 30.5 min_samples = 11 \t 0.29441459897754274\n",
      "eps = 30.5 min_samples = 12 \t 0.2954200706442886\n",
      "eps = 30.5 min_samples = 13 \t 0.2719451984157629\n",
      "eps = 30.5 min_samples = 14 \t 0.18293964419610728\n",
      "eps = 30.5 min_samples = 15 \t 0.12425157514266737\n",
      "eps = 30.5 min_samples = 16 \t 0.0929984485853252\n",
      "eps = 30.5 min_samples = 17 \t 0.050497494453761685\n",
      "eps = 30.5 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 30.5 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 30.6 min_samples = 5 \t 0.2744513535439396\n",
      "eps = 30.6 min_samples = 6 \t 0.2679745071448736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 30.6 min_samples = 7 \t 0.26977342553301487\n",
      "eps = 30.6 min_samples = 8 \t 0.26318543545439216\n",
      "eps = 30.6 min_samples = 9 \t 0.29663198884200404\n",
      "eps = 30.6 min_samples = 10 \t 0.29860700316984495\n",
      "eps = 30.6 min_samples = 11 \t 0.29441459897754274\n",
      "eps = 30.6 min_samples = 12 \t 0.2954200706442886\n",
      "eps = 30.6 min_samples = 13 \t 0.2869601441526612\n",
      "eps = 30.6 min_samples = 14 \t 0.23757065026043855\n",
      "eps = 30.6 min_samples = 15 \t 0.12425157514266737\n",
      "eps = 30.6 min_samples = 16 \t 0.0929984485853252\n",
      "eps = 30.6 min_samples = 17 \t 0.05539201368111033\n",
      "eps = 30.6 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 30.6 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 30.700000000000003 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 30.700000000000003 min_samples = 6 \t 0.2679745071448736\n",
      "eps = 30.700000000000003 min_samples = 7 \t 0.26977342553301487\n",
      "eps = 30.700000000000003 min_samples = 8 \t 0.26318543545439216\n",
      "eps = 30.700000000000003 min_samples = 9 \t 0.2956161406835855\n",
      "eps = 30.700000000000003 min_samples = 10 \t 0.29860700316984495\n",
      "eps = 30.700000000000003 min_samples = 11 \t 0.2931822855227094\n",
      "eps = 30.700000000000003 min_samples = 12 \t 0.2954200706442886\n",
      "eps = 30.700000000000003 min_samples = 13 \t 0.2869601441526612\n",
      "eps = 30.700000000000003 min_samples = 14 \t 0.23757065026043855\n",
      "eps = 30.700000000000003 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 30.700000000000003 min_samples = 16 \t 0.0929984485853252\n",
      "eps = 30.700000000000003 min_samples = 17 \t 0.05539201368111033\n",
      "eps = 30.700000000000003 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 30.700000000000003 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 30.8 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 30.8 min_samples = 6 \t 0.26913598658163196\n",
      "eps = 30.8 min_samples = 7 \t 0.2699513054007659\n",
      "eps = 30.8 min_samples = 8 \t 0.2699513054007659\n",
      "eps = 30.8 min_samples = 9 \t 0.3086687579728529\n",
      "eps = 30.8 min_samples = 10 \t 0.29860700316984495\n",
      "eps = 30.8 min_samples = 11 \t 0.2931822855227094\n",
      "eps = 30.8 min_samples = 12 \t 0.32472944502242773\n",
      "eps = 30.8 min_samples = 13 \t 0.2869601441526612\n",
      "eps = 30.8 min_samples = 14 \t 0.23757065026043855\n",
      "eps = 30.8 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 30.8 min_samples = 16 \t 0.0929984485853252\n",
      "eps = 30.8 min_samples = 17 \t 0.060894190633353676\n",
      "eps = 30.8 min_samples = 18 \t 0.015410126960771967\n",
      "eps = 30.8 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 30.900000000000002 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 30.900000000000002 min_samples = 6 \t 0.26913598658163196\n",
      "eps = 30.900000000000002 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 30.900000000000002 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 30.900000000000002 min_samples = 9 \t 0.31140812942588336\n",
      "eps = 30.900000000000002 min_samples = 10 \t 0.2977206268750755\n",
      "eps = 30.900000000000002 min_samples = 11 \t 0.2977206268750755\n",
      "eps = 30.900000000000002 min_samples = 12 \t 0.33267780177891587\n",
      "eps = 30.900000000000002 min_samples = 13 \t 0.2869601441526612\n",
      "eps = 30.900000000000002 min_samples = 14 \t 0.2701290307713797\n",
      "eps = 30.900000000000002 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 30.900000000000002 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 30.900000000000002 min_samples = 17 \t 0.060894190633353676\n",
      "eps = 30.900000000000002 min_samples = 18 \t 0.01582797493022519\n",
      "eps = 30.900000000000002 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 31.0 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 31.0 min_samples = 6 \t 0.26913598658163196\n",
      "eps = 31.0 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 31.0 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 31.0 min_samples = 9 \t 0.31140812942588336\n",
      "eps = 31.0 min_samples = 10 \t 0.2977206268750755\n",
      "eps = 31.0 min_samples = 11 \t 0.2977206268750755\n",
      "eps = 31.0 min_samples = 12 \t 0.33267780177891587\n",
      "eps = 31.0 min_samples = 13 \t 0.2869601441526612\n",
      "eps = 31.0 min_samples = 14 \t 0.2701290307713797\n",
      "eps = 31.0 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 31.0 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 31.0 min_samples = 17 \t 0.07934754416227631\n",
      "eps = 31.0 min_samples = 18 \t 0.01582797493022519\n",
      "eps = 31.0 min_samples = 19 \t 0.008995359380117463\n",
      "eps = 31.1 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 31.1 min_samples = 6 \t 0.26913598658163196\n",
      "eps = 31.1 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 31.1 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 31.1 min_samples = 9 \t 0.31140812942588336\n",
      "eps = 31.1 min_samples = 10 \t 0.2977206268750755\n",
      "eps = 31.1 min_samples = 11 \t 0.2977206268750755\n",
      "eps = 31.1 min_samples = 12 \t 0.34093000153243747\n",
      "eps = 31.1 min_samples = 13 \t 0.2869601441526612\n",
      "eps = 31.1 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 31.1 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 31.1 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 31.1 min_samples = 17 \t 0.07934754416227631\n",
      "eps = 31.1 min_samples = 18 \t 0.01582797493022519\n",
      "eps = 31.1 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 31.200000000000003 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 31.200000000000003 min_samples = 6 \t 0.26913598658163196\n",
      "eps = 31.200000000000003 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 31.200000000000003 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 31.200000000000003 min_samples = 9 \t 0.31140812942588336\n",
      "eps = 31.200000000000003 min_samples = 10 \t 0.2977206268750755\n",
      "eps = 31.200000000000003 min_samples = 11 \t 0.2977206268750755\n",
      "eps = 31.200000000000003 min_samples = 12 \t 0.34093000153243747\n",
      "eps = 31.200000000000003 min_samples = 13 \t 0.3170871596294206\n",
      "eps = 31.200000000000003 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 31.200000000000003 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 31.200000000000003 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 31.200000000000003 min_samples = 17 \t 0.07934754416227631\n",
      "eps = 31.200000000000003 min_samples = 18 \t 0.01582797493022519\n",
      "eps = 31.200000000000003 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 31.3 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 31.3 min_samples = 6 \t 0.26913598658163196\n",
      "eps = 31.3 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 31.3 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 31.3 min_samples = 9 \t 0.262388304659716\n",
      "eps = 31.3 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 31.3 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 31.3 min_samples = 12 \t 0.3006600846081524\n",
      "eps = 31.3 min_samples = 13 \t 0.3170871596294206\n",
      "eps = 31.3 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 31.3 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 31.3 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 31.3 min_samples = 17 \t 0.07934754416227631\n",
      "eps = 31.3 min_samples = 18 \t 0.01582797493022519\n",
      "eps = 31.3 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 31.400000000000002 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 31.400000000000002 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 31.400000000000002 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 31.400000000000002 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 31.400000000000002 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 31.400000000000002 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 31.400000000000002 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 31.400000000000002 min_samples = 12 \t 0.3006600846081524\n",
      "eps = 31.400000000000002 min_samples = 13 \t 0.3170871596294206\n",
      "eps = 31.400000000000002 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 31.400000000000002 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 31.400000000000002 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 31.400000000000002 min_samples = 17 \t 0.07934754416227631\n",
      "eps = 31.400000000000002 min_samples = 18 \t 0.01582797493022519\n",
      "eps = 31.400000000000002 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 31.5 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 31.5 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 31.5 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 31.5 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 31.5 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 31.5 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 31.5 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 31.5 min_samples = 12 \t 0.3006600846081524\n",
      "eps = 31.5 min_samples = 13 \t 0.3170871596294206\n",
      "eps = 31.5 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 31.5 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 31.5 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 31.5 min_samples = 17 \t 0.07934754416227631\n",
      "eps = 31.5 min_samples = 18 \t 0.01582797493022519\n",
      "eps = 31.5 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 31.6 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 31.6 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 31.6 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 31.6 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 31.6 min_samples = 9 \t 0.26871455067426264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 31.6 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 31.6 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 31.6 min_samples = 12 \t 0.3006600846081524\n",
      "eps = 31.6 min_samples = 13 \t 0.3170871596294206\n",
      "eps = 31.6 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 31.6 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 31.6 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 31.6 min_samples = 17 \t 0.07934754416227631\n",
      "eps = 31.6 min_samples = 18 \t 0.01582797493022519\n",
      "eps = 31.6 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 31.700000000000003 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 31.700000000000003 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 31.700000000000003 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 31.700000000000003 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 31.700000000000003 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 31.700000000000003 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 31.700000000000003 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 31.700000000000003 min_samples = 12 \t 0.3006600846081524\n",
      "eps = 31.700000000000003 min_samples = 13 \t 0.3170871596294206\n",
      "eps = 31.700000000000003 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 31.700000000000003 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 31.700000000000003 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 31.700000000000003 min_samples = 17 \t 0.07934754416227631\n",
      "eps = 31.700000000000003 min_samples = 18 \t 0.05474569839393016\n",
      "eps = 31.700000000000003 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 31.8 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 31.8 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 31.8 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 31.8 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 31.8 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 31.8 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 31.8 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 31.8 min_samples = 12 \t 0.3006600846081524\n",
      "eps = 31.8 min_samples = 13 \t 0.3170871596294206\n",
      "eps = 31.8 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 31.8 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 31.8 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 31.8 min_samples = 17 \t 0.07977751153572112\n",
      "eps = 31.8 min_samples = 18 \t 0.07365174736601196\n",
      "eps = 31.8 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 31.900000000000002 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 31.900000000000002 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 31.900000000000002 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 31.900000000000002 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 31.900000000000002 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 31.900000000000002 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 31.900000000000002 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 31.900000000000002 min_samples = 12 \t 0.3006600846081524\n",
      "eps = 31.900000000000002 min_samples = 13 \t 0.3170871596294206\n",
      "eps = 31.900000000000002 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 31.900000000000002 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 31.900000000000002 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 31.900000000000002 min_samples = 17 \t 0.07977751153572112\n",
      "eps = 31.900000000000002 min_samples = 18 \t 0.07365174736601196\n",
      "eps = 31.900000000000002 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 32.0 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 32.0 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 32.0 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 32.0 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 32.0 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 32.0 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 32.0 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 32.0 min_samples = 12 \t 0.3060601889209664\n",
      "eps = 32.0 min_samples = 13 \t 0.3170871596294206\n",
      "eps = 32.0 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 32.0 min_samples = 15 \t 0.18164089789151877\n",
      "eps = 32.0 min_samples = 16 \t 0.11601394363965517\n",
      "eps = 32.0 min_samples = 17 \t 0.07977751153572112\n",
      "eps = 32.0 min_samples = 18 \t 0.07365174736601196\n",
      "eps = 32.0 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 32.1 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 32.1 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 32.1 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 32.1 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 32.1 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 32.1 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 32.1 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 32.1 min_samples = 12 \t 0.3060601889209664\n",
      "eps = 32.1 min_samples = 13 \t 0.32447515371948005\n",
      "eps = 32.1 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 32.1 min_samples = 15 \t 0.2142865146043796\n",
      "eps = 32.1 min_samples = 16 \t 0.16100452886903655\n",
      "eps = 32.1 min_samples = 17 \t 0.07977751153572112\n",
      "eps = 32.1 min_samples = 18 \t 0.07365174736601196\n",
      "eps = 32.1 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 32.2 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 32.2 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 32.2 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 32.2 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 32.2 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 32.2 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 32.2 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 32.2 min_samples = 12 \t 0.3060601889209664\n",
      "eps = 32.2 min_samples = 13 \t 0.32447515371948005\n",
      "eps = 32.2 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 32.2 min_samples = 15 \t 0.2142865146043796\n",
      "eps = 32.2 min_samples = 16 \t 0.16100452886903655\n",
      "eps = 32.2 min_samples = 17 \t 0.07977751153572112\n",
      "eps = 32.2 min_samples = 18 \t 0.07365174736601196\n",
      "eps = 32.2 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 32.300000000000004 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 32.300000000000004 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 32.300000000000004 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 32.300000000000004 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 32.300000000000004 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 32.300000000000004 min_samples = 10 \t 0.2845205797912175\n",
      "eps = 32.300000000000004 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 32.300000000000004 min_samples = 12 \t 0.3060601889209664\n",
      "eps = 32.300000000000004 min_samples = 13 \t 0.32447515371948005\n",
      "eps = 32.300000000000004 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 32.300000000000004 min_samples = 15 \t 0.2142865146043796\n",
      "eps = 32.300000000000004 min_samples = 16 \t 0.16100452886903655\n",
      "eps = 32.300000000000004 min_samples = 17 \t 0.07977751153572112\n",
      "eps = 32.300000000000004 min_samples = 18 \t 0.07365174736601196\n",
      "eps = 32.300000000000004 min_samples = 19 \t 0.015410126960771967\n",
      "eps = 32.4 min_samples = 5 \t 0.2768894755449942\n",
      "eps = 32.4 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 32.4 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 32.4 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 32.4 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 32.4 min_samples = 10 \t 0.2982903965530651\n",
      "eps = 32.4 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 32.4 min_samples = 12 \t 0.3060601889209664\n",
      "eps = 32.4 min_samples = 13 \t 0.32447515371948005\n",
      "eps = 32.4 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 32.4 min_samples = 15 \t 0.23757065026043855\n",
      "eps = 32.4 min_samples = 16 \t 0.17283841463692687\n",
      "eps = 32.4 min_samples = 17 \t 0.08329951899279305\n",
      "eps = 32.4 min_samples = 18 \t 0.07365174736601196\n",
      "eps = 32.4 min_samples = 19 \t 0.053812612812610634\n",
      "eps = 32.5 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 32.5 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 32.5 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 32.5 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 32.5 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 32.5 min_samples = 10 \t 0.2982903965530651\n",
      "eps = 32.5 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 32.5 min_samples = 12 \t 0.30308594563206126\n",
      "eps = 32.5 min_samples = 13 \t 0.2677431776560807\n",
      "eps = 32.5 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 32.5 min_samples = 15 \t 0.24383516799949317\n",
      "eps = 32.5 min_samples = 16 \t 0.17668612942428405\n",
      "eps = 32.5 min_samples = 17 \t 0.14953519797798528\n",
      "eps = 32.5 min_samples = 18 \t 0.07365174736601196\n",
      "eps = 32.5 min_samples = 19 \t 0.053812612812610634\n",
      "eps = 32.6 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 32.6 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 32.6 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 32.6 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 32.6 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 32.6 min_samples = 10 \t 0.2982903965530651\n",
      "eps = 32.6 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 32.6 min_samples = 12 \t 0.30308594563206126\n",
      "eps = 32.6 min_samples = 13 \t 0.2677431776560807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 32.6 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 32.6 min_samples = 15 \t 0.2782990127515456\n",
      "eps = 32.6 min_samples = 16 \t 0.17668612942428405\n",
      "eps = 32.6 min_samples = 17 \t 0.15279164827260844\n",
      "eps = 32.6 min_samples = 18 \t 0.08401076005354015\n",
      "eps = 32.6 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 32.7 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 32.7 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 32.7 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 32.7 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 32.7 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 32.7 min_samples = 10 \t 0.2982903965530651\n",
      "eps = 32.7 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 32.7 min_samples = 12 \t 0.2662538592615463\n",
      "eps = 32.7 min_samples = 13 \t 0.2677431776560807\n",
      "eps = 32.7 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 32.7 min_samples = 15 \t 0.2782990127515456\n",
      "eps = 32.7 min_samples = 16 \t 0.18542640250469142\n",
      "eps = 32.7 min_samples = 17 \t 0.16087534882477855\n",
      "eps = 32.7 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 32.7 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 32.800000000000004 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 32.800000000000004 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 32.800000000000004 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 32.800000000000004 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 32.800000000000004 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 32.800000000000004 min_samples = 10 \t 0.2982903965530651\n",
      "eps = 32.800000000000004 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 32.800000000000004 min_samples = 12 \t 0.2662538592615463\n",
      "eps = 32.800000000000004 min_samples = 13 \t 0.2677431776560807\n",
      "eps = 32.800000000000004 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 32.800000000000004 min_samples = 15 \t 0.2782990127515456\n",
      "eps = 32.800000000000004 min_samples = 16 \t 0.18542640250469142\n",
      "eps = 32.800000000000004 min_samples = 17 \t 0.16087534882477855\n",
      "eps = 32.800000000000004 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 32.800000000000004 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 32.9 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 32.9 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 32.9 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 32.9 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 32.9 min_samples = 9 \t 0.26871455067426264\n",
      "eps = 32.9 min_samples = 10 \t 0.2982903965530651\n",
      "eps = 32.9 min_samples = 11 \t 0.2970759097049034\n",
      "eps = 32.9 min_samples = 12 \t 0.2662538592615463\n",
      "eps = 32.9 min_samples = 13 \t 0.2677431776560807\n",
      "eps = 32.9 min_samples = 14 \t 0.2840692727881743\n",
      "eps = 32.9 min_samples = 15 \t 0.2782990127515456\n",
      "eps = 32.9 min_samples = 16 \t 0.18542640250469142\n",
      "eps = 32.9 min_samples = 17 \t 0.16087534882477855\n",
      "eps = 32.9 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 32.9 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 33.0 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 33.0 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 33.0 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 33.0 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 33.0 min_samples = 9 \t 0.26915691073852516\n",
      "eps = 33.0 min_samples = 10 \t 0.2949461166761345\n",
      "eps = 33.0 min_samples = 11 \t 0.28382600204275843\n",
      "eps = 33.0 min_samples = 12 \t 0.2528694458868413\n",
      "eps = 33.0 min_samples = 13 \t 0.2543567636071726\n",
      "eps = 33.0 min_samples = 14 \t 0.28272735868653326\n",
      "eps = 33.0 min_samples = 15 \t 0.27686753848932283\n",
      "eps = 33.0 min_samples = 16 \t 0.18542640250469142\n",
      "eps = 33.0 min_samples = 17 \t 0.16087534882477855\n",
      "eps = 33.0 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 33.0 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 33.1 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 33.1 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 33.1 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 33.1 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 33.1 min_samples = 9 \t 0.26915691073852516\n",
      "eps = 33.1 min_samples = 10 \t 0.2949461166761345\n",
      "eps = 33.1 min_samples = 11 \t 0.28382600204275843\n",
      "eps = 33.1 min_samples = 12 \t 0.2528694458868413\n",
      "eps = 33.1 min_samples = 13 \t 0.2543567636071726\n",
      "eps = 33.1 min_samples = 14 \t 0.28272735868653326\n",
      "eps = 33.1 min_samples = 15 \t 0.27686753848932283\n",
      "eps = 33.1 min_samples = 16 \t 0.18542640250469142\n",
      "eps = 33.1 min_samples = 17 \t 0.16087534882477855\n",
      "eps = 33.1 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 33.1 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 33.2 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 33.2 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 33.2 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 33.2 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 33.2 min_samples = 9 \t 0.26915691073852516\n",
      "eps = 33.2 min_samples = 10 \t 0.2949461166761345\n",
      "eps = 33.2 min_samples = 11 \t 0.28382600204275843\n",
      "eps = 33.2 min_samples = 12 \t 0.28169399203823153\n",
      "eps = 33.2 min_samples = 13 \t 0.2740473551159812\n",
      "eps = 33.2 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 33.2 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 33.2 min_samples = 16 \t 0.2411025624034256\n",
      "eps = 33.2 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 33.2 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 33.2 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 33.300000000000004 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 33.300000000000004 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 33.300000000000004 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 33.300000000000004 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 33.300000000000004 min_samples = 9 \t 0.26915691073852516\n",
      "eps = 33.300000000000004 min_samples = 10 \t 0.2949461166761345\n",
      "eps = 33.300000000000004 min_samples = 11 \t 0.28382600204275843\n",
      "eps = 33.300000000000004 min_samples = 12 \t 0.28169399203823153\n",
      "eps = 33.300000000000004 min_samples = 13 \t 0.2740473551159812\n",
      "eps = 33.300000000000004 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 33.300000000000004 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 33.300000000000004 min_samples = 16 \t 0.2411025624034256\n",
      "eps = 33.300000000000004 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 33.300000000000004 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 33.300000000000004 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 33.4 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 33.4 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 33.4 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 33.4 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 33.4 min_samples = 9 \t 0.26915691073852516\n",
      "eps = 33.4 min_samples = 10 \t 0.2949461166761345\n",
      "eps = 33.4 min_samples = 11 \t 0.28382600204275843\n",
      "eps = 33.4 min_samples = 12 \t 0.28169399203823153\n",
      "eps = 33.4 min_samples = 13 \t 0.2740473551159812\n",
      "eps = 33.4 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 33.4 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 33.4 min_samples = 16 \t 0.2411025624034256\n",
      "eps = 33.4 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 33.4 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 33.4 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 33.5 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 33.5 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 33.5 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 33.5 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 33.5 min_samples = 9 \t 0.26915691073852516\n",
      "eps = 33.5 min_samples = 10 \t 0.2949461166761345\n",
      "eps = 33.5 min_samples = 11 \t 0.28382600204275843\n",
      "eps = 33.5 min_samples = 12 \t 0.28169399203823153\n",
      "eps = 33.5 min_samples = 13 \t 0.2740473551159812\n",
      "eps = 33.5 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 33.5 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 33.5 min_samples = 16 \t 0.2411025624034256\n",
      "eps = 33.5 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 33.5 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 33.5 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 33.6 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 33.6 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 33.6 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 33.6 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 33.6 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 33.6 min_samples = 10 \t 0.29562806455520735\n",
      "eps = 33.6 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 33.6 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 33.6 min_samples = 13 \t 0.2740473551159812\n",
      "eps = 33.6 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 33.6 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 33.6 min_samples = 16 \t 0.2411025624034256\n",
      "eps = 33.6 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 33.6 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 33.6 min_samples = 19 \t 0.05596794055278219\n",
      "eps = 33.7 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 33.7 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 33.7 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 33.7 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 33.7 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 33.7 min_samples = 10 \t 0.29562806455520735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 33.7 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 33.7 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 33.7 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 33.7 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 33.7 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 33.7 min_samples = 16 \t 0.2411025624034256\n",
      "eps = 33.7 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 33.7 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 33.7 min_samples = 19 \t 0.06105386000383575\n",
      "eps = 33.800000000000004 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 33.800000000000004 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 33.800000000000004 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 33.800000000000004 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 33.800000000000004 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 33.800000000000004 min_samples = 10 \t 0.29562806455520735\n",
      "eps = 33.800000000000004 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 33.800000000000004 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 33.800000000000004 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 33.800000000000004 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 33.800000000000004 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 33.800000000000004 min_samples = 16 \t 0.2411025624034256\n",
      "eps = 33.800000000000004 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 33.800000000000004 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 33.800000000000004 min_samples = 19 \t 0.06105386000383575\n",
      "eps = 33.9 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 33.9 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 33.9 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 33.9 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 33.9 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 33.9 min_samples = 10 \t 0.29562806455520735\n",
      "eps = 33.9 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 33.9 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 33.9 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 33.9 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 33.9 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 33.9 min_samples = 16 \t 0.2782990127515456\n",
      "eps = 33.9 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 33.9 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 33.9 min_samples = 19 \t 0.06105386000383575\n",
      "eps = 34.0 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 34.0 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 34.0 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 34.0 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 34.0 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 34.0 min_samples = 10 \t 0.29562806455520735\n",
      "eps = 34.0 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 34.0 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 34.0 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 34.0 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 34.0 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 34.0 min_samples = 16 \t 0.2782990127515456\n",
      "eps = 34.0 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 34.0 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 34.0 min_samples = 19 \t 0.06105386000383575\n",
      "eps = 34.1 min_samples = 5 \t 0.2806292731017809\n",
      "eps = 34.1 min_samples = 6 \t 0.27550746511083346\n",
      "eps = 34.1 min_samples = 7 \t 0.26714115149358053\n",
      "eps = 34.1 min_samples = 8 \t 0.2693102959334763\n",
      "eps = 34.1 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 34.1 min_samples = 10 \t 0.29562806455520735\n",
      "eps = 34.1 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 34.1 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 34.1 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 34.1 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 34.1 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 34.1 min_samples = 16 \t 0.2782990127515456\n",
      "eps = 34.1 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 34.1 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 34.1 min_samples = 19 \t 0.06105386000383575\n",
      "eps = 34.2 min_samples = 5 \t 0.2795120884891384\n",
      "eps = 34.2 min_samples = 6 \t 0.27389999480062394\n",
      "eps = 34.2 min_samples = 7 \t 0.26529843821673965\n",
      "eps = 34.2 min_samples = 8 \t 0.26529843821673965\n",
      "eps = 34.2 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 34.2 min_samples = 10 \t 0.29562806455520735\n",
      "eps = 34.2 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 34.2 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 34.2 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 34.2 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 34.2 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 34.2 min_samples = 16 \t 0.2782990127515456\n",
      "eps = 34.2 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 34.2 min_samples = 18 \t 0.11312651550631903\n",
      "eps = 34.2 min_samples = 19 \t 0.061843777364319424\n",
      "eps = 34.300000000000004 min_samples = 5 \t 0.2795120884891384\n",
      "eps = 34.300000000000004 min_samples = 6 \t 0.27389999480062394\n",
      "eps = 34.300000000000004 min_samples = 7 \t 0.26529843821673965\n",
      "eps = 34.300000000000004 min_samples = 8 \t 0.26529843821673965\n",
      "eps = 34.300000000000004 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 34.300000000000004 min_samples = 10 \t 0.28223627870609297\n",
      "eps = 34.300000000000004 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 34.300000000000004 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 34.300000000000004 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 34.300000000000004 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 34.300000000000004 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 34.300000000000004 min_samples = 16 \t 0.2782990127515456\n",
      "eps = 34.300000000000004 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 34.300000000000004 min_samples = 18 \t 0.11380251042811486\n",
      "eps = 34.300000000000004 min_samples = 19 \t 0.0805466646954741\n",
      "eps = 34.4 min_samples = 5 \t 0.2795120884891384\n",
      "eps = 34.4 min_samples = 6 \t 0.27389999480062394\n",
      "eps = 34.4 min_samples = 7 \t 0.26529843821673965\n",
      "eps = 34.4 min_samples = 8 \t 0.26529843821673965\n",
      "eps = 34.4 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 34.4 min_samples = 10 \t 0.28223627870609297\n",
      "eps = 34.4 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 34.4 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 34.4 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 34.4 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 34.4 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 34.4 min_samples = 16 \t 0.2782990127515456\n",
      "eps = 34.4 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 34.4 min_samples = 18 \t 0.11380251042811486\n",
      "eps = 34.4 min_samples = 19 \t 0.0805466646954741\n",
      "eps = 34.5 min_samples = 5 \t 0.2795120884891384\n",
      "eps = 34.5 min_samples = 6 \t 0.27389999480062394\n",
      "eps = 34.5 min_samples = 7 \t 0.26529843821673965\n",
      "eps = 34.5 min_samples = 8 \t 0.26529843821673965\n",
      "eps = 34.5 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 34.5 min_samples = 10 \t 0.28223627870609297\n",
      "eps = 34.5 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 34.5 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 34.5 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 34.5 min_samples = 14 \t 0.3095439655739183\n",
      "eps = 34.5 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 34.5 min_samples = 16 \t 0.2782990127515456\n",
      "eps = 34.5 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 34.5 min_samples = 18 \t 0.11996836085199732\n",
      "eps = 34.5 min_samples = 19 \t 0.0909582693825821\n",
      "eps = 34.6 min_samples = 5 \t 0.285733474756479\n",
      "eps = 34.6 min_samples = 6 \t 0.2804517325595238\n",
      "eps = 34.6 min_samples = 7 \t 0.2785492960916405\n",
      "eps = 34.6 min_samples = 8 \t 0.26529843821673965\n",
      "eps = 34.6 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 34.6 min_samples = 10 \t 0.28223627870609297\n",
      "eps = 34.6 min_samples = 11 \t 0.28437030541990277\n",
      "eps = 34.6 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 34.6 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 34.6 min_samples = 14 \t 0.3167882433468125\n",
      "eps = 34.6 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 34.6 min_samples = 16 \t 0.2782990127515456\n",
      "eps = 34.6 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 34.6 min_samples = 18 \t 0.11996836085199732\n",
      "eps = 34.6 min_samples = 19 \t 0.0909582693825821\n",
      "eps = 34.7 min_samples = 5 \t 0.285733474756479\n",
      "eps = 34.7 min_samples = 6 \t 0.2804517325595238\n",
      "eps = 34.7 min_samples = 7 \t 0.2785492960916405\n",
      "eps = 34.7 min_samples = 8 \t 0.26529843821673965\n",
      "eps = 34.7 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 34.7 min_samples = 10 \t 0.28223627870609297\n",
      "eps = 34.7 min_samples = 11 \t 0.29009206755814326\n",
      "eps = 34.7 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 34.7 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 34.7 min_samples = 14 \t 0.3167882433468125\n",
      "eps = 34.7 min_samples = 15 \t 0.2763689009997006\n",
      "eps = 34.7 min_samples = 16 \t 0.2782990127515456\n",
      "eps = 34.7 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 34.7 min_samples = 18 \t 0.11996836085199732\n",
      "eps = 34.7 min_samples = 19 \t 0.0909582693825821\n",
      "eps = 34.800000000000004 min_samples = 5 \t 0.285733474756479\n",
      "eps = 34.800000000000004 min_samples = 6 \t 0.2804517325595238\n",
      "eps = 34.800000000000004 min_samples = 7 \t 0.27933834170291466\n",
      "eps = 34.800000000000004 min_samples = 8 \t 0.26529843821673965\n",
      "eps = 34.800000000000004 min_samples = 9 \t 0.2693102959334763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 34.800000000000004 min_samples = 10 \t 0.28223627870609297\n",
      "eps = 34.800000000000004 min_samples = 11 \t 0.29009206755814326\n",
      "eps = 34.800000000000004 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 34.800000000000004 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 34.800000000000004 min_samples = 14 \t 0.3167882433468125\n",
      "eps = 34.800000000000004 min_samples = 15 \t 0.2801552646637755\n",
      "eps = 34.800000000000004 min_samples = 16 \t 0.2782990127515456\n",
      "eps = 34.800000000000004 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 34.800000000000004 min_samples = 18 \t 0.11996836085199732\n",
      "eps = 34.800000000000004 min_samples = 19 \t 0.0909582693825821\n",
      "eps = 34.9 min_samples = 5 \t 0.285733474756479\n",
      "eps = 34.9 min_samples = 6 \t 0.2804517325595238\n",
      "eps = 34.9 min_samples = 7 \t 0.27933834170291466\n",
      "eps = 34.9 min_samples = 8 \t 0.26529843821673965\n",
      "eps = 34.9 min_samples = 9 \t 0.2693102959334763\n",
      "eps = 34.9 min_samples = 10 \t 0.28223627870609297\n",
      "eps = 34.9 min_samples = 11 \t 0.29009206755814326\n",
      "eps = 34.9 min_samples = 12 \t 0.2849645384972087\n",
      "eps = 34.9 min_samples = 13 \t 0.28123333266925854\n",
      "eps = 34.9 min_samples = 14 \t 0.3167882433468125\n",
      "eps = 34.9 min_samples = 15 \t 0.2801552646637755\n",
      "eps = 34.9 min_samples = 16 \t 0.28225634999301635\n",
      "eps = 34.9 min_samples = 17 \t 0.17260599916012379\n",
      "eps = 34.9 min_samples = 18 \t 0.11996836085199732\n",
      "eps = 34.9 min_samples = 19 \t 0.0909582693825821\n",
      "\n",
      "The maxvalue is 0.34093000153243747 where i = 31.1 and j = 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "def DBSS(e,ms):\n",
    "    DBS = DBSCAN(eps=e, min_samples=ms, metric='euclidean').fit(resData)\n",
    "    labels = DBS.labels_\n",
    "    return labels\n",
    "maxvalue = 0\n",
    "maxi = 0\n",
    "maxj = 0\n",
    "for i in range(210, 350,1):\n",
    "    for j in range(5,20,1):\n",
    "        score = metrics.adjusted_rand_score(DBSS(i*0.1, j) , res_test_y)\n",
    "        if maxvalue < score:\n",
    "            maxvalue = score\n",
    "            maxi = i\n",
    "            maxj = j\n",
    "        print('eps =',i*0.1,'min_samples =',j,'\\t',score)\n",
    "print(\"\\nThe maxvalue is\",maxvalue,\"where i =\",maxi*0.1,\"and j =\",maxj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "这里的DBSCAN参数调整是一个比较困难和复杂的内容，所以需要多次遍历观察得到最优的值和解\n",
    "\n",
    "当前测试出来结果：当 eps = 31.1 and min_samples = 12 是接近最高的值和结果，大约0.34\n",
    "\n",
    "下面进行时间观测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.34093000153243747\n",
      "DBSCAN time: 0.013842399999703048 s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "score = metrics.adjusted_rand_score(DBSS(31.1, 12) , res_test_y)\n",
    "print(\"score: \", score)\n",
    "end = time.perf_counter()\n",
    "print(\"DBSCAN time:\", end-start ,\"s\")\n",
    "DBSCAN_time = end-start\n",
    "DBSCAN_score = maxvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层次聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  0.36840191587483156\n",
      "\n",
      "AgglomerativeClustering time: 0.007786199999827659 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering as agg\n",
    "def agg_test(num):\n",
    "    clustering = agg(n_clusters=3).fit(resData)\n",
    "    return clustering.labels_\n",
    "\n",
    "start = time.perf_counter()\n",
    "score = metrics.adjusted_rand_score(agg_test(3), res_test_y)\n",
    "end = time.perf_counter()\n",
    "print(\"scores: \",score)\n",
    "print(\"\\nAgglomerativeClustering time:\", end-start ,\"s\")\n",
    "AgglomerativeClustering_time = end-start\n",
    "AgglomerativeClustering_score = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP聚类算法\n",
    "\n",
    "同样，我们需要遍历观测相关的阻尼系数等参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0.5 and j = -100\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.012770973489855448 \n",
      "\n",
      "i = 0.5 and j = -90\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.011291915542835786 \n",
      "\n",
      "i = 0.5 and j = -80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0 \n",
      "\n",
      "i = 0.5 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0 \n",
      "\n",
      "i = 0.5 and j = -60\n",
      "\n",
      "score: 0.010743196267297674 \n",
      "\n",
      "i = 0.5 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010651776099837092 \n",
      "\n",
      "i = 0.5 and j = -40\n",
      "\n",
      "score: 0.007434188472496415 \n",
      "\n",
      "i = 0.5 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0 \n",
      "\n",
      "i = 0.5 and j = -20\n",
      "\n",
      "score: 0.0019886112961378104 \n",
      "\n",
      "i = 0.5 and j = -10\n",
      "\n",
      "score: 0.0007459561526701658 \n",
      "\n",
      "i = 0.55 and j = -100\n",
      "\n",
      "score: 0.011418844294271665 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "i = 0.55 and j = -90\n",
      "\n",
      "score: 0.010559094872647442 \n",
      "\n",
      "i = 0.55 and j = -80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0 \n",
      "\n",
      "i = 0.55 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0 \n",
      "\n",
      "i = 0.55 and j = -60\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.010248944359087391 \n",
      "\n",
      "i = 0.55 and j = -50\n",
      "\n",
      "score: 0.010157093112623613 \n",
      "\n",
      "i = 0.55 and j = -40\n",
      "\n",
      "score: 0.007434188472496415 \n",
      "\n",
      "i = 0.55 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0 \n",
      "\n",
      "i = 0.55 and j = -20\n",
      "\n",
      "score: 0.0019886112961378104 \n",
      "\n",
      "i = 0.55 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0007459561526701658 \n",
      "\n",
      "i = 0.6000000000000001 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.012038956029769798 \n",
      "\n",
      "i = 0.6000000000000001 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010566208655913687 \n",
      "\n",
      "i = 0.6000000000000001 and j = -80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010601816377545252 \n",
      "\n",
      "i = 0.6000000000000001 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010347719443150865 \n",
      "\n",
      "i = 0.6000000000000001 and j = -60\n",
      "\n",
      "score: 0.010750354332089358 \n",
      "\n",
      "i = 0.6000000000000001 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010157093112623613 \n",
      "\n",
      "i = 0.6000000000000001 and j = -40\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.007434188472496415 \n",
      "\n",
      "i = 0.6000000000000001 and j = -30\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.004217500045730034 \n",
      "\n",
      "i = 0.6000000000000001 and j = -20\n",
      "\n",
      "score: 0.0019886112961378104 \n",
      "\n",
      "i = 0.6000000000000001 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0007459561526701658 \n",
      "\n",
      "i = 0.65 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.011694700175406622 \n",
      "\n",
      "i = 0.65 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010939932467563956 \n",
      "\n",
      "i = 0.65 and j = -80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010721737689770989 \n",
      "\n",
      "i = 0.65 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010107757052474709 \n",
      "\n",
      "i = 0.65 and j = -60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.01025601335623088 \n",
      "\n",
      "i = 0.65 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010157093112623613 \n",
      "\n",
      "i = 0.65 and j = -40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.007434188472496415 \n",
      "\n",
      "i = 0.65 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0 \n",
      "\n",
      "i = 0.65 and j = -20\n",
      "\n",
      "score: 0.0019886112961378104 \n",
      "\n",
      "i = 0.65 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0007459561526701658 \n",
      "\n",
      "i = 0.7000000000000001 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.011941439237783463 \n",
      "\n",
      "i = 0.7000000000000001 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.011059703920055989 \n",
      "\n",
      "i = 0.7000000000000001 and j = -80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.011582271246950451 \n",
      "\n",
      "i = 0.7000000000000001 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.01047476021034287 \n",
      "\n",
      "i = 0.7000000000000001 and j = -60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.01025601335623088 \n",
      "\n",
      "i = 0.7000000000000001 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010157093112623613 \n",
      "\n",
      "i = 0.7000000000000001 and j = -40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.007929532628174581 \n",
      "\n",
      "i = 0.7000000000000001 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.004217500045730034 \n",
      "\n",
      "i = 0.7000000000000001 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0019886112961378104 \n",
      "\n",
      "i = 0.7000000000000001 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0007459561526701658 \n",
      "\n",
      "i = 0.75 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.011814401971524948 \n",
      "\n",
      "i = 0.75 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010566208655913687 \n",
      "\n",
      "i = 0.75 and j = -80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010601816377545252 \n",
      "\n",
      "i = 0.75 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.009980715429462389 \n",
      "\n",
      "i = 0.75 and j = -60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.009761552429561638 \n",
      "\n",
      "i = 0.75 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010157093112623613 \n",
      "\n",
      "i = 0.75 and j = -40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.007929532628174581 \n",
      "\n",
      "i = 0.75 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.004217500045730034 \n",
      "\n",
      "i = 0.75 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0019886112961378104 \n",
      "\n",
      "i = 0.75 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0007459561526701658 \n",
      "\n",
      "i = 0.8 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.011426112064565848 \n",
      "\n",
      "i = 0.8 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010693162639420021 \n",
      "\n",
      "i = 0.8 and j = -80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010601816377545252 \n",
      "\n",
      "i = 0.8 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.00985368920656419 \n",
      "\n",
      "i = 0.8 and j = -60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.009881677506516896 \n",
      "\n",
      "i = 0.8 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.010157093112623613 \n",
      "\n",
      "i = 0.8 and j = -40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.007186471264329387 \n",
      "\n",
      "i = 0.8 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.004217500045730034 \n",
      "\n",
      "i = 0.8 and j = -20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0019886112961378104 \n",
      "\n",
      "i = 0.8 and j = -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.000994547677732603 \n",
      "\n",
      "i = 0.8500000000000001 and j = -100\n",
      "\n",
      "score: 0.008985430246411755 \n",
      "\n",
      "i = 0.8500000000000001 and j = -90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.016153010266979493 \n",
      "\n",
      "i = 0.8500000000000001 and j = -80\n",
      "\n",
      "score: 0.01670166911691513 \n",
      "\n",
      "i = 0.8500000000000001 and j = -70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.007769264738211139 \n",
      "\n",
      "i = 0.8500000000000001 and j = -60\n",
      "\n",
      "score: 0.007039871259836523 \n",
      "\n",
      "i = 0.8500000000000001 and j = -50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.012180739585364824 \n",
      "\n",
      "i = 0.8500000000000001 and j = -40\n",
      "\n",
      "score: 0.01047476021034287 \n",
      "\n",
      "i = 0.8500000000000001 and j = -30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.00074059946076979 \n",
      "\n",
      "i = 0.8500000000000001 and j = -20\n",
      "\n",
      "score: 0.003963406988714461 \n",
      "\n",
      "i = 0.8500000000000001 and j = -10\n",
      "\n",
      "score: 0.0012376621699498028 \n",
      "\n",
      "i = 0.9 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.018726427671139512 \n",
      "\n",
      "i = 0.9 and j = -90\n",
      "\n",
      "score: 0.008497862118481251 \n",
      "\n",
      "i = 0.9 and j = -80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.008016661060193086 \n",
      "\n",
      "i = 0.9 and j = -70\n",
      "\n",
      "score: 0.007769264738211139 \n",
      "\n",
      "i = 0.9 and j = -60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.007039871259836523 \n",
      "\n",
      "i = 0.9 and j = -50\n",
      "\n",
      "score: 0.005947433700853211 \n",
      "\n",
      "i = 0.9 and j = -40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.0029706698342377665 \n",
      "\n",
      "i = 0.9 and j = -30\n",
      "\n",
      "score: 0.007515264835829074 \n",
      "\n",
      "i = 0.9 and j = -20\n",
      "\n",
      "score: 0.003963406988714461 \n",
      "\n",
      "i = 0.9 and j = -10\n",
      "\n",
      "score: 0.0012376621699498028 \n",
      "\n",
      "i = 0.9500000000000001 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.035352708438287396 \n",
      "\n",
      "i = 0.9500000000000001 and j = -90\n",
      "\n",
      "score: 0.03157829011130313 \n",
      "\n",
      "i = 0.9500000000000001 and j = -80\n",
      "\n",
      "score: 0.02826110230567827 \n",
      "\n",
      "i = 0.9500000000000001 and j = -70\n",
      "\n",
      "score: 0.02595537489580687 \n",
      "\n",
      "i = 0.9500000000000001 and j = -60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: 0.023311354305299695 \n",
      "\n",
      "i = 0.9500000000000001 and j = -50\n",
      "\n",
      "score: 0.01948834815223831 \n",
      "\n",
      "i = 0.9500000000000001 and j = -40\n",
      "\n",
      "score: 0.011919353873323437 \n",
      "\n",
      "i = 0.9500000000000001 and j = -30\n",
      "\n",
      "score: 0.0072352441081304725 \n",
      "\n",
      "i = 0.9500000000000001 and j = -20\n",
      "\n",
      "score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.003963406988714461 \n",
      "\n",
      "i = 0.9500000000000001 and j = -10\n",
      "\n",
      "score: 0.0012376621699498028 \n",
      "\n",
      "The maxvalue is 0.035352708438287396 where i = 0.9500000000000001 and j = -100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def affs(damp, pre):\n",
    "    '''\n",
    "    :param damp: 阻尼系数/阻尼因子\n",
    "    :param pre: preference 参考度\n",
    "    :return:\n",
    "    '''\n",
    "    clustering = AffinityPropagation(damping=damp,preference=pre)\n",
    "    label = clustering.fit_predict(resData)\n",
    "    return label\n",
    "maxvalue = 0\n",
    "maxi = 0\n",
    "maxj = 0\n",
    "for i in range(10,20):\n",
    "    for j in range(-100,0,10):\n",
    "        print('i =',i*0.05,'and j =',j)\n",
    "        score = metrics.adjusted_rand_score(affs(0.05*i, j),res_test_y)\n",
    "        print(\"\\nscore:\",score,'\\n')\n",
    "        if maxvalue < score:\n",
    "            maxvalue = score\n",
    "            maxi = i\n",
    "            maxj = j\n",
    "print(\"The maxvalue is\",maxvalue,\"where i =\",maxi*0.05,\"and j =\",maxj)\n",
    "AffinityPropagation_score = maxvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.035352708438287396\n",
      "AffinityPropagation time:  0.06195969999953377 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "print(\"Score: \",metrics.adjusted_rand_score(affs(0.95, -100),res_test_y))\n",
    "end = time.perf_counter()\n",
    "print(\"AffinityPropagation time: \",end-start,\"s\")\n",
    "AffinityPropagation_time = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结和对比分析 LAB B\n",
    "下面我们会绘制图表进行观察相关的结果，比如运行时间和得到的adjusted_rand_score结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TABLE A  时间和相关算法的关系柱状图\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "xlabels = ['kmeans','DBSCAN','Agglomerative','AffinityPropagation']\n",
    "ylabels = [kmeans_time, DBSCAN_time, AgglomerativeClustering_time, AffinityPropagation_time]\n",
    "plt.bar(range(len(xlabels)), ylabels, tick_label=xlabels)\n",
    "plt.title('时间运行和算法相关参数图,纵坐标单位：s')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TABLE B  adjusted_rand_score和相关算法的关系柱状图\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "ylabels = [kmeans_score, DBSCAN_score, AgglomerativeClustering_score, AffinityPropagation_score]\n",
    "plt.bar(range(len(xlabels)), ylabels, tick_label=xlabels)\n",
    "plt.title('adjusted_rand_score和算法相关参数图')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
